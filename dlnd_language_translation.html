<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />
<title>dlnd_language_translation</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.6 (http://getbootstrap.com)
 * Copyright 2011-2015 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    color: #000 !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: thin dotted;
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.2.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.2.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.2.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.2.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.2.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.2.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=1);
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2);
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=3);
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1);
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  filter: progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1);
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
@media (max-width: 991px) {
  #ipython_notebook {
    margin-left: 10px;
  }
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#login_widget {
  float: right;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  text-align: center;
  vertical-align: middle;
  display: inline;
  opacity: 0;
  z-index: 2;
  width: 12ex;
  margin-right: -12ex;
}
.alternate_upload .btn-upload {
  height: 22px;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: baseline;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI colors. */
.ansibold {
  font-weight: bold;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  border-left-width: 1px;
  padding-left: 5px;
  background: linear-gradient(to right, transparent -40px, transparent 1px, transparent 1px, transparent 100%);
}
div.cell.jupyter-soft-selected {
  border-left-color: #90CAF9;
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected {
  border-color: #ababab;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 5px, transparent 5px, transparent 100%);
}
@media print {
  div.cell.selected {
    border-color: transparent;
  }
}
div.cell.selected.jupyter-soft-selected {
  border-left-width: 0;
  padding-left: 6px;
  background: linear-gradient(to right, #42A5F5 -40px, #42A5F5 7px, #E3F2FD 7px, #E3F2FD 100%);
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
  border-left-width: 0px;
  padding-left: 6px;
  background: linear-gradient(to right, #66BB6A -40px, #66BB6A 5px, transparent 5px, transparent 100%);
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
@-moz-document url-prefix() {
  div.inner_cell {
    overflow-x: hidden;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  padding: 0.4em;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. We need the 0 value because of how we size */
  /* .CodeMirror-lines */
  padding: 0;
  border: 0;
  border-radius: 0;
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul {
  list-style: disc;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ul ul {
  list-style: square;
  margin: 0em 2em;
}
.rendered_html ul ul ul {
  list-style: circle;
  margin: 0em 2em;
}
.rendered_html ol {
  list-style: decimal;
  margin: 0em 2em;
  padding-left: 0px;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
  margin: 0em 2em;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
  margin: 0em 2em;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  background-color: #fff;
  color: #000;
  font-size: 100%;
  padding: 0px;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: 1px solid black;
  border-collapse: collapse;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  border: 1px solid black;
  border-collapse: collapse;
  margin: 1em 2em;
}
.rendered_html td,
.rendered_html th {
  text-align: left;
  vertical-align: middle;
  padding: 4px;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget {
  float: right !important;
  float: right;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 20ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  margin-top: 6px;
}
span.save_widget span.filename {
  height: 1em;
  line-height: 1em;
  padding: 3px;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  display: none;
}
.command-shortcut:before {
  content: "(command)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}

@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Tradutor-de-texto">Tradutor de texto<a class="anchor-link" href="#Tradutor-de-texto">&#182;</a></h1><p>Neste projeto, será criando um modelo chamado ´sequence to sequence´ (Seq2Seq) utilizando um dataset com sentenças em ingles e sentenças em francês, que irá traduzir textos em inglês para textos em francês.</p>
<h2 id="Importar-os-dados">Importar os dados<a class="anchor-link" href="#Importar-os-dados">&#182;</a></h2><p>Uma vez que traduzir todo o idioma do inglês para o francês levará muito tempo para treinar, fornecemos uma pequena porção do corpus inglês</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">helper</span> <span class="c1"># Utilizado para salvar/carregar os dados </span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span> <span class="c1"># Utilizado para realizar testes em cada bloco</span>

<span class="n">source_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_en&#39;</span>
<span class="n">target_path</span> <span class="o">=</span> <span class="s1">&#39;data/small_vocab_fr&#39;</span>
<span class="n">source_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">)</span>
<span class="n">target_text</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_data</span><span class="p">(</span><span class="n">target_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Explorar-os-dados">Explorar os dados<a class="anchor-link" href="#Explorar-os-dados">&#182;</a></h2><p>Utilize a função view_sentence_range para ver diversas partes diferentes do dataset</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">view_sentence_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Estatísticas do dataset&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Numero de palavras unicas: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">({</span><span class="n">word</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">()})))</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">word_counts</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentences</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Numero aproximado de sentenças: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sentences</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Média de palavras por sentença: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">word_counts</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sentenças em inglês de </span><span class="si">{}</span><span class="s2"> a </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sentenças em francês de </span><span class="si">{}</span><span class="s1"> a </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="o">*</span><span class="n">view_sentence_range</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)[</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">view_sentence_range</span><span class="p">[</span><span class="mi">1</span><span class="p">]]))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Estatísticas do dataset
Numero de palavras unicas: 227
Numero aproximado de sentenças: 137861
Média de palavras por sentença: 13.225277634719028

Sentenças em inglês de 0 a 10
new jersey is sometimes quiet during autumn , and it is snowy in april .
the united states is usually chilly during july , and it is usually freezing in november .
california is usually quiet during march , and it is usually hot in june .
the united states is sometimes mild during june , and it is cold in september .
your least liked fruit is the grape , but my least liked is the apple .
his favorite fruit is the orange , but my favorite is the grape .
paris is relaxing during december , but it is usually chilly in july .
new jersey is busy during spring , and it is never hot in march .
our least liked fruit is the lemon , but my least liked is the grape .
the united states is sometimes busy during january , and it is sometimes warm in november .

Sentenças em francês de 0 a 10:
new jersey est parfois calme pendant l&#39; automne , et il est neigeux en avril .
les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .
california est généralement calme en mars , et il est généralement chaud en juin .
les états-unis est parfois légère en juin , et il fait froid en septembre .
votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .
son fruit préféré est l&#39;orange , mais mon préféré est le raisin .
paris est relaxant en décembre , mais il est généralement froid en juillet .
new jersey est occupé au printemps , et il est jamais chaude en mars .
notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .
les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementar-fun&#231;&#227;o-de-pre-processamento">Implementar fun&#231;&#227;o de pre processamento<a class="anchor-link" href="#Implementar-fun&#231;&#227;o-de-pre-processamento">&#182;</a></h2><h3 id="Texto-para-ID">Texto para ID<a class="anchor-link" href="#Texto-para-ID">&#182;</a></h3><p>Assim com é feito em outras RNNs, os textos devem ser transformados em numeros para que o computador possa entende-los.
Na função <code>text_to_ids()</code>, o <code>source_text</code> e <code>target_text</code> serão passados de textos para ids. Para isso é preciso adicionar a palavra <code>&lt;EOS&gt;</code>  e id no final de <code>target_text</code>. Isto ajudará a rede neural a prever quando a sentença deve terminar.</p>
<p>É possivel pegar o id da palavra  <code>&lt;EOS&gt;</code> através do comando :</p>
<ul>
<li><code>target_vocab_to_int['&lt;EOS&gt;']</code></li>
</ul>
<p>Pode pegar outros ids de plavara utilizando  <code>source_vocab_to_int</code> and <code>target_vocab_to_int</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">text_to_ids</span><span class="p">(</span><span class="n">source_text</span><span class="p">,</span> <span class="n">target_text</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
 
    <span class="n">source_id_text</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">indice</span><span class="p">,</span> <span class="n">linha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">source_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="n">source_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">palavra</span>  <span class="ow">in</span> <span class="n">linha</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">source_id_text</span><span class="p">[</span><span class="n">indice</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">[</span><span class="n">palavra</span><span class="p">])</span>
            
    <span class="n">target_id_text</span> <span class="o">=</span><span class="p">[]</span>
    <span class="k">for</span> <span class="n">indice</span><span class="p">,</span> <span class="n">linha</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">target_text</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">)):</span>
        <span class="n">target_id_text</span><span class="o">.</span><span class="n">append</span><span class="p">([])</span>
        <span class="k">for</span> <span class="n">palavra</span> <span class="ow">in</span> <span class="n">linha</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
            <span class="n">target_id_text</span><span class="p">[</span><span class="n">indice</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="n">palavra</span><span class="p">])</span>
        <span class="n">target_id_text</span><span class="p">[</span><span class="n">indice</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">source_id_text</span><span class="p">,</span> <span class="n">target_id_text</span><span class="p">)</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_text_to_ids</span><span class="p">(</span><span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Processar-e-salvar-todos-os-dados">Processar e salvar todos os dados<a class="anchor-link" href="#Processar-e-salvar-todos-os-dados">&#182;</a></h3><p>Rodar este bloco para processar e salvar todos os dados em um arquivo</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">helper</span><span class="o">.</span><span class="n">preprocess_and_save_data</span><span class="p">(</span><span class="n">source_path</span><span class="p">,</span> <span class="n">target_path</span><span class="p">,</span> <span class="n">text_to_ids</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Check-Point">Check Point<a class="anchor-link" href="#Check-Point">&#182;</a></h1><p>Este é o primeiro check point. Se decidir restartar o noteboook, poderá começar daqui. O processamento dos dados foi salvo para o disco.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[8]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Verificar-vers&#227;o-do-TensorFlow-e-acesso-a-GPU">Verificar vers&#227;o do TensorFlow e acesso a GPU<a class="anchor-link" href="#Verificar-vers&#227;o-do-TensorFlow-e-acesso-a-GPU">&#182;</a></h3><p>Este bloco checará se a versão do Tensorflow está correta, e se você possui acesso a GPU</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[9]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">distutils.version</span> <span class="k">import</span> <span class="n">LooseVersion</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.layers.core</span> <span class="k">import</span> <span class="n">Dense</span>

<span class="c1"># Check TensorFlow Version</span>
<span class="k">assert</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">LooseVersion</span><span class="p">(</span><span class="s1">&#39;1.1&#39;</span><span class="p">),</span> <span class="s1">&#39;Please use TensorFlow version 1.1 or newer&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;TensorFlow Version: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">__version__</span><span class="p">))</span>

<span class="c1"># Check for a GPU</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">():</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="s1">&#39;GPU Não encontrada. Por favor utilize uma GPU para treinar a rede neural.&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Default GPU Device: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">gpu_device_name</span><span class="p">()))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>TensorFlow Version: 1.8.0
</pre>
</div>
</div>

<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stderr output_text">
<pre>C:\Users\dudu_\Anaconda3\lib\site-packages\ipykernel\__main__.py:12: UserWarning: GPU Não encontrada. Por favor utilize uma GPU para treinar a rede neural.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Construir-a-Rede-Neural">Construir a Rede Neural<a class="anchor-link" href="#Construir-a-Rede-Neural">&#182;</a></h2><p>Construção dos componentes necessários para construir um modelo Sequence-to-Sequence (Seq2Seq) implementando as funções abaixo:</p>
<ul>
<li><code>model_inputs</code></li>
<li><code>process_decoder_input</code></li>
<li><code>encoding_layer</code></li>
<li><code>decoding_layer_train</code></li>
<li><code>decoding_layer_infer</code></li>
<li><code>decoding_layer</code></li>
<li><code>seq2seq_model</code></li>
</ul>
<h3 id="Input">Input<a class="anchor-link" href="#Input">&#182;</a></h3><p>Implemente a função <code>model_inputs()</code> para criar os TF Placeholders para a rede neural. Devem ser criados os seguintes placeholders:</p>
<ul>
<li>Input text placeholder named "input" using the TF Placeholder name parameter with rank 2.</li>
<li>Targets placeholder with rank 2.</li>
<li>Learning rate placeholder with rank 0.</li>
<li>Keep probability placeholder named "keep_prob" using the TF Placeholder name parameter with rank 0.</li>
<li>Target sequence length placeholder named "target_sequence_length" with rank 1</li>
<li>Max target sequence length tensor named "max_target_len" getting its value from applying tf.reduce_max on the target_sequence_length placeholder. Rank 0.</li>
<li>Source sequence length placeholder named "source_sequence_length" with rank 1</li>
</ul>
<p>Retornar os placeholders de acordo com a seguinte tupla (input, targets, learning_rate, keep_prob, target_sequence_len, max_target_sequence_len, source_sequence_len)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">model_inputs</span><span class="p">():</span>
    
    <span class="n">inputs</span> <span class="o">=</span>  <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;targets&#39;</span><span class="p">)</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;learning_rate&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;keep_prob&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;target_sequence_length&quot;</span><span class="p">)</span>
    <span class="n">max_target_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span> <span class="s1">&#39;max_target_len&#39;</span><span class="p">)</span>
    
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span> <span class="s2">&quot;source_sequence_length&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_length</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">)</span>
    
<span class="n">tests</span><span class="o">.</span><span class="n">test_model_inputs</span><span class="p">(</span><span class="n">model_inputs</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Processar-Decode-do-Input">Processar Decode do Input<a class="anchor-link" href="#Processar-Decode-do-Input">&#182;</a></h4><p>Implemente a função <code>process_decoder_input</code> removendo o ultimo id da palavra para cada batch em <code>target_data</code> e concatenar com o id de <GO> para iniciar cada batch</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>

    <span class="n">id_go</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
    <span class="n">t_data</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">id_go</span><span class="p">,</span> <span class="n">target_data</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span><span class="mi">1</span><span class="p">)</span>    
    <span class="k">return</span> <span class="n">t_data</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_process_encoding_input</span><span class="p">(</span><span class="n">process_decoder_input</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Encoding">Encoding<a class="anchor-link" href="#Encoding">&#182;</a></h3><p>Implementar função <code>encoding_layer()</code> Para criar uma camada de RNN</p>
<ul>
<li><p>Embed the encoder input using <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/layers/embed_sequence"><code>tf.contrib.layers.embed_sequence</code></a></p>
</li>
<li><p>Construct a <a href="https://github.com/tensorflow/tensorflow/blob/6947f65a374ebf29e74bb71e36fd82760056d82c/tensorflow/docs_src/tutorials/recurrent.md#stacking-multiple-lstms">stacked</a> <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/LSTMCell"><code>tf.contrib.rnn.LSTMCell</code></a> wrapped in a <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/DropoutWrapper"><code>tf.contrib.rnn.DropoutWrapper</code></a></p>
</li>
<li>Pass cell and embedded input to <a href="https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn"><code>tf.nn.dynamic_rnn()</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">imp</span> <span class="k">import</span> <span class="n">reload</span>
<span class="n">reload</span><span class="p">(</span><span class="n">tests</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">encoding_layer</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">encoding_embedding_size</span><span class="p">):</span>
    
    
    <span class="k">def</span> <span class="nf">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">lstm_dropout</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lstm_dropout</span>
    
    <span class="c1"># Criando celula multicamada RNN</span>
    <span class="n">stacked_lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="c1"># Criando camada embed</span>
    <span class="n">embed_encoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">embed_sequence</span><span class="p">(</span><span class="n">rnn_inputs</span><span class="p">,</span> <span class="n">vocab_size</span> <span class="o">=</span> <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">embed_dim</span> <span class="o">=</span> <span class="n">encoding_embedding_size</span><span class="p">)</span>
    
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dynamic_rnn</span><span class="p">(</span><span class="n">stacked_lstm</span><span class="p">,</span> <span class="n">embed_encoder</span><span class="p">,</span> <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_encoding_layer</span><span class="p">(</span><span class="n">encoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Training">Decoding - Training<a class="anchor-link" href="#Decoding---Training">&#182;</a></h3><p>Criar uma camada de decodificação de treinamento:</p>
<ul>
<li>Criar um <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/TrainingHelper"><code>tf.contrib.seq2seq.TrainingHelper</code></a> </li>
<li>Criar um <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obter decoder outputs de <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_train</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_summary_length</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>

    <span class="n">training</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">TrainingHelper</span><span class="p">(</span><span class="n">dec_embed_input</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">training</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">dumy_1</span><span class="p">,</span> <span class="n">dummy_2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span> <span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_summary_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_train</span><span class="p">(</span><span class="n">decoding_layer_train</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Decoding---Inference">Decoding - Inference<a class="anchor-link" href="#Decoding---Inference">&#182;</a></h3><p>Criar decodificador de inferencia :</p>
<ul>
<li>Criar um <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/GreedyEmbeddingHelper"><code>tf.contrib.seq2seq.GreedyEmbeddingHelper</code></a></li>
<li>Criar um<a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BasicDecoder"><code>tf.contrib.seq2seq.BasicDecoder</code></a></li>
<li>Obter decoder outputs de <a href="https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_decode"><code>tf.contrib.seq2seq.dynamic_decode</code></a></li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer_infer</span><span class="p">(</span><span class="n">encoder_state</span><span class="p">,</span> <span class="n">dec_cell</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_of_sequence_id</span><span class="p">,</span>
                         <span class="n">end_of_sequence_id</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                         <span class="n">vocab_size</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
    
    
    <span class="n">start_id</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">tile</span><span class="p">([</span><span class="n">start_of_sequence_id</span><span class="p">],</span> <span class="p">[</span><span class="n">batch_size</span><span class="p">])</span>
   
    <span class="n">embedding</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">GreedyEmbeddingHelper</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">start_id</span><span class="p">,</span> <span class="n">end_of_sequence_id</span><span class="p">)</span>
    <span class="n">decoder</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">BasicDecoder</span><span class="p">(</span><span class="n">dec_cell</span><span class="p">,</span> <span class="n">embedding</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span> <span class="n">output_layer</span><span class="p">)</span>
    <span class="n">f_output</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">dynamic_decode</span><span class="p">(</span><span class="n">decoder</span><span class="p">,</span><span class="n">maximum_iterations</span><span class="o">=</span><span class="n">max_target_sequence_length</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f_output</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer_infer</span><span class="p">(</span><span class="n">decoding_layer_infer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Construir-a-camada-de-decodifica&#231;&#227;o">Construir a camada de decodifica&#231;&#227;o<a class="anchor-link" href="#Construir-a-camada-de-decodifica&#231;&#227;o">&#182;</a></h3><p>Implementar função <code>decoding_layer()</code> para criar uma camada decodificador RNN.</p>
<ul>
<li>Incorporar as sequências de destino</li>
<li>Construa a célula LSTM do decodificador (assim como você construiu a célula do encoder acima)</li>
<li>Crie uma camada de saída para mapear as saídas do decodificador para os elementos do nosso vocabulário</li>
<li>Use a função <code>decoding_layer_train (encoder_state, dec_cell, dec_embed_input, target_sequence_length, max_target_sequence_length, output_layer, keep_prob)</code> para obter os logits de treinamento.</li>
<li>Use sua função <code>decoding_layer_infer (encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, max_target_sequence_length, vocab_size, output_layer, batch_size, keep_prob)</code> para obter os logits de inferência.</li>
</ul>
<p>Nota: Você precisará usar [tf.variable_scope] (<a href="https://www.tensorflow.org/api_docs/python/tf/variable_scope">https://www.tensorflow.org/api_docs/python/tf/variable_scope</a>) para compartilhar variáveis ​​entre treinamento e inferência.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">decoding_layer</span><span class="p">(</span><span class="n">dec_input</span><span class="p">,</span> <span class="n">encoder_state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span>
                   <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create decoding layer</span>
<span class="sd">    :param dec_input: Decoder input</span>
<span class="sd">    :param encoder_state: Encoder state</span>
<span class="sd">    :param target_sequence_length: The lengths of each sequence in the target batch</span>
<span class="sd">    :param max_target_sequence_length: Maximum length of target sequences</span>
<span class="sd">    :param rnn_size: RNN Size</span>
<span class="sd">    :param num_layers: Number of layers</span>
<span class="sd">    :param target_vocab_to_int: Dictionary to go from the target words to an id</span>
<span class="sd">    :param target_vocab_size: Size of target vocabulary</span>
<span class="sd">    :param batch_size: The size of the batch</span>
<span class="sd">    :param keep_prob: Dropout keep probability</span>
<span class="sd">    :param decoding_embedding_size: Decoding embedding size</span>
<span class="sd">    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Use the same proess as in the encoding layer.</span>
    <span class="k">def</span> <span class="nf">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">):</span>
        <span class="n">lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">)</span>
        <span class="n">lstm_drop</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">DropoutWrapper</span><span class="p">(</span><span class="n">lstm</span><span class="p">,</span> <span class="n">output_keep_prob</span><span class="o">=</span><span class="n">keep_prob</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lstm_drop</span>
    <span class="c1"># Stack them all</span>
    <span class="n">stacked_lstm</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">MultiRNNCell</span><span class="p">([</span><span class="n">build_cell</span><span class="p">(</span><span class="n">rnn_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">)])</span>
    
    <span class="n">dec_embeddings</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="n">target_vocab_size</span><span class="p">,</span> <span class="n">decoding_embedding_size</span><span class="p">]))</span>
    <span class="n">dec_embed_input</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span><span class="n">dec_embeddings</span><span class="p">,</span> <span class="n">dec_input</span><span class="p">)</span>

    <span class="n">dense_layer</span> <span class="o">=</span> <span class="n">Dense</span><span class="p">(</span><span class="n">target_vocab_size</span><span class="p">,</span>
                         <span class="n">kernel_initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">truncated_normal_initializer</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.1</span><span class="p">))</span>
    
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s2">&quot;decode&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">scope</span><span class="p">:</span>
        <span class="n">tr_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_train</span><span class="p">(</span>
            <span class="n">encoder_state</span><span class="p">,</span> <span class="n">stacked_lstm</span><span class="p">,</span> <span class="n">dec_embed_input</span><span class="p">,</span> 
            <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
        <span class="n">scope</span><span class="o">.</span><span class="n">reuse_variables</span><span class="p">()</span>
        <span class="n">inf_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer_infer</span><span class="p">(</span>
            <span class="n">encoder_state</span><span class="p">,</span> <span class="n">stacked_lstm</span><span class="p">,</span> <span class="n">dec_embeddings</span><span class="p">,</span> 
            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;GO&gt;&#39;</span><span class="p">],</span> <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;EOS&gt;&#39;</span><span class="p">],</span> 
            <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span> 
            <span class="n">dense_layer</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tr_decoder_output</span><span class="p">,</span> <span class="n">inf_decoder_output</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">DON&#39;T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">tests</span><span class="o">.</span><span class="n">test_decoding_layer</span><span class="p">(</span><span class="n">decoding_layer</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Construa-a-Rede-Neural">Construa a Rede Neural<a class="anchor-link" href="#Construa-a-Rede-Neural">&#182;</a></h3><p>Aplique as funções implementadas abaixo para:</p>
<ul>
<li>Codifique a entrada usando seu <code>encoding_layer (rnn_inputs, rnn_size, num_layers, keep_prob, source_sequence_length, source_vocab_size, encoding_embedding_size)</code>.</li>
<li>Processar dados de destino usando sua função <code>process_decoder_input (target_data, target_vocab_to_int, batch_size)</code>.</li>
<li>Decodifique a entrada codificada usando sua função <code>decoding_layer (dec_input, enc_state, target_sequence_length, max_target_sentence_length, rnn_size, num_layers, target_vocab_to_int, target_vocab_size, batch_size, keep_prob, dec_embedding_size)</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">seq2seq_model</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">target_data</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                  <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span>
                  <span class="n">max_target_sentence_length</span><span class="p">,</span>
                  <span class="n">source_vocab_size</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                  <span class="n">enc_embedding_size</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">,</span>
                  <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">):</span>
    <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">encoding_layer</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> 
                   <span class="n">source_sequence_length</span><span class="p">,</span> <span class="n">source_vocab_size</span><span class="p">,</span> 
                   <span class="n">enc_embedding_size</span><span class="p">)</span>
    
    <span class="n">processed_input</span> <span class="o">=</span> <span class="n">process_decoder_input</span><span class="p">(</span><span class="n">target_data</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
    
    <span class="n">tr_decoder_output</span><span class="p">,</span> <span class="n">inf_decoder_output</span> <span class="o">=</span> <span class="n">decoding_layer</span><span class="p">(</span><span class="n">processed_input</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span>
                   <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sentence_length</span><span class="p">,</span>
                   <span class="n">rnn_size</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_size</span><span class="p">,</span>
                   <span class="n">batch_size</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">dec_embedding_size</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">tr_decoder_output</span><span class="p">,</span> <span class="n">inf_decoder_output</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_seq2seq_model</span><span class="p">(</span><span class="n">seq2seq_model</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Treinamento-em-Redes-Neurais">Treinamento em Redes Neurais<a class="anchor-link" href="#Treinamento-em-Redes-Neurais">&#182;</a></h2><h3 id="Hyperparameters">Hyperparameters<a class="anchor-link" href="#Hyperparameters">&#182;</a></h3><p>Ajuste os seguintes parâmetros:</p>
<ul>
<li>Defina "épocas" para o número de épocas.</li>
<li>Configure <code>batch_size</code> para o tamanho do lote.</li>
<li>Defina <code>rnn_size</code> para o tamanho dos RNNs.</li>
<li>Defina <code>num_layers</code> para o número de camadas.</li>
<li>Defina <code>encoding_embedding_size</code> com o tamanho da incorporação para o codificador.</li>
<li>Defina <code>decoding_embedding_size</code> com o tamanho da incorporação para o decodificador.</li>
<li>Configure <code>learning_rate</code> para a taxa de aprendizado.</li>
<li>Defina <code>keep_probability</code> para a probabilidade de dropout keep</li>
<li>Defina <code>display_step</code> para indicar quantos passos entre cada declaração de saída de depuração</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[25]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Number of Epochs</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="c1"># Batch Size</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">512</span>
<span class="c1"># RNN Size</span>
<span class="n">rnn_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Number of Layers</span>
<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">2</span>
<span class="c1"># Embedding Size</span>
<span class="n">encoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">decoding_embedding_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="c1"># Learning Rate</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.001</span>
<span class="c1"># Dropout Keep Probability</span>
<span class="n">keep_probability</span> <span class="o">=</span> <span class="mf">0.55</span>
<span class="n">display_step</span> <span class="o">=</span> <span class="kc">True</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Construir-o-grafo">Construir o grafo<a class="anchor-link" href="#Construir-o-grafo">&#182;</a></h3><p>Construa o grafo usando a rede neural que você implementou.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[26]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">save_path</span> <span class="o">=</span> <span class="s1">&#39;checkpoints/dev&#39;</span>
<span class="p">(</span><span class="n">source_int_text</span><span class="p">,</span> <span class="n">target_int_text</span><span class="p">),</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="n">_</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">max_target_sentence_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">source_int_text</span><span class="p">])</span>

<span class="n">train_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">train_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="n">input_data</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">keep_prob</span><span class="p">,</span> <span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">model_inputs</span><span class="p">()</span>

    <span class="c1">#sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name=&#39;sequence_length&#39;)</span>
    <span class="n">input_shape</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">input_data</span><span class="p">)</span>

    <span class="n">train_logits</span><span class="p">,</span> <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">seq2seq_model</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reverse</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span>
                                                   <span class="n">targets</span><span class="p">,</span>
                                                   <span class="n">keep_prob</span><span class="p">,</span>
                                                   <span class="n">batch_size</span><span class="p">,</span>
                                                   <span class="n">source_sequence_length</span><span class="p">,</span>
                                                   <span class="n">target_sequence_length</span><span class="p">,</span>
                                                   <span class="n">max_target_sequence_length</span><span class="p">,</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">),</span>
                                                   <span class="nb">len</span><span class="p">(</span><span class="n">target_vocab_to_int</span><span class="p">),</span>
                                                   <span class="n">encoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">decoding_embedding_size</span><span class="p">,</span>
                                                   <span class="n">rnn_size</span><span class="p">,</span>
                                                   <span class="n">num_layers</span><span class="p">,</span>
                                                   <span class="n">target_vocab_to_int</span><span class="p">)</span>


    <span class="n">training_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">train_logits</span><span class="o">.</span><span class="n">rnn_output</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;logits&#39;</span><span class="p">)</span>
    <span class="n">inference_logits</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">inference_logits</span><span class="o">.</span><span class="n">sample_id</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;predictions&#39;</span><span class="p">)</span>

    <span class="n">masks</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">sequence_mask</span><span class="p">(</span><span class="n">target_sequence_length</span><span class="p">,</span> <span class="n">max_target_sequence_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;masks&#39;</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">name_scope</span><span class="p">(</span><span class="s2">&quot;optimization&quot;</span><span class="p">):</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">seq2seq</span><span class="o">.</span><span class="n">sequence_loss</span><span class="p">(</span><span class="n">training_logits</span><span class="p">,</span><span class="n">targets</span><span class="p">,</span><span class="n">masks</span><span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
        <span class="n">gradients</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
        <span class="n">capped_gradients</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">gradients</span> <span class="k">if</span> <span class="n">grad</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">]</span>
        <span class="n">train_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_gradients</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Batch and pad the source and target sequences</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[27]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">pad_sentence_batch</span><span class="p">(</span><span class="n">sentence_batch</span><span class="p">,</span> <span class="n">pad_int</span><span class="p">):</span>
    <span class="n">max_sentence</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">sentence</span> <span class="o">+</span> <span class="p">[</span><span class="n">pad_int</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_sentence</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">))</span> <span class="k">for</span> <span class="n">sentence</span> <span class="ow">in</span> <span class="n">sentence_batch</span><span class="p">]</span>


<span class="k">def</span> <span class="nf">get_batches</span><span class="p">(</span><span class="n">sources</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">batch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sources</span><span class="p">)</span><span class="o">//</span><span class="n">batch_size</span><span class="p">):</span>
        <span class="n">start_i</span> <span class="o">=</span> <span class="n">batch_i</span> <span class="o">*</span> <span class="n">batch_size</span>

        <span class="n">sources_batch</span> <span class="o">=</span> <span class="n">sources</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
        <span class="n">targets_batch</span> <span class="o">=</span> <span class="n">targets</span><span class="p">[</span><span class="n">start_i</span><span class="p">:</span><span class="n">start_i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>

        <span class="n">pad_sources_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">sources_batch</span><span class="p">,</span> <span class="n">source_pad_int</span><span class="p">))</span>
        <span class="n">pad_targets_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pad_sentence_batch</span><span class="p">(</span><span class="n">targets_batch</span><span class="p">,</span> <span class="n">target_pad_int</span><span class="p">))</span>

        <span class="n">pad_targets_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">target</span> <span class="ow">in</span> <span class="n">pad_targets_batch</span><span class="p">:</span>
            <span class="n">pad_targets_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">target</span><span class="p">))</span>

        <span class="n">pad_source_lengths</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">source</span> <span class="ow">in</span> <span class="n">pad_sources_batch</span><span class="p">:</span>
            <span class="n">pad_source_lengths</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">))</span>

        <span class="k">yield</span> <span class="n">pad_sources_batch</span><span class="p">,</span> <span class="n">pad_targets_batch</span><span class="p">,</span> <span class="n">pad_source_lengths</span><span class="p">,</span> <span class="n">pad_targets_lengths</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Treinar">Treinar<a class="anchor-link" href="#Treinar">&#182;</a></h3><p>Treine a rede neural nos dados pré-processados. Se você tiver dificuldade em obter uma boa perda, verifique os formulários para ver se alguém está com o mesmo problema.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[28]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_accuracy</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate accuracy</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">max_seq</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
            <span class="n">logits</span><span class="p">,</span>
            <span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="n">max_seq</span> <span class="o">-</span> <span class="n">logits</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])],</span>
            <span class="s1">&#39;constant&#39;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">logits</span><span class="p">))</span>

<span class="c1"># Split data to training and validation sets</span>
<span class="n">train_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">train_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[</span><span class="n">batch_size</span><span class="p">:]</span>
<span class="n">valid_source</span> <span class="o">=</span> <span class="n">source_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="n">valid_target</span> <span class="o">=</span> <span class="n">target_int_text</span><span class="p">[:</span><span class="n">batch_size</span><span class="p">]</span>
<span class="p">(</span><span class="n">valid_sources_batch</span><span class="p">,</span> <span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">valid_sources_lengths</span><span class="p">,</span> <span class="n">valid_targets_lengths</span> <span class="p">)</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">get_batches</span><span class="p">(</span><span class="n">valid_source</span><span class="p">,</span>
                                                                                                             <span class="n">valid_target</span><span class="p">,</span>
                                                                                                             <span class="n">batch_size</span><span class="p">,</span>
                                                                                                             <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                                                                                                             <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">]))</span>                                                                                                  
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">train_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">epoch_i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">batch_i</span><span class="p">,</span> <span class="p">(</span><span class="n">source_batch</span><span class="p">,</span> <span class="n">target_batch</span><span class="p">,</span> <span class="n">sources_lengths</span><span class="p">,</span> <span class="n">targets_lengths</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span>
                <span class="n">get_batches</span><span class="p">(</span><span class="n">train_source</span><span class="p">,</span> <span class="n">train_target</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span>
                            <span class="n">source_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">],</span>
                            <span class="n">target_vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;PAD&gt;&#39;</span><span class="p">])):</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_op</span><span class="p">,</span> <span class="n">cost</span><span class="p">],</span>
                <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                 <span class="n">targets</span><span class="p">:</span> <span class="n">target_batch</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                 <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                 <span class="n">keep_prob</span><span class="p">:</span> <span class="n">keep_probability</span><span class="p">})</span>


            <span class="k">if</span> <span class="n">batch_i</span> <span class="o">%</span> <span class="n">display_step</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch_i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>


                <span class="n">batch_train_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">source_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>


                <span class="n">batch_valid_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">inference_logits</span><span class="p">,</span>
                    <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="n">valid_sources_batch</span><span class="p">,</span>
                     <span class="n">source_sequence_length</span><span class="p">:</span> <span class="n">valid_sources_lengths</span><span class="p">,</span>
                     <span class="n">target_sequence_length</span><span class="p">:</span> <span class="n">valid_targets_lengths</span><span class="p">,</span>
                     <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})</span>

                <span class="n">train_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">target_batch</span><span class="p">,</span> <span class="n">batch_train_logits</span><span class="p">)</span>

                <span class="n">valid_acc</span> <span class="o">=</span> <span class="n">get_accuracy</span><span class="p">(</span><span class="n">valid_targets_batch</span><span class="p">,</span> <span class="n">batch_valid_logits</span><span class="p">)</span>

                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{:&gt;3}</span><span class="s1"> Batch </span><span class="si">{:&gt;4}</span><span class="s1">/</span><span class="si">{}</span><span class="s1"> - Train Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Validation Accuracy: </span><span class="si">{:&gt;6.4f}</span><span class="s1">, Loss: </span><span class="si">{:&gt;6.4f}</span><span class="s1">&#39;</span>
                      <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch_i</span><span class="p">,</span> <span class="n">batch_i</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source_int_text</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">valid_acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

    <span class="c1"># Save Model</span>
    <span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>
    <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Modelo treinado e salvo&#39;</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch   0 Batch    1/269 - Train Accuracy: 0.2329, Validation Accuracy: 0.3096, Loss: 5.7553
Epoch   0 Batch    2/269 - Train Accuracy: 0.2655, Validation Accuracy: 0.3096, Loss: 5.5650
Epoch   0 Batch    3/269 - Train Accuracy: 0.2444, Validation Accuracy: 0.3096, Loss: 5.4162
Epoch   0 Batch    4/269 - Train Accuracy: 0.2317, Validation Accuracy: 0.3096, Loss: 5.2458
Epoch   0 Batch    5/269 - Train Accuracy: 0.2325, Validation Accuracy: 0.3096, Loss: 5.0633
Epoch   0 Batch    6/269 - Train Accuracy: 0.2785, Validation Accuracy: 0.3096, Loss: 4.7383
Epoch   0 Batch    7/269 - Train Accuracy: 0.2765, Validation Accuracy: 0.3096, Loss: 4.5589
Epoch   0 Batch    8/269 - Train Accuracy: 0.2503, Validation Accuracy: 0.3182, Loss: 4.5569
Epoch   0 Batch    9/269 - Train Accuracy: 0.2797, Validation Accuracy: 0.3220, Loss: 4.3420
Epoch   0 Batch   10/269 - Train Accuracy: 0.2567, Validation Accuracy: 0.3312, Loss: 4.3775
Epoch   0 Batch   11/269 - Train Accuracy: 0.3034, Validation Accuracy: 0.3399, Loss: 4.1410
Epoch   0 Batch   12/269 - Train Accuracy: 0.2780, Validation Accuracy: 0.3411, Loss: 4.1765
Epoch   0 Batch   13/269 - Train Accuracy: 0.3434, Validation Accuracy: 0.3421, Loss: 3.7803
Epoch   0 Batch   14/269 - Train Accuracy: 0.3053, Validation Accuracy: 0.3428, Loss: 3.9039
Epoch   0 Batch   15/269 - Train Accuracy: 0.2961, Validation Accuracy: 0.3427, Loss: 3.8717
Epoch   0 Batch   16/269 - Train Accuracy: 0.3202, Validation Accuracy: 0.3513, Loss: 3.7362
Epoch   0 Batch   17/269 - Train Accuracy: 0.3142, Validation Accuracy: 0.3546, Loss: 3.6862
Epoch   0 Batch   18/269 - Train Accuracy: 0.3037, Validation Accuracy: 0.3726, Loss: 3.7862
Epoch   0 Batch   19/269 - Train Accuracy: 0.3714, Validation Accuracy: 0.3726, Loss: 3.4362
Epoch   0 Batch   20/269 - Train Accuracy: 0.3162, Validation Accuracy: 0.3788, Loss: 3.6703
Epoch   0 Batch   21/269 - Train Accuracy: 0.3172, Validation Accuracy: 0.3794, Loss: 3.6483
Epoch   0 Batch   22/269 - Train Accuracy: 0.3540, Validation Accuracy: 0.3802, Loss: 3.4180
Epoch   0 Batch   23/269 - Train Accuracy: 0.3638, Validation Accuracy: 0.3806, Loss: 3.3582
Epoch   0 Batch   24/269 - Train Accuracy: 0.3225, Validation Accuracy: 0.3840, Loss: 3.5003
Epoch   0 Batch   25/269 - Train Accuracy: 0.3373, Validation Accuracy: 0.3982, Loss: 3.4608
Epoch   0 Batch   26/269 - Train Accuracy: 0.4006, Validation Accuracy: 0.3999, Loss: 3.1375
Epoch   0 Batch   27/269 - Train Accuracy: 0.3712, Validation Accuracy: 0.4023, Loss: 3.2691
Epoch   0 Batch   28/269 - Train Accuracy: 0.3264, Validation Accuracy: 0.3987, Loss: 3.4221
Epoch   0 Batch   29/269 - Train Accuracy: 0.3327, Validation Accuracy: 0.3982, Loss: 3.3554
Epoch   0 Batch   30/269 - Train Accuracy: 0.3631, Validation Accuracy: 0.4010, Loss: 3.1867
Epoch   0 Batch   31/269 - Train Accuracy: 0.3802, Validation Accuracy: 0.4050, Loss: 3.1366
Epoch   0 Batch   32/269 - Train Accuracy: 0.3675, Validation Accuracy: 0.4041, Loss: 3.1620
Epoch   0 Batch   33/269 - Train Accuracy: 0.3788, Validation Accuracy: 0.4060, Loss: 3.0671
Epoch   0 Batch   34/269 - Train Accuracy: 0.3691, Validation Accuracy: 0.4006, Loss: 3.0679
Epoch   0 Batch   35/269 - Train Accuracy: 0.3743, Validation Accuracy: 0.4034, Loss: 3.0392
Epoch   0 Batch   36/269 - Train Accuracy: 0.3726, Validation Accuracy: 0.4013, Loss: 3.0443
Epoch   0 Batch   37/269 - Train Accuracy: 0.3785, Validation Accuracy: 0.4026, Loss: 3.0236
Epoch   0 Batch   38/269 - Train Accuracy: 0.3730, Validation Accuracy: 0.4047, Loss: 2.9975
Epoch   0 Batch   39/269 - Train Accuracy: 0.3697, Validation Accuracy: 0.4044, Loss: 2.9801
Epoch   0 Batch   40/269 - Train Accuracy: 0.3482, Validation Accuracy: 0.4116, Loss: 3.0902
Epoch   0 Batch   41/269 - Train Accuracy: 0.3714, Validation Accuracy: 0.4040, Loss: 2.9488
Epoch   0 Batch   42/269 - Train Accuracy: 0.4050, Validation Accuracy: 0.4076, Loss: 2.8156
Epoch   0 Batch   43/269 - Train Accuracy: 0.3523, Validation Accuracy: 0.4064, Loss: 3.0148
Epoch   0 Batch   44/269 - Train Accuracy: 0.3949, Validation Accuracy: 0.4188, Loss: 2.8758
Epoch   0 Batch   45/269 - Train Accuracy: 0.3613, Validation Accuracy: 0.4200, Loss: 3.0141
Epoch   0 Batch   46/269 - Train Accuracy: 0.3620, Validation Accuracy: 0.4278, Loss: 3.0447
Epoch   0 Batch   47/269 - Train Accuracy: 0.4328, Validation Accuracy: 0.4336, Loss: 2.7223
Epoch   0 Batch   48/269 - Train Accuracy: 0.4081, Validation Accuracy: 0.4302, Loss: 2.8093
Epoch   0 Batch   49/269 - Train Accuracy: 0.3771, Validation Accuracy: 0.4315, Loss: 2.9405
Epoch   0 Batch   50/269 - Train Accuracy: 0.3867, Validation Accuracy: 0.4380, Loss: 2.9182
Epoch   0 Batch   51/269 - Train Accuracy: 0.4037, Validation Accuracy: 0.4359, Loss: 2.8314
Epoch   0 Batch   52/269 - Train Accuracy: 0.4128, Validation Accuracy: 0.4378, Loss: 2.7652
Epoch   0 Batch   53/269 - Train Accuracy: 0.3876, Validation Accuracy: 0.4421, Loss: 2.8706
Epoch   0 Batch   54/269 - Train Accuracy: 0.3957, Validation Accuracy: 0.4451, Loss: 2.8691
Epoch   0 Batch   55/269 - Train Accuracy: 0.4191, Validation Accuracy: 0.4460, Loss: 2.7426
Epoch   0 Batch   56/269 - Train Accuracy: 0.4249, Validation Accuracy: 0.4482, Loss: 2.7137
Epoch   0 Batch   57/269 - Train Accuracy: 0.4268, Validation Accuracy: 0.4504, Loss: 2.6991
Epoch   0 Batch   58/269 - Train Accuracy: 0.4341, Validation Accuracy: 0.4541, Loss: 2.6920
Epoch   0 Batch   59/269 - Train Accuracy: 0.4303, Validation Accuracy: 0.4548, Loss: 2.6687
Epoch   0 Batch   60/269 - Train Accuracy: 0.4337, Validation Accuracy: 0.4481, Loss: 2.6057
Epoch   0 Batch   61/269 - Train Accuracy: 0.4568, Validation Accuracy: 0.4561, Loss: 2.5344
Epoch   0 Batch   62/269 - Train Accuracy: 0.4513, Validation Accuracy: 0.4487, Loss: 2.5640
Epoch   0 Batch   63/269 - Train Accuracy: 0.4385, Validation Accuracy: 0.4640, Loss: 2.6402
Epoch   0 Batch   64/269 - Train Accuracy: 0.4365, Validation Accuracy: 0.4654, Loss: 2.6364
Epoch   0 Batch   65/269 - Train Accuracy: 0.4151, Validation Accuracy: 0.4414, Loss: 2.6120
Epoch   0 Batch   66/269 - Train Accuracy: 0.4547, Validation Accuracy: 0.4645, Loss: 2.5563
Epoch   0 Batch   67/269 - Train Accuracy: 0.4355, Validation Accuracy: 0.4664, Loss: 2.6176
Epoch   0 Batch   68/269 - Train Accuracy: 0.4314, Validation Accuracy: 0.4590, Loss: 2.6052
Epoch   0 Batch   69/269 - Train Accuracy: 0.4108, Validation Accuracy: 0.4669, Loss: 2.7420
Epoch   0 Batch   70/269 - Train Accuracy: 0.4499, Validation Accuracy: 0.4672, Loss: 2.5455
Epoch   0 Batch   71/269 - Train Accuracy: 0.4224, Validation Accuracy: 0.4727, Loss: 2.7010
Epoch   0 Batch   72/269 - Train Accuracy: 0.4633, Validation Accuracy: 0.4734, Loss: 2.4625
Epoch   0 Batch   73/269 - Train Accuracy: 0.4530, Validation Accuracy: 0.4756, Loss: 2.5446
Epoch   0 Batch   74/269 - Train Accuracy: 0.4286, Validation Accuracy: 0.4754, Loss: 2.6188
Epoch   0 Batch   75/269 - Train Accuracy: 0.4499, Validation Accuracy: 0.4751, Loss: 2.5216
Epoch   0 Batch   76/269 - Train Accuracy: 0.4393, Validation Accuracy: 0.4712, Loss: 2.5677
Epoch   0 Batch   77/269 - Train Accuracy: 0.4606, Validation Accuracy: 0.4795, Loss: 2.5009
Epoch   0 Batch   78/269 - Train Accuracy: 0.4510, Validation Accuracy: 0.4803, Loss: 2.5199
Epoch   0 Batch   79/269 - Train Accuracy: 0.4489, Validation Accuracy: 0.4781, Loss: 2.4919
Epoch   0 Batch   80/269 - Train Accuracy: 0.4680, Validation Accuracy: 0.4822, Loss: 2.4154
Epoch   0 Batch   81/269 - Train Accuracy: 0.4563, Validation Accuracy: 0.4831, Loss: 2.4760
Epoch   0 Batch   82/269 - Train Accuracy: 0.4746, Validation Accuracy: 0.4862, Loss: 2.4112
Epoch   0 Batch   83/269 - Train Accuracy: 0.4688, Validation Accuracy: 0.4822, Loss: 2.3941
Epoch   0 Batch   84/269 - Train Accuracy: 0.4611, Validation Accuracy: 0.4814, Loss: 2.4268
Epoch   0 Batch   85/269 - Train Accuracy: 0.4575, Validation Accuracy: 0.4833, Loss: 2.4416
Epoch   0 Batch   86/269 - Train Accuracy: 0.4547, Validation Accuracy: 0.4804, Loss: 2.4370
Epoch   0 Batch   87/269 - Train Accuracy: 0.4278, Validation Accuracy: 0.4872, Loss: 2.5737
Epoch   0 Batch   88/269 - Train Accuracy: 0.4626, Validation Accuracy: 0.4822, Loss: 2.3802
Epoch   0 Batch   89/269 - Train Accuracy: 0.4676, Validation Accuracy: 0.4887, Loss: 2.3770
Epoch   0 Batch   90/269 - Train Accuracy: 0.4249, Validation Accuracy: 0.4788, Loss: 2.5123
Epoch   0 Batch   91/269 - Train Accuracy: 0.4559, Validation Accuracy: 0.4850, Loss: 2.3716
Epoch   0 Batch   92/269 - Train Accuracy: 0.4604, Validation Accuracy: 0.4855, Loss: 2.3528
Epoch   0 Batch   93/269 - Train Accuracy: 0.4799, Validation Accuracy: 0.4815, Loss: 2.2570
Epoch   0 Batch   94/269 - Train Accuracy: 0.4606, Validation Accuracy: 0.4857, Loss: 2.3591
Epoch   0 Batch   95/269 - Train Accuracy: 0.4600, Validation Accuracy: 0.4846, Loss: 2.3260
Epoch   0 Batch   96/269 - Train Accuracy: 0.4610, Validation Accuracy: 0.4882, Loss: 2.3235
Epoch   0 Batch   97/269 - Train Accuracy: 0.4643, Validation Accuracy: 0.4876, Loss: 2.3001
Epoch   0 Batch   98/269 - Train Accuracy: 0.4714, Validation Accuracy: 0.4862, Loss: 2.2675
Epoch   0 Batch   99/269 - Train Accuracy: 0.4331, Validation Accuracy: 0.4861, Loss: 2.4157
Epoch   0 Batch  100/269 - Train Accuracy: 0.4815, Validation Accuracy: 0.4841, Loss: 2.2227
Epoch   0 Batch  101/269 - Train Accuracy: 0.4330, Validation Accuracy: 0.4877, Loss: 2.3931
Epoch   0 Batch  102/269 - Train Accuracy: 0.4691, Validation Accuracy: 0.4932, Loss: 2.2584
Epoch   0 Batch  103/269 - Train Accuracy: 0.4727, Validation Accuracy: 0.4984, Loss: 2.2423
Epoch   0 Batch  104/269 - Train Accuracy: 0.4603, Validation Accuracy: 0.4954, Loss: 2.2526
Epoch   0 Batch  105/269 - Train Accuracy: 0.4569, Validation Accuracy: 0.4876, Loss: 2.2579
Epoch   0 Batch  106/269 - Train Accuracy: 0.4545, Validation Accuracy: 0.4893, Loss: 2.2509
Epoch   0 Batch  107/269 - Train Accuracy: 0.4296, Validation Accuracy: 0.4885, Loss: 2.3528
Epoch   0 Batch  108/269 - Train Accuracy: 0.4591, Validation Accuracy: 0.4859, Loss: 2.2174
Epoch   0 Batch  109/269 - Train Accuracy: 0.4612, Validation Accuracy: 0.4983, Loss: 2.2045
Epoch   0 Batch  110/269 - Train Accuracy: 0.4674, Validation Accuracy: 0.4998, Loss: 2.2002
Epoch   0 Batch  111/269 - Train Accuracy: 0.4424, Validation Accuracy: 0.5004, Loss: 2.3175
Epoch   0 Batch  112/269 - Train Accuracy: 0.4783, Validation Accuracy: 0.4992, Loss: 2.1678
Epoch   0 Batch  113/269 - Train Accuracy: 0.4913, Validation Accuracy: 0.4986, Loss: 2.0773
Epoch   0 Batch  114/269 - Train Accuracy: 0.4646, Validation Accuracy: 0.4988, Loss: 2.1553
Epoch   0 Batch  115/269 - Train Accuracy: 0.4499, Validation Accuracy: 0.4997, Loss: 2.2440
Epoch   0 Batch  116/269 - Train Accuracy: 0.4780, Validation Accuracy: 0.4999, Loss: 2.1489
Epoch   0 Batch  117/269 - Train Accuracy: 0.4686, Validation Accuracy: 0.5006, Loss: 2.1346
Epoch   0 Batch  118/269 - Train Accuracy: 0.4983, Validation Accuracy: 0.5013, Loss: 2.0657
Epoch   0 Batch  119/269 - Train Accuracy: 0.4632, Validation Accuracy: 0.5037, Loss: 2.2035
Epoch   0 Batch  120/269 - Train Accuracy: 0.4473, Validation Accuracy: 0.5017, Loss: 2.1947
Epoch   0 Batch  121/269 - Train Accuracy: 0.4761, Validation Accuracy: 0.4991, Loss: 2.0894
Epoch   0 Batch  122/269 - Train Accuracy: 0.4787, Validation Accuracy: 0.5021, Loss: 2.0595
Epoch   0 Batch  123/269 - Train Accuracy: 0.4480, Validation Accuracy: 0.5066, Loss: 2.1885
Epoch   0 Batch  124/269 - Train Accuracy: 0.4842, Validation Accuracy: 0.5078, Loss: 2.0609
Epoch   0 Batch  125/269 - Train Accuracy: 0.4776, Validation Accuracy: 0.5070, Loss: 2.0408
Epoch   0 Batch  126/269 - Train Accuracy: 0.4860, Validation Accuracy: 0.5055, Loss: 2.0219
Epoch   0 Batch  127/269 - Train Accuracy: 0.4540, Validation Accuracy: 0.5058, Loss: 2.1469
Epoch   0 Batch  128/269 - Train Accuracy: 0.4846, Validation Accuracy: 0.5062, Loss: 2.0133
Epoch   0 Batch  129/269 - Train Accuracy: 0.4778, Validation Accuracy: 0.5067, Loss: 2.0447
Epoch   0 Batch  130/269 - Train Accuracy: 0.4487, Validation Accuracy: 0.5067, Loss: 2.1590
Epoch   0 Batch  131/269 - Train Accuracy: 0.4685, Validation Accuracy: 0.5095, Loss: 2.0942
Epoch   0 Batch  132/269 - Train Accuracy: 0.4762, Validation Accuracy: 0.5096, Loss: 2.0244
Epoch   0 Batch  133/269 - Train Accuracy: 0.4856, Validation Accuracy: 0.5079, Loss: 1.9921
Epoch   0 Batch  134/269 - Train Accuracy: 0.4539, Validation Accuracy: 0.5059, Loss: 2.0573
Epoch   0 Batch  135/269 - Train Accuracy: 0.4461, Validation Accuracy: 0.5039, Loss: 2.0998
Epoch   0 Batch  136/269 - Train Accuracy: 0.4519, Validation Accuracy: 0.5076, Loss: 2.0722
Epoch   0 Batch  137/269 - Train Accuracy: 0.4610, Validation Accuracy: 0.5090, Loss: 2.0508
Epoch   0 Batch  138/269 - Train Accuracy: 0.4681, Validation Accuracy: 0.5059, Loss: 1.9895
Epoch   0 Batch  139/269 - Train Accuracy: 0.4904, Validation Accuracy: 0.5115, Loss: 1.9215
Epoch   0 Batch  140/269 - Train Accuracy: 0.4911, Validation Accuracy: 0.5109, Loss: 1.9250
Epoch   0 Batch  141/269 - Train Accuracy: 0.4731, Validation Accuracy: 0.5072, Loss: 1.9529
Epoch   0 Batch  142/269 - Train Accuracy: 0.4935, Validation Accuracy: 0.5085, Loss: 1.8985
Epoch   0 Batch  143/269 - Train Accuracy: 0.4909, Validation Accuracy: 0.5140, Loss: 1.9030
Epoch   0 Batch  144/269 - Train Accuracy: 0.4940, Validation Accuracy: 0.5177, Loss: 1.8883
Epoch   0 Batch  145/269 - Train Accuracy: 0.4876, Validation Accuracy: 0.5180, Loss: 1.8856
Epoch   0 Batch  146/269 - Train Accuracy: 0.4927, Validation Accuracy: 0.5134, Loss: 1.8575
Epoch   0 Batch  147/269 - Train Accuracy: 0.5064, Validation Accuracy: 0.5123, Loss: 1.7949
Epoch   0 Batch  148/269 - Train Accuracy: 0.4780, Validation Accuracy: 0.5098, Loss: 1.9043
Epoch   0 Batch  149/269 - Train Accuracy: 0.4837, Validation Accuracy: 0.5099, Loss: 1.8419
Epoch   0 Batch  150/269 - Train Accuracy: 0.4809, Validation Accuracy: 0.5116, Loss: 1.8525
Epoch   0 Batch  151/269 - Train Accuracy: 0.5133, Validation Accuracy: 0.5118, Loss: 1.7568
Epoch   0 Batch  152/269 - Train Accuracy: 0.4789, Validation Accuracy: 0.5123, Loss: 1.8299
Epoch   0 Batch  153/269 - Train Accuracy: 0.4931, Validation Accuracy: 0.5133, Loss: 1.8163
Epoch   0 Batch  154/269 - Train Accuracy: 0.4593, Validation Accuracy: 0.5181, Loss: 1.9128
Epoch   0 Batch  155/269 - Train Accuracy: 0.5056, Validation Accuracy: 0.5041, Loss: 1.7053
Epoch   0 Batch  156/269 - Train Accuracy: 0.4801, Validation Accuracy: 0.5225, Loss: 1.8547
Epoch   0 Batch  157/269 - Train Accuracy: 0.4820, Validation Accuracy: 0.5113, Loss: 1.8005
Epoch   0 Batch  158/269 - Train Accuracy: 0.4869, Validation Accuracy: 0.5148, Loss: 1.7654
Epoch   0 Batch  159/269 - Train Accuracy: 0.5034, Validation Accuracy: 0.5252, Loss: 1.7780
Epoch   0 Batch  160/269 - Train Accuracy: 0.4689, Validation Accuracy: 0.4976, Loss: 1.7980
Epoch   0 Batch  161/269 - Train Accuracy: 0.4847, Validation Accuracy: 0.5200, Loss: 1.8015
Epoch   0 Batch  162/269 - Train Accuracy: 0.4977, Validation Accuracy: 0.5218, Loss: 1.7501
Epoch   0 Batch  163/269 - Train Accuracy: 0.4716, Validation Accuracy: 0.4994, Loss: 1.7532
Epoch   0 Batch  164/269 - Train Accuracy: 0.4890, Validation Accuracy: 0.5178, Loss: 1.7643
Epoch   0 Batch  165/269 - Train Accuracy: 0.4631, Validation Accuracy: 0.5170, Loss: 1.8068
Epoch   0 Batch  166/269 - Train Accuracy: 0.5018, Validation Accuracy: 0.5036, Loss: 1.6411
Epoch   0 Batch  167/269 - Train Accuracy: 0.4913, Validation Accuracy: 0.5135, Loss: 1.7327
Epoch   0 Batch  168/269 - Train Accuracy: 0.4933, Validation Accuracy: 0.5215, Loss: 1.7343
Epoch   0 Batch  169/269 - Train Accuracy: 0.4910, Validation Accuracy: 0.5241, Loss: 1.7229
Epoch   0 Batch  170/269 - Train Accuracy: 0.4926, Validation Accuracy: 0.5210, Loss: 1.7052
Epoch   0 Batch  171/269 - Train Accuracy: 0.4797, Validation Accuracy: 0.5233, Loss: 1.7730
Epoch   0 Batch  172/269 - Train Accuracy: 0.4909, Validation Accuracy: 0.5199, Loss: 1.7165
Epoch   0 Batch  173/269 - Train Accuracy: 0.4759, Validation Accuracy: 0.5071, Loss: 1.6925
Epoch   0 Batch  174/269 - Train Accuracy: 0.4973, Validation Accuracy: 0.5234, Loss: 1.7002
Epoch   0 Batch  175/269 - Train Accuracy: 0.5007, Validation Accuracy: 0.5241, Loss: 1.6966
Epoch   0 Batch  176/269 - Train Accuracy: 0.4692, Validation Accuracy: 0.5156, Loss: 1.7565
Epoch   0 Batch  177/269 - Train Accuracy: 0.5119, Validation Accuracy: 0.5230, Loss: 1.6193
Epoch   0 Batch  178/269 - Train Accuracy: 0.4825, Validation Accuracy: 0.5256, Loss: 1.7367
Epoch   0 Batch  179/269 - Train Accuracy: 0.4985, Validation Accuracy: 0.5176, Loss: 1.6576
Epoch   0 Batch  180/269 - Train Accuracy: 0.5023, Validation Accuracy: 0.5227, Loss: 1.6431
Epoch   0 Batch  181/269 - Train Accuracy: 0.4926, Validation Accuracy: 0.5201, Loss: 1.6534
Epoch   0 Batch  182/269 - Train Accuracy: 0.4995, Validation Accuracy: 0.5243, Loss: 1.6468
Epoch   0 Batch  183/269 - Train Accuracy: 0.5625, Validation Accuracy: 0.5266, Loss: 1.4247
Epoch   0 Batch  184/269 - Train Accuracy: 0.4797, Validation Accuracy: 0.5257, Loss: 1.6949
Epoch   0 Batch  185/269 - Train Accuracy: 0.5121, Validation Accuracy: 0.5270, Loss: 1.6051
Epoch   0 Batch  186/269 - Train Accuracy: 0.4663, Validation Accuracy: 0.5206, Loss: 1.6945
Epoch   0 Batch  187/269 - Train Accuracy: 0.4988, Validation Accuracy: 0.5224, Loss: 1.5888
Epoch   0 Batch  188/269 - Train Accuracy: 0.5050, Validation Accuracy: 0.5234, Loss: 1.5654
Epoch   0 Batch  189/269 - Train Accuracy: 0.5026, Validation Accuracy: 0.5156, Loss: 1.5934
Epoch   0 Batch  190/269 - Train Accuracy: 0.5049, Validation Accuracy: 0.5379, Loss: 1.5990
Epoch   0 Batch  191/269 - Train Accuracy: 0.5018, Validation Accuracy: 0.5287, Loss: 1.6107
Epoch   0 Batch  192/269 - Train Accuracy: 0.5125, Validation Accuracy: 0.5308, Loss: 1.6009
Epoch   0 Batch  193/269 - Train Accuracy: 0.5047, Validation Accuracy: 0.5341, Loss: 1.5947
Epoch   0 Batch  194/269 - Train Accuracy: 0.5093, Validation Accuracy: 0.5289, Loss: 1.5936
Epoch   0 Batch  195/269 - Train Accuracy: 0.4875, Validation Accuracy: 0.5299, Loss: 1.6131
Epoch   0 Batch  196/269 - Train Accuracy: 0.5032, Validation Accuracy: 0.5413, Loss: 1.5693
Epoch   0 Batch  197/269 - Train Accuracy: 0.4655, Validation Accuracy: 0.5271, Loss: 1.6555
Epoch   0 Batch  198/269 - Train Accuracy: 0.4773, Validation Accuracy: 0.5330, Loss: 1.6683
Epoch   0 Batch  199/269 - Train Accuracy: 0.5012, Validation Accuracy: 0.5363, Loss: 1.5964
Epoch   0 Batch  200/269 - Train Accuracy: 0.4803, Validation Accuracy: 0.5187, Loss: 1.6261
Epoch   0 Batch  201/269 - Train Accuracy: 0.4990, Validation Accuracy: 0.5232, Loss: 1.5614
Epoch   0 Batch  202/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5365, Loss: 1.5703
Epoch   0 Batch  203/269 - Train Accuracy: 0.4792, Validation Accuracy: 0.5297, Loss: 1.6162
Epoch   0 Batch  204/269 - Train Accuracy: 0.4568, Validation Accuracy: 0.5158, Loss: 1.5943
Epoch   0 Batch  205/269 - Train Accuracy: 0.4957, Validation Accuracy: 0.5345, Loss: 1.5434
Epoch   0 Batch  206/269 - Train Accuracy: 0.4732, Validation Accuracy: 0.5332, Loss: 1.6305
Epoch   0 Batch  207/269 - Train Accuracy: 0.5166, Validation Accuracy: 0.5211, Loss: 1.4741
Epoch   0 Batch  208/269 - Train Accuracy: 0.4789, Validation Accuracy: 0.5331, Loss: 1.6308
Epoch   0 Batch  209/269 - Train Accuracy: 0.4940, Validation Accuracy: 0.5380, Loss: 1.5862
Epoch   0 Batch  210/269 - Train Accuracy: 0.5011, Validation Accuracy: 0.5223, Loss: 1.5159
Epoch   0 Batch  211/269 - Train Accuracy: 0.5044, Validation Accuracy: 0.5273, Loss: 1.5127
Epoch   0 Batch  212/269 - Train Accuracy: 0.5233, Validation Accuracy: 0.5363, Loss: 1.4806
Epoch   0 Batch  213/269 - Train Accuracy: 0.4986, Validation Accuracy: 0.5249, Loss: 1.4894
Epoch   0 Batch  214/269 - Train Accuracy: 0.5038, Validation Accuracy: 0.5257, Loss: 1.4962
Epoch   0 Batch  215/269 - Train Accuracy: 0.5380, Validation Accuracy: 0.5358, Loss: 1.4202
Epoch   0 Batch  216/269 - Train Accuracy: 0.4721, Validation Accuracy: 0.5312, Loss: 1.5951
Epoch   0 Batch  217/269 - Train Accuracy: 0.4672, Validation Accuracy: 0.5221, Loss: 1.5646
Epoch   0 Batch  218/269 - Train Accuracy: 0.4911, Validation Accuracy: 0.5298, Loss: 1.5615
Epoch   0 Batch  219/269 - Train Accuracy: 0.4904, Validation Accuracy: 0.5273, Loss: 1.5452
Epoch   0 Batch  220/269 - Train Accuracy: 0.5097, Validation Accuracy: 0.5210, Loss: 1.4286
Epoch   0 Batch  221/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5271, Loss: 1.4810
Epoch   0 Batch  222/269 - Train Accuracy: 0.5121, Validation Accuracy: 0.5282, Loss: 1.4258
Epoch   0 Batch  223/269 - Train Accuracy: 0.5053, Validation Accuracy: 0.5212, Loss: 1.4375
Epoch   0 Batch  224/269 - Train Accuracy: 0.5020, Validation Accuracy: 0.5166, Loss: 1.4756
Epoch   0 Batch  225/269 - Train Accuracy: 0.4837, Validation Accuracy: 0.5241, Loss: 1.5257
Epoch   0 Batch  226/269 - Train Accuracy: 0.4917, Validation Accuracy: 0.5217, Loss: 1.4607
Epoch   0 Batch  227/269 - Train Accuracy: 0.5632, Validation Accuracy: 0.5161, Loss: 1.2800
Epoch   0 Batch  228/269 - Train Accuracy: 0.4926, Validation Accuracy: 0.5244, Loss: 1.4752
Epoch   0 Batch  229/269 - Train Accuracy: 0.5011, Validation Accuracy: 0.5235, Loss: 1.4531
Epoch   0 Batch  230/269 - Train Accuracy: 0.4956, Validation Accuracy: 0.5224, Loss: 1.4521
Epoch   0 Batch  231/269 - Train Accuracy: 0.4680, Validation Accuracy: 0.5274, Loss: 1.5289
Epoch   0 Batch  232/269 - Train Accuracy: 0.4774, Validation Accuracy: 0.5266, Loss: 1.4973
Epoch   0 Batch  233/269 - Train Accuracy: 0.5043, Validation Accuracy: 0.5233, Loss: 1.4524
Epoch   0 Batch  234/269 - Train Accuracy: 0.5011, Validation Accuracy: 0.5231, Loss: 1.4441
Epoch   0 Batch  235/269 - Train Accuracy: 0.5103, Validation Accuracy: 0.5241, Loss: 1.4434
Epoch   0 Batch  236/269 - Train Accuracy: 0.5066, Validation Accuracy: 0.5358, Loss: 1.4210
Epoch   0 Batch  237/269 - Train Accuracy: 0.5086, Validation Accuracy: 0.5336, Loss: 1.4145
Epoch   0 Batch  238/269 - Train Accuracy: 0.5074, Validation Accuracy: 0.5283, Loss: 1.4179
Epoch   0 Batch  239/269 - Train Accuracy: 0.5102, Validation Accuracy: 0.5257, Loss: 1.3958
Epoch   0 Batch  240/269 - Train Accuracy: 0.5324, Validation Accuracy: 0.5212, Loss: 1.3156
Epoch   0 Batch  241/269 - Train Accuracy: 0.5051, Validation Accuracy: 0.5268, Loss: 1.4044
Epoch   0 Batch  242/269 - Train Accuracy: 0.5001, Validation Accuracy: 0.5314, Loss: 1.3990
Epoch   0 Batch  243/269 - Train Accuracy: 0.5107, Validation Accuracy: 0.5204, Loss: 1.3711
Epoch   0 Batch  244/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5227, Loss: 1.3752
Epoch   0 Batch  245/269 - Train Accuracy: 0.4841, Validation Accuracy: 0.5303, Loss: 1.4596
Epoch   0 Batch  246/269 - Train Accuracy: 0.5059, Validation Accuracy: 0.5324, Loss: 1.3936
Epoch   0 Batch  247/269 - Train Accuracy: 0.4883, Validation Accuracy: 0.5257, Loss: 1.4387
Epoch   0 Batch  248/269 - Train Accuracy: 0.5032, Validation Accuracy: 0.5281, Loss: 1.3827
Epoch   0 Batch  249/269 - Train Accuracy: 0.5349, Validation Accuracy: 0.5307, Loss: 1.3362
Epoch   0 Batch  250/269 - Train Accuracy: 0.4783, Validation Accuracy: 0.5147, Loss: 1.4171
Epoch   0 Batch  251/269 - Train Accuracy: 0.5170, Validation Accuracy: 0.5328, Loss: 1.3634
Epoch   0 Batch  252/269 - Train Accuracy: 0.4820, Validation Accuracy: 0.5157, Loss: 1.3904
Epoch   0 Batch  253/269 - Train Accuracy: 0.4690, Validation Accuracy: 0.4967, Loss: 1.3649
Epoch   0 Batch  254/269 - Train Accuracy: 0.5035, Validation Accuracy: 0.5249, Loss: 1.3443
Epoch   0 Batch  255/269 - Train Accuracy: 0.5365, Validation Accuracy: 0.5316, Loss: 1.3151
Epoch   0 Batch  256/269 - Train Accuracy: 0.4608, Validation Accuracy: 0.5030, Loss: 1.3775
Epoch   0 Batch  257/269 - Train Accuracy: 0.5041, Validation Accuracy: 0.5351, Loss: 1.3734
Epoch   0 Batch  258/269 - Train Accuracy: 0.5018, Validation Accuracy: 0.5336, Loss: 1.3658
Epoch   0 Batch  259/269 - Train Accuracy: 0.4993, Validation Accuracy: 0.5055, Loss: 1.3371
Epoch   0 Batch  260/269 - Train Accuracy: 0.5021, Validation Accuracy: 0.5413, Loss: 1.4124
Epoch   0 Batch  261/269 - Train Accuracy: 0.4807, Validation Accuracy: 0.5387, Loss: 1.4220
Epoch   0 Batch  262/269 - Train Accuracy: 0.5157, Validation Accuracy: 0.5328, Loss: 1.3494
Epoch   0 Batch  263/269 - Train Accuracy: 0.5123, Validation Accuracy: 0.5334, Loss: 1.3872
Epoch   0 Batch  264/269 - Train Accuracy: 0.4906, Validation Accuracy: 0.5277, Loss: 1.4035
Epoch   0 Batch  265/269 - Train Accuracy: 0.4840, Validation Accuracy: 0.5214, Loss: 1.3739
Epoch   0 Batch  266/269 - Train Accuracy: 0.5108, Validation Accuracy: 0.5277, Loss: 1.3114
Epoch   0 Batch  267/269 - Train Accuracy: 0.5073, Validation Accuracy: 0.5320, Loss: 1.3517
Epoch   1 Batch    1/269 - Train Accuracy: 0.4765, Validation Accuracy: 0.5289, Loss: 1.3692
Epoch   1 Batch    2/269 - Train Accuracy: 0.5060, Validation Accuracy: 0.5442, Loss: 1.3418
Epoch   1 Batch    3/269 - Train Accuracy: 0.5024, Validation Accuracy: 0.5398, Loss: 1.3657
Epoch   1 Batch    4/269 - Train Accuracy: 0.4821, Validation Accuracy: 0.5219, Loss: 1.3478
Epoch   1 Batch    5/269 - Train Accuracy: 0.4878, Validation Accuracy: 0.5370, Loss: 1.3620
Epoch   1 Batch    6/269 - Train Accuracy: 0.5318, Validation Accuracy: 0.5371, Loss: 1.2439
Epoch   1 Batch    7/269 - Train Accuracy: 0.5101, Validation Accuracy: 0.5246, Loss: 1.2766
Epoch   1 Batch    8/269 - Train Accuracy: 0.4981, Validation Accuracy: 0.5374, Loss: 1.3391
Epoch   1 Batch    9/269 - Train Accuracy: 0.5140, Validation Accuracy: 0.5366, Loss: 1.2883
Epoch   1 Batch   10/269 - Train Accuracy: 0.4919, Validation Accuracy: 0.5264, Loss: 1.3120
Epoch   1 Batch   11/269 - Train Accuracy: 0.5017, Validation Accuracy: 0.5237, Loss: 1.2881
Epoch   1 Batch   12/269 - Train Accuracy: 0.4814, Validation Accuracy: 0.5303, Loss: 1.3392
Epoch   1 Batch   13/269 - Train Accuracy: 0.5414, Validation Accuracy: 0.5395, Loss: 1.1874
Epoch   1 Batch   14/269 - Train Accuracy: 0.5051, Validation Accuracy: 0.5281, Loss: 1.2595
Epoch   1 Batch   15/269 - Train Accuracy: 0.5062, Validation Accuracy: 0.5394, Loss: 1.2715
Epoch   1 Batch   16/269 - Train Accuracy: 0.5253, Validation Accuracy: 0.5363, Loss: 1.2706
Epoch   1 Batch   17/269 - Train Accuracy: 0.5063, Validation Accuracy: 0.5208, Loss: 1.2430
Epoch   1 Batch   18/269 - Train Accuracy: 0.4873, Validation Accuracy: 0.5253, Loss: 1.3008
Epoch   1 Batch   19/269 - Train Accuracy: 0.5349, Validation Accuracy: 0.5289, Loss: 1.1903
Epoch   1 Batch   20/269 - Train Accuracy: 0.4973, Validation Accuracy: 0.5328, Loss: 1.2886
Epoch   1 Batch   21/269 - Train Accuracy: 0.5012, Validation Accuracy: 0.5335, Loss: 1.3244
Epoch   1 Batch   22/269 - Train Accuracy: 0.5270, Validation Accuracy: 0.5404, Loss: 1.2367
Epoch   1 Batch   23/269 - Train Accuracy: 0.5217, Validation Accuracy: 0.5337, Loss: 1.2472
Epoch   1 Batch   24/269 - Train Accuracy: 0.4871, Validation Accuracy: 0.5285, Loss: 1.2903
Epoch   1 Batch   25/269 - Train Accuracy: 0.4892, Validation Accuracy: 0.5281, Loss: 1.2967
Epoch   1 Batch   26/269 - Train Accuracy: 0.5439, Validation Accuracy: 0.5357, Loss: 1.1610
Epoch   1 Batch   27/269 - Train Accuracy: 0.5127, Validation Accuracy: 0.5384, Loss: 1.2329
Epoch   1 Batch   28/269 - Train Accuracy: 0.4921, Validation Accuracy: 0.5352, Loss: 1.3000
Epoch   1 Batch   29/269 - Train Accuracy: 0.5121, Validation Accuracy: 0.5447, Loss: 1.2683
Epoch   1 Batch   30/269 - Train Accuracy: 0.5381, Validation Accuracy: 0.5469, Loss: 1.2154
Epoch   1 Batch   31/269 - Train Accuracy: 0.5367, Validation Accuracy: 0.5436, Loss: 1.2152
Epoch   1 Batch   32/269 - Train Accuracy: 0.5226, Validation Accuracy: 0.5406, Loss: 1.2132
Epoch   1 Batch   33/269 - Train Accuracy: 0.5413, Validation Accuracy: 0.5431, Loss: 1.1812
Epoch   1 Batch   34/269 - Train Accuracy: 0.5236, Validation Accuracy: 0.5324, Loss: 1.2053
Epoch   1 Batch   35/269 - Train Accuracy: 0.5268, Validation Accuracy: 0.5312, Loss: 1.2062
Epoch   1 Batch   36/269 - Train Accuracy: 0.5212, Validation Accuracy: 0.5365, Loss: 1.2035
Epoch   1 Batch   37/269 - Train Accuracy: 0.5272, Validation Accuracy: 0.5417, Loss: 1.2117
Epoch   1 Batch   38/269 - Train Accuracy: 0.5268, Validation Accuracy: 0.5503, Loss: 1.2124
Epoch   1 Batch   39/269 - Train Accuracy: 0.5345, Validation Accuracy: 0.5446, Loss: 1.1785
Epoch   1 Batch   40/269 - Train Accuracy: 0.5083, Validation Accuracy: 0.5344, Loss: 1.2339
Epoch   1 Batch   41/269 - Train Accuracy: 0.5214, Validation Accuracy: 0.5360, Loss: 1.1906
Epoch   1 Batch   42/269 - Train Accuracy: 0.5512, Validation Accuracy: 0.5496, Loss: 1.1275
Epoch   1 Batch   43/269 - Train Accuracy: 0.5200, Validation Accuracy: 0.5513, Loss: 1.2203
Epoch   1 Batch   44/269 - Train Accuracy: 0.5506, Validation Accuracy: 0.5589, Loss: 1.1878
Epoch   1 Batch   45/269 - Train Accuracy: 0.5176, Validation Accuracy: 0.5535, Loss: 1.2275
Epoch   1 Batch   46/269 - Train Accuracy: 0.5251, Validation Accuracy: 0.5529, Loss: 1.2241
Epoch   1 Batch   47/269 - Train Accuracy: 0.5636, Validation Accuracy: 0.5562, Loss: 1.0957
Epoch   1 Batch   48/269 - Train Accuracy: 0.5354, Validation Accuracy: 0.5497, Loss: 1.1339
Epoch   1 Batch   49/269 - Train Accuracy: 0.5221, Validation Accuracy: 0.5439, Loss: 1.1949
Epoch   1 Batch   50/269 - Train Accuracy: 0.5155, Validation Accuracy: 0.5486, Loss: 1.2118
Epoch   1 Batch   51/269 - Train Accuracy: 0.5275, Validation Accuracy: 0.5544, Loss: 1.1770
Epoch   1 Batch   52/269 - Train Accuracy: 0.5305, Validation Accuracy: 0.5535, Loss: 1.1342
Epoch   1 Batch   53/269 - Train Accuracy: 0.5142, Validation Accuracy: 0.5515, Loss: 1.2087
Epoch   1 Batch   54/269 - Train Accuracy: 0.5261, Validation Accuracy: 0.5545, Loss: 1.1989
Epoch   1 Batch   55/269 - Train Accuracy: 0.5404, Validation Accuracy: 0.5526, Loss: 1.1365
Epoch   1 Batch   56/269 - Train Accuracy: 0.5505, Validation Accuracy: 0.5499, Loss: 1.1532
Epoch   1 Batch   57/269 - Train Accuracy: 0.5463, Validation Accuracy: 0.5514, Loss: 1.1534
Epoch   1 Batch   58/269 - Train Accuracy: 0.5398, Validation Accuracy: 0.5501, Loss: 1.1313
Epoch   1 Batch   59/269 - Train Accuracy: 0.5360, Validation Accuracy: 0.5494, Loss: 1.1093
Epoch   1 Batch   60/269 - Train Accuracy: 0.5455, Validation Accuracy: 0.5530, Loss: 1.0890
Epoch   1 Batch   61/269 - Train Accuracy: 0.5623, Validation Accuracy: 0.5550, Loss: 1.0647
Epoch   1 Batch   62/269 - Train Accuracy: 0.5531, Validation Accuracy: 0.5542, Loss: 1.0941
Epoch   1 Batch   63/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5559, Loss: 1.1343
Epoch   1 Batch   64/269 - Train Accuracy: 0.5299, Validation Accuracy: 0.5517, Loss: 1.1194
Epoch   1 Batch   65/269 - Train Accuracy: 0.5309, Validation Accuracy: 0.5441, Loss: 1.0989
Epoch   1 Batch   66/269 - Train Accuracy: 0.5391, Validation Accuracy: 0.5479, Loss: 1.0811
Epoch   1 Batch   67/269 - Train Accuracy: 0.5199, Validation Accuracy: 0.5489, Loss: 1.1269
Epoch   1 Batch   68/269 - Train Accuracy: 0.5174, Validation Accuracy: 0.5471, Loss: 1.1141
Epoch   1 Batch   69/269 - Train Accuracy: 0.5104, Validation Accuracy: 0.5479, Loss: 1.2042
Epoch   1 Batch   70/269 - Train Accuracy: 0.5505, Validation Accuracy: 0.5518, Loss: 1.1048
Epoch   1 Batch   71/269 - Train Accuracy: 0.5179, Validation Accuracy: 0.5533, Loss: 1.1611
Epoch   1 Batch   72/269 - Train Accuracy: 0.5504, Validation Accuracy: 0.5526, Loss: 1.0780
Epoch   1 Batch   73/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5558, Loss: 1.1265
Epoch   1 Batch   74/269 - Train Accuracy: 0.5316, Validation Accuracy: 0.5557, Loss: 1.1248
Epoch   1 Batch   75/269 - Train Accuracy: 0.5305, Validation Accuracy: 0.5520, Loss: 1.0885
Epoch   1 Batch   76/269 - Train Accuracy: 0.5166, Validation Accuracy: 0.5455, Loss: 1.1190
Epoch   1 Batch   77/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5463, Loss: 1.0862
Epoch   1 Batch   78/269 - Train Accuracy: 0.5327, Validation Accuracy: 0.5516, Loss: 1.0928
Epoch   1 Batch   79/269 - Train Accuracy: 0.5441, Validation Accuracy: 0.5521, Loss: 1.0797
Epoch   1 Batch   80/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5587, Loss: 1.0673
Epoch   1 Batch   81/269 - Train Accuracy: 0.5380, Validation Accuracy: 0.5603, Loss: 1.1085
Epoch   1 Batch   82/269 - Train Accuracy: 0.5504, Validation Accuracy: 0.5578, Loss: 1.0535
Epoch   1 Batch   83/269 - Train Accuracy: 0.5521, Validation Accuracy: 0.5491, Loss: 1.0611
Epoch   1 Batch   84/269 - Train Accuracy: 0.5307, Validation Accuracy: 0.5476, Loss: 1.0556
Epoch   1 Batch   85/269 - Train Accuracy: 0.5289, Validation Accuracy: 0.5466, Loss: 1.0732
Epoch   1 Batch   86/269 - Train Accuracy: 0.5052, Validation Accuracy: 0.5435, Loss: 1.0781
Epoch   1 Batch   87/269 - Train Accuracy: 0.4878, Validation Accuracy: 0.5417, Loss: 1.1519
Epoch   1 Batch   88/269 - Train Accuracy: 0.5236, Validation Accuracy: 0.5412, Loss: 1.0656
Epoch   1 Batch   89/269 - Train Accuracy: 0.5466, Validation Accuracy: 0.5519, Loss: 1.0595
Epoch   1 Batch   90/269 - Train Accuracy: 0.4950, Validation Accuracy: 0.5457, Loss: 1.1213
Epoch   1 Batch   91/269 - Train Accuracy: 0.5264, Validation Accuracy: 0.5537, Loss: 1.0485
Epoch   1 Batch   92/269 - Train Accuracy: 0.5356, Validation Accuracy: 0.5539, Loss: 1.0480
Epoch   1 Batch   93/269 - Train Accuracy: 0.5534, Validation Accuracy: 0.5550, Loss: 1.0170
Epoch   1 Batch   94/269 - Train Accuracy: 0.5266, Validation Accuracy: 0.5480, Loss: 1.0737
Epoch   1 Batch   95/269 - Train Accuracy: 0.5410, Validation Accuracy: 0.5455, Loss: 1.0580
Epoch   1 Batch   96/269 - Train Accuracy: 0.5390, Validation Accuracy: 0.5430, Loss: 1.0356
Epoch   1 Batch   97/269 - Train Accuracy: 0.5183, Validation Accuracy: 0.5392, Loss: 1.0501
Epoch   1 Batch   98/269 - Train Accuracy: 0.5454, Validation Accuracy: 0.5407, Loss: 1.0293
Epoch   1 Batch   99/269 - Train Accuracy: 0.5158, Validation Accuracy: 0.5516, Loss: 1.0912
Epoch   1 Batch  100/269 - Train Accuracy: 0.5485, Validation Accuracy: 0.5485, Loss: 1.0100
Epoch   1 Batch  101/269 - Train Accuracy: 0.5076, Validation Accuracy: 0.5486, Loss: 1.0903
Epoch   1 Batch  102/269 - Train Accuracy: 0.5323, Validation Accuracy: 0.5472, Loss: 1.0291
Epoch   1 Batch  103/269 - Train Accuracy: 0.5325, Validation Accuracy: 0.5586, Loss: 1.0336
Epoch   1 Batch  104/269 - Train Accuracy: 0.5417, Validation Accuracy: 0.5616, Loss: 1.0274
Epoch   1 Batch  105/269 - Train Accuracy: 0.5417, Validation Accuracy: 0.5624, Loss: 1.0412
Epoch   1 Batch  106/269 - Train Accuracy: 0.5365, Validation Accuracy: 0.5492, Loss: 1.0305
Epoch   1 Batch  107/269 - Train Accuracy: 0.4996, Validation Accuracy: 0.5535, Loss: 1.0784
Epoch   1 Batch  108/269 - Train Accuracy: 0.5443, Validation Accuracy: 0.5578, Loss: 1.0093
Epoch   1 Batch  109/269 - Train Accuracy: 0.5256, Validation Accuracy: 0.5607, Loss: 1.0366
Epoch   1 Batch  110/269 - Train Accuracy: 0.5477, Validation Accuracy: 0.5607, Loss: 1.0152
Epoch   1 Batch  111/269 - Train Accuracy: 0.5210, Validation Accuracy: 0.5588, Loss: 1.0958
Epoch   1 Batch  112/269 - Train Accuracy: 0.5556, Validation Accuracy: 0.5606, Loss: 1.0066
Epoch   1 Batch  113/269 - Train Accuracy: 0.5614, Validation Accuracy: 0.5556, Loss: 0.9756
Epoch   1 Batch  114/269 - Train Accuracy: 0.5293, Validation Accuracy: 0.5565, Loss: 1.0034
Epoch   1 Batch  115/269 - Train Accuracy: 0.5331, Validation Accuracy: 0.5645, Loss: 1.0361
Epoch   1 Batch  116/269 - Train Accuracy: 0.5572, Validation Accuracy: 0.5645, Loss: 1.0127
Epoch   1 Batch  117/269 - Train Accuracy: 0.5461, Validation Accuracy: 0.5644, Loss: 0.9964
Epoch   1 Batch  118/269 - Train Accuracy: 0.5669, Validation Accuracy: 0.5613, Loss: 0.9754
Epoch   1 Batch  119/269 - Train Accuracy: 0.5343, Validation Accuracy: 0.5603, Loss: 1.0517
Epoch   1 Batch  120/269 - Train Accuracy: 0.5228, Validation Accuracy: 0.5597, Loss: 1.0370
Epoch   1 Batch  121/269 - Train Accuracy: 0.5412, Validation Accuracy: 0.5572, Loss: 0.9780
Epoch   1 Batch  122/269 - Train Accuracy: 0.5505, Validation Accuracy: 0.5625, Loss: 0.9854
Epoch   1 Batch  123/269 - Train Accuracy: 0.5246, Validation Accuracy: 0.5619, Loss: 1.0356
Epoch   1 Batch  124/269 - Train Accuracy: 0.5558, Validation Accuracy: 0.5631, Loss: 0.9635
Epoch   1 Batch  125/269 - Train Accuracy: 0.5539, Validation Accuracy: 0.5601, Loss: 0.9605
Epoch   1 Batch  126/269 - Train Accuracy: 0.5576, Validation Accuracy: 0.5589, Loss: 0.9700
Epoch   1 Batch  127/269 - Train Accuracy: 0.5258, Validation Accuracy: 0.5630, Loss: 1.0351
Epoch   1 Batch  128/269 - Train Accuracy: 0.5708, Validation Accuracy: 0.5608, Loss: 0.9760
Epoch   1 Batch  129/269 - Train Accuracy: 0.5407, Validation Accuracy: 0.5660, Loss: 0.9939
Epoch   1 Batch  130/269 - Train Accuracy: 0.5278, Validation Accuracy: 0.5627, Loss: 1.0359
Epoch   1 Batch  131/269 - Train Accuracy: 0.5323, Validation Accuracy: 0.5621, Loss: 1.0100
Epoch   1 Batch  132/269 - Train Accuracy: 0.5427, Validation Accuracy: 0.5585, Loss: 0.9816
Epoch   1 Batch  133/269 - Train Accuracy: 0.5446, Validation Accuracy: 0.5549, Loss: 0.9553
Epoch   1 Batch  134/269 - Train Accuracy: 0.5090, Validation Accuracy: 0.5513, Loss: 1.0045
Epoch   1 Batch  135/269 - Train Accuracy: 0.5086, Validation Accuracy: 0.5568, Loss: 1.0415
Epoch   1 Batch  136/269 - Train Accuracy: 0.5110, Validation Accuracy: 0.5588, Loss: 1.0280
Epoch   1 Batch  137/269 - Train Accuracy: 0.5352, Validation Accuracy: 0.5575, Loss: 1.0110
Epoch   1 Batch  138/269 - Train Accuracy: 0.5295, Validation Accuracy: 0.5604, Loss: 0.9871
Epoch   1 Batch  139/269 - Train Accuracy: 0.5655, Validation Accuracy: 0.5608, Loss: 0.9353
Epoch   1 Batch  140/269 - Train Accuracy: 0.5525, Validation Accuracy: 0.5605, Loss: 0.9650
Epoch   1 Batch  141/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5596, Loss: 0.9773
Epoch   1 Batch  142/269 - Train Accuracy: 0.5447, Validation Accuracy: 0.5585, Loss: 0.9338
Epoch   1 Batch  143/269 - Train Accuracy: 0.5552, Validation Accuracy: 0.5629, Loss: 0.9629
Epoch   1 Batch  144/269 - Train Accuracy: 0.5427, Validation Accuracy: 0.5619, Loss: 0.9292
Epoch   1 Batch  145/269 - Train Accuracy: 0.5369, Validation Accuracy: 0.5552, Loss: 0.9474
Epoch   1 Batch  146/269 - Train Accuracy: 0.5352, Validation Accuracy: 0.5541, Loss: 0.9437
Epoch   1 Batch  147/269 - Train Accuracy: 0.5767, Validation Accuracy: 0.5549, Loss: 0.9071
Epoch   1 Batch  148/269 - Train Accuracy: 0.5293, Validation Accuracy: 0.5588, Loss: 0.9738
Epoch   1 Batch  149/269 - Train Accuracy: 0.5522, Validation Accuracy: 0.5625, Loss: 0.9496
Epoch   1 Batch  150/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5662, Loss: 0.9634
Epoch   1 Batch  151/269 - Train Accuracy: 0.5871, Validation Accuracy: 0.5629, Loss: 0.9156
Epoch   1 Batch  152/269 - Train Accuracy: 0.5468, Validation Accuracy: 0.5649, Loss: 0.9489
Epoch   1 Batch  153/269 - Train Accuracy: 0.5650, Validation Accuracy: 0.5698, Loss: 0.9315
Epoch   1 Batch  154/269 - Train Accuracy: 0.5225, Validation Accuracy: 0.5634, Loss: 0.9672
Epoch   1 Batch  155/269 - Train Accuracy: 0.5740, Validation Accuracy: 0.5611, Loss: 0.8898
Epoch   1 Batch  156/269 - Train Accuracy: 0.5357, Validation Accuracy: 0.5682, Loss: 0.9744
Epoch   1 Batch  157/269 - Train Accuracy: 0.5425, Validation Accuracy: 0.5634, Loss: 0.9368
Epoch   1 Batch  158/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5683, Loss: 0.9246
Epoch   1 Batch  159/269 - Train Accuracy: 0.5526, Validation Accuracy: 0.5681, Loss: 0.9374
Epoch   1 Batch  160/269 - Train Accuracy: 0.5503, Validation Accuracy: 0.5644, Loss: 0.9345
Epoch   1 Batch  161/269 - Train Accuracy: 0.5410, Validation Accuracy: 0.5641, Loss: 0.9346
Epoch   1 Batch  162/269 - Train Accuracy: 0.5449, Validation Accuracy: 0.5620, Loss: 0.9185
Epoch   1 Batch  163/269 - Train Accuracy: 0.5594, Validation Accuracy: 0.5671, Loss: 0.9166
Epoch   1 Batch  164/269 - Train Accuracy: 0.5565, Validation Accuracy: 0.5660, Loss: 0.9151
Epoch   1 Batch  165/269 - Train Accuracy: 0.5294, Validation Accuracy: 0.5629, Loss: 0.9401
Epoch   1 Batch  166/269 - Train Accuracy: 0.5746, Validation Accuracy: 0.5591, Loss: 0.8761
Epoch   1 Batch  167/269 - Train Accuracy: 0.5563, Validation Accuracy: 0.5599, Loss: 0.9193
Epoch   1 Batch  168/269 - Train Accuracy: 0.5433, Validation Accuracy: 0.5672, Loss: 0.9265
Epoch   1 Batch  169/269 - Train Accuracy: 0.5469, Validation Accuracy: 0.5661, Loss: 0.9198
Epoch   1 Batch  170/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5602, Loss: 0.9088
Epoch   1 Batch  171/269 - Train Accuracy: 0.5439, Validation Accuracy: 0.5624, Loss: 0.9501
Epoch   1 Batch  172/269 - Train Accuracy: 0.5540, Validation Accuracy: 0.5658, Loss: 0.9220
Epoch   1 Batch  173/269 - Train Accuracy: 0.5554, Validation Accuracy: 0.5672, Loss: 0.9048
Epoch   1 Batch  174/269 - Train Accuracy: 0.5504, Validation Accuracy: 0.5644, Loss: 0.9136
Epoch   1 Batch  175/269 - Train Accuracy: 0.5505, Validation Accuracy: 0.5631, Loss: 0.9194
Epoch   1 Batch  176/269 - Train Accuracy: 0.5407, Validation Accuracy: 0.5677, Loss: 0.9570
Epoch   1 Batch  177/269 - Train Accuracy: 0.5729, Validation Accuracy: 0.5695, Loss: 0.8744
Epoch   1 Batch  178/269 - Train Accuracy: 0.5381, Validation Accuracy: 0.5656, Loss: 0.9307
Epoch   1 Batch  179/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5658, Loss: 0.9063
Epoch   1 Batch  180/269 - Train Accuracy: 0.5481, Validation Accuracy: 0.5672, Loss: 0.8914
Epoch   1 Batch  181/269 - Train Accuracy: 0.5433, Validation Accuracy: 0.5713, Loss: 0.9041
Epoch   1 Batch  182/269 - Train Accuracy: 0.5587, Validation Accuracy: 0.5692, Loss: 0.9026
Epoch   1 Batch  183/269 - Train Accuracy: 0.6192, Validation Accuracy: 0.5643, Loss: 0.7839
Epoch   1 Batch  184/269 - Train Accuracy: 0.5348, Validation Accuracy: 0.5625, Loss: 0.9313
Epoch   1 Batch  185/269 - Train Accuracy: 0.5693, Validation Accuracy: 0.5703, Loss: 0.8898
Epoch   1 Batch  186/269 - Train Accuracy: 0.5266, Validation Accuracy: 0.5658, Loss: 0.9188
Epoch   1 Batch  187/269 - Train Accuracy: 0.5651, Validation Accuracy: 0.5605, Loss: 0.8746
Epoch   1 Batch  188/269 - Train Accuracy: 0.5607, Validation Accuracy: 0.5619, Loss: 0.8669
Epoch   1 Batch  189/269 - Train Accuracy: 0.5654, Validation Accuracy: 0.5660, Loss: 0.8708
Epoch   1 Batch  190/269 - Train Accuracy: 0.5504, Validation Accuracy: 0.5653, Loss: 0.8702
Epoch   1 Batch  191/269 - Train Accuracy: 0.5488, Validation Accuracy: 0.5617, Loss: 0.8811
Epoch   1 Batch  192/269 - Train Accuracy: 0.5550, Validation Accuracy: 0.5636, Loss: 0.8888
Epoch   1 Batch  193/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5727, Loss: 0.8893
Epoch   1 Batch  194/269 - Train Accuracy: 0.5757, Validation Accuracy: 0.5786, Loss: 0.8874
Epoch   1 Batch  195/269 - Train Accuracy: 0.5506, Validation Accuracy: 0.5763, Loss: 0.8899
Epoch   1 Batch  196/269 - Train Accuracy: 0.5380, Validation Accuracy: 0.5654, Loss: 0.8785
Epoch   1 Batch  197/269 - Train Accuracy: 0.5385, Validation Accuracy: 0.5722, Loss: 0.9177
Epoch   1 Batch  198/269 - Train Accuracy: 0.5428, Validation Accuracy: 0.5778, Loss: 0.9343
Epoch   1 Batch  199/269 - Train Accuracy: 0.5468, Validation Accuracy: 0.5724, Loss: 0.8931
Epoch   1 Batch  200/269 - Train Accuracy: 0.5459, Validation Accuracy: 0.5717, Loss: 0.9052
Epoch   1 Batch  201/269 - Train Accuracy: 0.5571, Validation Accuracy: 0.5738, Loss: 0.8726
Epoch   1 Batch  202/269 - Train Accuracy: 0.5657, Validation Accuracy: 0.5766, Loss: 0.8816
Epoch   1 Batch  203/269 - Train Accuracy: 0.5374, Validation Accuracy: 0.5731, Loss: 0.9274
Epoch   1 Batch  204/269 - Train Accuracy: 0.5535, Validation Accuracy: 0.5831, Loss: 0.9062
Epoch   1 Batch  205/269 - Train Accuracy: 0.5632, Validation Accuracy: 0.5837, Loss: 0.8591
Epoch   1 Batch  206/269 - Train Accuracy: 0.5425, Validation Accuracy: 0.5709, Loss: 0.9133
Epoch   1 Batch  207/269 - Train Accuracy: 0.5786, Validation Accuracy: 0.5607, Loss: 0.8452
Epoch   1 Batch  208/269 - Train Accuracy: 0.5272, Validation Accuracy: 0.5732, Loss: 0.9207
Epoch   1 Batch  209/269 - Train Accuracy: 0.5403, Validation Accuracy: 0.5771, Loss: 0.8872
Epoch   1 Batch  210/269 - Train Accuracy: 0.5701, Validation Accuracy: 0.5752, Loss: 0.8543
Epoch   1 Batch  211/269 - Train Accuracy: 0.5652, Validation Accuracy: 0.5722, Loss: 0.8699
Epoch   1 Batch  212/269 - Train Accuracy: 0.5879, Validation Accuracy: 0.5742, Loss: 0.8478
Epoch   1 Batch  213/269 - Train Accuracy: 0.5712, Validation Accuracy: 0.5764, Loss: 0.8502
Epoch   1 Batch  214/269 - Train Accuracy: 0.5720, Validation Accuracy: 0.5765, Loss: 0.8544
Epoch   1 Batch  215/269 - Train Accuracy: 0.5889, Validation Accuracy: 0.5784, Loss: 0.8006
Epoch   1 Batch  216/269 - Train Accuracy: 0.5416, Validation Accuracy: 0.5794, Loss: 0.9304
Epoch   1 Batch  217/269 - Train Accuracy: 0.5410, Validation Accuracy: 0.5812, Loss: 0.8906
Epoch   1 Batch  218/269 - Train Accuracy: 0.5570, Validation Accuracy: 0.5790, Loss: 0.8906
Epoch   1 Batch  219/269 - Train Accuracy: 0.5570, Validation Accuracy: 0.5763, Loss: 0.8898
Epoch   1 Batch  220/269 - Train Accuracy: 0.5780, Validation Accuracy: 0.5806, Loss: 0.8137
Epoch   1 Batch  221/269 - Train Accuracy: 0.5920, Validation Accuracy: 0.5854, Loss: 0.8498
Epoch   1 Batch  222/269 - Train Accuracy: 0.5868, Validation Accuracy: 0.5885, Loss: 0.8200
Epoch   1 Batch  223/269 - Train Accuracy: 0.5788, Validation Accuracy: 0.5851, Loss: 0.8192
Epoch   1 Batch  224/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.5882, Loss: 0.8727
Epoch   1 Batch  225/269 - Train Accuracy: 0.5651, Validation Accuracy: 0.5843, Loss: 0.8699
Epoch   1 Batch  226/269 - Train Accuracy: 0.5763, Validation Accuracy: 0.5840, Loss: 0.8517
Epoch   1 Batch  227/269 - Train Accuracy: 0.6340, Validation Accuracy: 0.5851, Loss: 0.7502
Epoch   1 Batch  228/269 - Train Accuracy: 0.5739, Validation Accuracy: 0.5875, Loss: 0.8475
Epoch   1 Batch  229/269 - Train Accuracy: 0.5714, Validation Accuracy: 0.5838, Loss: 0.8363
Epoch   1 Batch  230/269 - Train Accuracy: 0.5643, Validation Accuracy: 0.5747, Loss: 0.8457
Epoch   1 Batch  231/269 - Train Accuracy: 0.5433, Validation Accuracy: 0.5779, Loss: 0.8932
Epoch   1 Batch  232/269 - Train Accuracy: 0.5499, Validation Accuracy: 0.5903, Loss: 0.8857
Epoch   1 Batch  233/269 - Train Accuracy: 0.5864, Validation Accuracy: 0.5897, Loss: 0.8493
Epoch   1 Batch  234/269 - Train Accuracy: 0.5718, Validation Accuracy: 0.5849, Loss: 0.8486
Epoch   1 Batch  235/269 - Train Accuracy: 0.5748, Validation Accuracy: 0.5790, Loss: 0.8323
Epoch   1 Batch  236/269 - Train Accuracy: 0.5598, Validation Accuracy: 0.5898, Loss: 0.8363
Epoch   1 Batch  237/269 - Train Accuracy: 0.5772, Validation Accuracy: 0.5955, Loss: 0.8309
Epoch   1 Batch  238/269 - Train Accuracy: 0.5959, Validation Accuracy: 0.5908, Loss: 0.8366
Epoch   1 Batch  239/269 - Train Accuracy: 0.5863, Validation Accuracy: 0.5838, Loss: 0.8259
Epoch   1 Batch  240/269 - Train Accuracy: 0.6020, Validation Accuracy: 0.5807, Loss: 0.7712
Epoch   1 Batch  241/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.5938, Loss: 0.8448
Epoch   1 Batch  242/269 - Train Accuracy: 0.5721, Validation Accuracy: 0.5920, Loss: 0.8256
Epoch   1 Batch  243/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.5920, Loss: 0.8024
Epoch   1 Batch  244/269 - Train Accuracy: 0.5718, Validation Accuracy: 0.5880, Loss: 0.8249
Epoch   1 Batch  245/269 - Train Accuracy: 0.5767, Validation Accuracy: 0.5915, Loss: 0.8733
Epoch   1 Batch  246/269 - Train Accuracy: 0.5700, Validation Accuracy: 0.5940, Loss: 0.8397
Epoch   1 Batch  247/269 - Train Accuracy: 0.5725, Validation Accuracy: 0.5953, Loss: 0.8598
Epoch   1 Batch  248/269 - Train Accuracy: 0.5813, Validation Accuracy: 0.5952, Loss: 0.8153
Epoch   1 Batch  249/269 - Train Accuracy: 0.6077, Validation Accuracy: 0.5892, Loss: 0.7878
Epoch   1 Batch  250/269 - Train Accuracy: 0.5605, Validation Accuracy: 0.5856, Loss: 0.8465
Epoch   1 Batch  251/269 - Train Accuracy: 0.5969, Validation Accuracy: 0.5890, Loss: 0.8078
Epoch   1 Batch  252/269 - Train Accuracy: 0.5865, Validation Accuracy: 0.5991, Loss: 0.8283
Epoch   1 Batch  253/269 - Train Accuracy: 0.5762, Validation Accuracy: 0.5981, Loss: 0.8317
Epoch   1 Batch  254/269 - Train Accuracy: 0.5901, Validation Accuracy: 0.5961, Loss: 0.8159
Epoch   1 Batch  255/269 - Train Accuracy: 0.6125, Validation Accuracy: 0.5888, Loss: 0.7905
Epoch   1 Batch  256/269 - Train Accuracy: 0.5722, Validation Accuracy: 0.5899, Loss: 0.8376
Epoch   1 Batch  257/269 - Train Accuracy: 0.5672, Validation Accuracy: 0.5979, Loss: 0.8295
Epoch   1 Batch  258/269 - Train Accuracy: 0.5778, Validation Accuracy: 0.5993, Loss: 0.8276
Epoch   1 Batch  259/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.5990, Loss: 0.8170
Epoch   1 Batch  260/269 - Train Accuracy: 0.5732, Validation Accuracy: 0.5974, Loss: 0.8537
Epoch   1 Batch  261/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5932, Loss: 0.8658
Epoch   1 Batch  262/269 - Train Accuracy: 0.5891, Validation Accuracy: 0.5944, Loss: 0.8194
Epoch   1 Batch  263/269 - Train Accuracy: 0.5799, Validation Accuracy: 0.5974, Loss: 0.8448
Epoch   1 Batch  264/269 - Train Accuracy: 0.5587, Validation Accuracy: 0.5955, Loss: 0.8569
Epoch   1 Batch  265/269 - Train Accuracy: 0.5629, Validation Accuracy: 0.5955, Loss: 0.8382
Epoch   1 Batch  266/269 - Train Accuracy: 0.5967, Validation Accuracy: 0.5989, Loss: 0.7991
Epoch   1 Batch  267/269 - Train Accuracy: 0.5821, Validation Accuracy: 0.5968, Loss: 0.8284
Epoch   2 Batch    1/269 - Train Accuracy: 0.5710, Validation Accuracy: 0.5977, Loss: 0.8301
Epoch   2 Batch    2/269 - Train Accuracy: 0.5742, Validation Accuracy: 0.6007, Loss: 0.8142
Epoch   2 Batch    3/269 - Train Accuracy: 0.5746, Validation Accuracy: 0.5959, Loss: 0.8344
Epoch   2 Batch    4/269 - Train Accuracy: 0.5594, Validation Accuracy: 0.5963, Loss: 0.8338
Epoch   2 Batch    5/269 - Train Accuracy: 0.5616, Validation Accuracy: 0.5988, Loss: 0.8435
Epoch   2 Batch    6/269 - Train Accuracy: 0.5967, Validation Accuracy: 0.5969, Loss: 0.7680
Epoch   2 Batch    7/269 - Train Accuracy: 0.5918, Validation Accuracy: 0.5983, Loss: 0.7931
Epoch   2 Batch    8/269 - Train Accuracy: 0.5615, Validation Accuracy: 0.6005, Loss: 0.8459
Epoch   2 Batch    9/269 - Train Accuracy: 0.5748, Validation Accuracy: 0.5853, Loss: 0.8172
Epoch   2 Batch   10/269 - Train Accuracy: 0.5724, Validation Accuracy: 0.5909, Loss: 0.8255
Epoch   2 Batch   11/269 - Train Accuracy: 0.5827, Validation Accuracy: 0.5984, Loss: 0.8160
Epoch   2 Batch   12/269 - Train Accuracy: 0.5661, Validation Accuracy: 0.5974, Loss: 0.8383
Epoch   2 Batch   13/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.5923, Loss: 0.7526
Epoch   2 Batch   14/269 - Train Accuracy: 0.5860, Validation Accuracy: 0.5999, Loss: 0.8048
Epoch   2 Batch   15/269 - Train Accuracy: 0.5792, Validation Accuracy: 0.6005, Loss: 0.7901
Epoch   2 Batch   16/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6001, Loss: 0.7966
Epoch   2 Batch   17/269 - Train Accuracy: 0.5898, Validation Accuracy: 0.5983, Loss: 0.7806
Epoch   2 Batch   18/269 - Train Accuracy: 0.5620, Validation Accuracy: 0.6000, Loss: 0.8234
Epoch   2 Batch   19/269 - Train Accuracy: 0.6180, Validation Accuracy: 0.6016, Loss: 0.7510
Epoch   2 Batch   20/269 - Train Accuracy: 0.5797, Validation Accuracy: 0.6050, Loss: 0.8212
Epoch   2 Batch   21/269 - Train Accuracy: 0.5800, Validation Accuracy: 0.5995, Loss: 0.8458
Epoch   2 Batch   22/269 - Train Accuracy: 0.5984, Validation Accuracy: 0.5991, Loss: 0.7735
Epoch   2 Batch   23/269 - Train Accuracy: 0.5977, Validation Accuracy: 0.6040, Loss: 0.7928
Epoch   2 Batch   24/269 - Train Accuracy: 0.5874, Validation Accuracy: 0.6035, Loss: 0.8203
Epoch   2 Batch   25/269 - Train Accuracy: 0.5689, Validation Accuracy: 0.6021, Loss: 0.8382
Epoch   2 Batch   26/269 - Train Accuracy: 0.6199, Validation Accuracy: 0.5993, Loss: 0.7325
Epoch   2 Batch   27/269 - Train Accuracy: 0.5831, Validation Accuracy: 0.6027, Loss: 0.7840
Epoch   2 Batch   28/269 - Train Accuracy: 0.5586, Validation Accuracy: 0.6018, Loss: 0.8393
Epoch   2 Batch   29/269 - Train Accuracy: 0.5865, Validation Accuracy: 0.6032, Loss: 0.8067
Epoch   2 Batch   30/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.6012, Loss: 0.7737
Epoch   2 Batch   31/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6056, Loss: 0.7654
Epoch   2 Batch   32/269 - Train Accuracy: 0.5922, Validation Accuracy: 0.6031, Loss: 0.7734
Epoch   2 Batch   33/269 - Train Accuracy: 0.6106, Validation Accuracy: 0.5998, Loss: 0.7526
Epoch   2 Batch   34/269 - Train Accuracy: 0.5964, Validation Accuracy: 0.6009, Loss: 0.7707
Epoch   2 Batch   35/269 - Train Accuracy: 0.6014, Validation Accuracy: 0.6015, Loss: 0.7853
Epoch   2 Batch   36/269 - Train Accuracy: 0.5936, Validation Accuracy: 0.6032, Loss: 0.7794
Epoch   2 Batch   37/269 - Train Accuracy: 0.6009, Validation Accuracy: 0.6024, Loss: 0.7707
Epoch   2 Batch   38/269 - Train Accuracy: 0.6010, Validation Accuracy: 0.6034, Loss: 0.7804
Epoch   2 Batch   39/269 - Train Accuracy: 0.5978, Validation Accuracy: 0.6018, Loss: 0.7665
Epoch   2 Batch   40/269 - Train Accuracy: 0.5800, Validation Accuracy: 0.6033, Loss: 0.8035
Epoch   2 Batch   41/269 - Train Accuracy: 0.5860, Validation Accuracy: 0.6059, Loss: 0.7857
Epoch   2 Batch   42/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6049, Loss: 0.7381
Epoch   2 Batch   43/269 - Train Accuracy: 0.5813, Validation Accuracy: 0.6087, Loss: 0.8092
Epoch   2 Batch   44/269 - Train Accuracy: 0.6038, Validation Accuracy: 0.6060, Loss: 0.7784
Epoch   2 Batch   45/269 - Train Accuracy: 0.5671, Validation Accuracy: 0.5960, Loss: 0.8057
Epoch   2 Batch   46/269 - Train Accuracy: 0.5836, Validation Accuracy: 0.6039, Loss: 0.7950
Epoch   2 Batch   47/269 - Train Accuracy: 0.6262, Validation Accuracy: 0.6036, Loss: 0.7154
Epoch   2 Batch   48/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.5992, Loss: 0.7515
Epoch   2 Batch   49/269 - Train Accuracy: 0.5808, Validation Accuracy: 0.5993, Loss: 0.7913
Epoch   2 Batch   50/269 - Train Accuracy: 0.5854, Validation Accuracy: 0.6037, Loss: 0.8010
Epoch   2 Batch   51/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.6049, Loss: 0.7754
Epoch   2 Batch   52/269 - Train Accuracy: 0.5946, Validation Accuracy: 0.6044, Loss: 0.7423
Epoch   2 Batch   53/269 - Train Accuracy: 0.5804, Validation Accuracy: 0.6060, Loss: 0.8051
Epoch   2 Batch   54/269 - Train Accuracy: 0.5959, Validation Accuracy: 0.6050, Loss: 0.7923
Epoch   2 Batch   55/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6059, Loss: 0.7575
Epoch   2 Batch   56/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6060, Loss: 0.7615
Epoch   2 Batch   57/269 - Train Accuracy: 0.6088, Validation Accuracy: 0.6027, Loss: 0.7826
Epoch   2 Batch   58/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6038, Loss: 0.7570
Epoch   2 Batch   59/269 - Train Accuracy: 0.6094, Validation Accuracy: 0.6035, Loss: 0.7335
Epoch   2 Batch   60/269 - Train Accuracy: 0.6079, Validation Accuracy: 0.6041, Loss: 0.7283
Epoch   2 Batch   61/269 - Train Accuracy: 0.6191, Validation Accuracy: 0.6061, Loss: 0.7064
Epoch   2 Batch   62/269 - Train Accuracy: 0.6108, Validation Accuracy: 0.6051, Loss: 0.7372
Epoch   2 Batch   63/269 - Train Accuracy: 0.5940, Validation Accuracy: 0.6069, Loss: 0.7713
Epoch   2 Batch   64/269 - Train Accuracy: 0.5830, Validation Accuracy: 0.6031, Loss: 0.7513
Epoch   2 Batch   65/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6041, Loss: 0.7463
Epoch   2 Batch   66/269 - Train Accuracy: 0.6083, Validation Accuracy: 0.6055, Loss: 0.7250
Epoch   2 Batch   67/269 - Train Accuracy: 0.6024, Validation Accuracy: 0.6082, Loss: 0.7599
Epoch   2 Batch   68/269 - Train Accuracy: 0.5806, Validation Accuracy: 0.5912, Loss: 0.7640
Epoch   2 Batch   69/269 - Train Accuracy: 0.5797, Validation Accuracy: 0.6016, Loss: 0.8248
Epoch   2 Batch   70/269 - Train Accuracy: 0.6182, Validation Accuracy: 0.6090, Loss: 0.7554
Epoch   2 Batch   71/269 - Train Accuracy: 0.5969, Validation Accuracy: 0.6106, Loss: 0.7893
Epoch   2 Batch   72/269 - Train Accuracy: 0.6114, Validation Accuracy: 0.6044, Loss: 0.7452
Epoch   2 Batch   73/269 - Train Accuracy: 0.6002, Validation Accuracy: 0.6088, Loss: 0.7689
Epoch   2 Batch   74/269 - Train Accuracy: 0.6022, Validation Accuracy: 0.6091, Loss: 0.7672
Epoch   2 Batch   75/269 - Train Accuracy: 0.5937, Validation Accuracy: 0.6040, Loss: 0.7435
Epoch   2 Batch   76/269 - Train Accuracy: 0.5869, Validation Accuracy: 0.6048, Loss: 0.7629
Epoch   2 Batch   77/269 - Train Accuracy: 0.6217, Validation Accuracy: 0.6108, Loss: 0.7483
Epoch   2 Batch   78/269 - Train Accuracy: 0.6054, Validation Accuracy: 0.6081, Loss: 0.7398
Epoch   2 Batch   79/269 - Train Accuracy: 0.6009, Validation Accuracy: 0.6012, Loss: 0.7393
Epoch   2 Batch   80/269 - Train Accuracy: 0.6117, Validation Accuracy: 0.6097, Loss: 0.7394
Epoch   2 Batch   81/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6075, Loss: 0.7658
Epoch   2 Batch   82/269 - Train Accuracy: 0.6126, Validation Accuracy: 0.6048, Loss: 0.7238
Epoch   2 Batch   83/269 - Train Accuracy: 0.5973, Validation Accuracy: 0.6063, Loss: 0.7433
Epoch   2 Batch   84/269 - Train Accuracy: 0.6088, Validation Accuracy: 0.6103, Loss: 0.7284
Epoch   2 Batch   85/269 - Train Accuracy: 0.6018, Validation Accuracy: 0.6116, Loss: 0.7456
Epoch   2 Batch   86/269 - Train Accuracy: 0.5831, Validation Accuracy: 0.6115, Loss: 0.7400
Epoch   2 Batch   87/269 - Train Accuracy: 0.5791, Validation Accuracy: 0.6077, Loss: 0.7929
Epoch   2 Batch   88/269 - Train Accuracy: 0.5931, Validation Accuracy: 0.6091, Loss: 0.7367
Epoch   2 Batch   89/269 - Train Accuracy: 0.6236, Validation Accuracy: 0.6149, Loss: 0.7451
Epoch   2 Batch   90/269 - Train Accuracy: 0.5657, Validation Accuracy: 0.6127, Loss: 0.7885
Epoch   2 Batch   91/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6091, Loss: 0.7196
Epoch   2 Batch   92/269 - Train Accuracy: 0.5996, Validation Accuracy: 0.6119, Loss: 0.7286
Epoch   2 Batch   93/269 - Train Accuracy: 0.6250, Validation Accuracy: 0.6124, Loss: 0.7052
Epoch   2 Batch   94/269 - Train Accuracy: 0.6073, Validation Accuracy: 0.6084, Loss: 0.7554
Epoch   2 Batch   95/269 - Train Accuracy: 0.6042, Validation Accuracy: 0.6148, Loss: 0.7420
Epoch   2 Batch   96/269 - Train Accuracy: 0.5990, Validation Accuracy: 0.6125, Loss: 0.7334
Epoch   2 Batch   97/269 - Train Accuracy: 0.5880, Validation Accuracy: 0.6142, Loss: 0.7371
Epoch   2 Batch   98/269 - Train Accuracy: 0.6130, Validation Accuracy: 0.6159, Loss: 0.7346
Epoch   2 Batch   99/269 - Train Accuracy: 0.5937, Validation Accuracy: 0.6177, Loss: 0.7648
Epoch   2 Batch  100/269 - Train Accuracy: 0.6175, Validation Accuracy: 0.6156, Loss: 0.7245
Epoch   2 Batch  101/269 - Train Accuracy: 0.5729, Validation Accuracy: 0.6153, Loss: 0.7704
Epoch   2 Batch  102/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.6142, Loss: 0.7335
Epoch   2 Batch  103/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6141, Loss: 0.7275
Epoch   2 Batch  104/269 - Train Accuracy: 0.5940, Validation Accuracy: 0.6159, Loss: 0.7299
Epoch   2 Batch  105/269 - Train Accuracy: 0.5962, Validation Accuracy: 0.6148, Loss: 0.7403
Epoch   2 Batch  106/269 - Train Accuracy: 0.5990, Validation Accuracy: 0.6158, Loss: 0.7211
Epoch   2 Batch  107/269 - Train Accuracy: 0.5725, Validation Accuracy: 0.6099, Loss: 0.7671
Epoch   2 Batch  108/269 - Train Accuracy: 0.6060, Validation Accuracy: 0.6143, Loss: 0.7283
Epoch   2 Batch  109/269 - Train Accuracy: 0.5869, Validation Accuracy: 0.6160, Loss: 0.7429
Epoch   2 Batch  110/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.6146, Loss: 0.7190
Epoch   2 Batch  111/269 - Train Accuracy: 0.5798, Validation Accuracy: 0.6130, Loss: 0.7715
Epoch   2 Batch  112/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6111, Loss: 0.7254
Epoch   2 Batch  113/269 - Train Accuracy: 0.6107, Validation Accuracy: 0.6110, Loss: 0.6968
Epoch   2 Batch  114/269 - Train Accuracy: 0.6027, Validation Accuracy: 0.6126, Loss: 0.7240
Epoch   2 Batch  115/269 - Train Accuracy: 0.5929, Validation Accuracy: 0.6127, Loss: 0.7480
Epoch   2 Batch  116/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6118, Loss: 0.7298
Epoch   2 Batch  117/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6151, Loss: 0.7192
Epoch   2 Batch  118/269 - Train Accuracy: 0.6264, Validation Accuracy: 0.6150, Loss: 0.6993
Epoch   2 Batch  119/269 - Train Accuracy: 0.5932, Validation Accuracy: 0.6091, Loss: 0.7615
Epoch   2 Batch  120/269 - Train Accuracy: 0.6082, Validation Accuracy: 0.6162, Loss: 0.7465
Epoch   2 Batch  121/269 - Train Accuracy: 0.6095, Validation Accuracy: 0.6143, Loss: 0.7133
Epoch   2 Batch  122/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6100, Loss: 0.7104
Epoch   2 Batch  123/269 - Train Accuracy: 0.5801, Validation Accuracy: 0.6116, Loss: 0.7576
Epoch   2 Batch  124/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6127, Loss: 0.7023
Epoch   2 Batch  125/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.6113, Loss: 0.7060
Epoch   2 Batch  126/269 - Train Accuracy: 0.6126, Validation Accuracy: 0.6142, Loss: 0.7047
Epoch   2 Batch  127/269 - Train Accuracy: 0.6007, Validation Accuracy: 0.6120, Loss: 0.7443
Epoch   2 Batch  128/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6127, Loss: 0.7159
Epoch   2 Batch  129/269 - Train Accuracy: 0.6066, Validation Accuracy: 0.6121, Loss: 0.7192
Epoch   2 Batch  130/269 - Train Accuracy: 0.5840, Validation Accuracy: 0.6160, Loss: 0.7523
Epoch   2 Batch  131/269 - Train Accuracy: 0.5988, Validation Accuracy: 0.6165, Loss: 0.7356
Epoch   2 Batch  132/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6204, Loss: 0.7260
Epoch   2 Batch  133/269 - Train Accuracy: 0.6136, Validation Accuracy: 0.6183, Loss: 0.7002
Epoch   2 Batch  134/269 - Train Accuracy: 0.5981, Validation Accuracy: 0.6174, Loss: 0.7290
Epoch   2 Batch  135/269 - Train Accuracy: 0.5735, Validation Accuracy: 0.6164, Loss: 0.7646
Epoch   2 Batch  136/269 - Train Accuracy: 0.5932, Validation Accuracy: 0.6191, Loss: 0.7635
Epoch   2 Batch  137/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6173, Loss: 0.7453
Epoch   2 Batch  138/269 - Train Accuracy: 0.6079, Validation Accuracy: 0.6167, Loss: 0.7353
Epoch   2 Batch  139/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6138, Loss: 0.6906
Epoch   2 Batch  140/269 - Train Accuracy: 0.6265, Validation Accuracy: 0.6166, Loss: 0.7327
Epoch   2 Batch  141/269 - Train Accuracy: 0.6132, Validation Accuracy: 0.6191, Loss: 0.7229
Epoch   2 Batch  142/269 - Train Accuracy: 0.6155, Validation Accuracy: 0.6184, Loss: 0.6958
Epoch   2 Batch  143/269 - Train Accuracy: 0.6114, Validation Accuracy: 0.6113, Loss: 0.7127
Epoch   2 Batch  144/269 - Train Accuracy: 0.6074, Validation Accuracy: 0.6092, Loss: 0.6851
Epoch   2 Batch  145/269 - Train Accuracy: 0.6238, Validation Accuracy: 0.6168, Loss: 0.7012
Epoch   2 Batch  146/269 - Train Accuracy: 0.6228, Validation Accuracy: 0.6196, Loss: 0.6983
Epoch   2 Batch  147/269 - Train Accuracy: 0.6288, Validation Accuracy: 0.6123, Loss: 0.6768
Epoch   2 Batch  148/269 - Train Accuracy: 0.6015, Validation Accuracy: 0.6145, Loss: 0.7185
Epoch   2 Batch  149/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6114, Loss: 0.7123
Epoch   2 Batch  150/269 - Train Accuracy: 0.6132, Validation Accuracy: 0.6091, Loss: 0.7155
Epoch   2 Batch  151/269 - Train Accuracy: 0.6438, Validation Accuracy: 0.6114, Loss: 0.6827
Epoch   2 Batch  152/269 - Train Accuracy: 0.6078, Validation Accuracy: 0.6139, Loss: 0.7116
Epoch   2 Batch  153/269 - Train Accuracy: 0.6107, Validation Accuracy: 0.6120, Loss: 0.6980
Epoch   2 Batch  154/269 - Train Accuracy: 0.5926, Validation Accuracy: 0.6140, Loss: 0.7229
Epoch   2 Batch  155/269 - Train Accuracy: 0.6444, Validation Accuracy: 0.6214, Loss: 0.6663
Epoch   2 Batch  156/269 - Train Accuracy: 0.6016, Validation Accuracy: 0.6170, Loss: 0.7310
Epoch   2 Batch  157/269 - Train Accuracy: 0.5944, Validation Accuracy: 0.6062, Loss: 0.7001
Epoch   2 Batch  158/269 - Train Accuracy: 0.6131, Validation Accuracy: 0.6193, Loss: 0.6993
Epoch   2 Batch  159/269 - Train Accuracy: 0.6205, Validation Accuracy: 0.6200, Loss: 0.7066
Epoch   2 Batch  160/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6165, Loss: 0.6962
Epoch   2 Batch  161/269 - Train Accuracy: 0.6043, Validation Accuracy: 0.6195, Loss: 0.7046
Epoch   2 Batch  162/269 - Train Accuracy: 0.6096, Validation Accuracy: 0.6221, Loss: 0.6997
Epoch   2 Batch  163/269 - Train Accuracy: 0.6270, Validation Accuracy: 0.6222, Loss: 0.6884
Epoch   2 Batch  164/269 - Train Accuracy: 0.6254, Validation Accuracy: 0.6246, Loss: 0.6872
Epoch   2 Batch  165/269 - Train Accuracy: 0.5907, Validation Accuracy: 0.6205, Loss: 0.7156
Epoch   2 Batch  166/269 - Train Accuracy: 0.6303, Validation Accuracy: 0.6171, Loss: 0.6528
Epoch   2 Batch  167/269 - Train Accuracy: 0.6191, Validation Accuracy: 0.6175, Loss: 0.6992
Epoch   2 Batch  168/269 - Train Accuracy: 0.6003, Validation Accuracy: 0.6183, Loss: 0.7071
Epoch   2 Batch  169/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6225, Loss: 0.7064
Epoch   2 Batch  170/269 - Train Accuracy: 0.6155, Validation Accuracy: 0.6233, Loss: 0.6879
Epoch   2 Batch  171/269 - Train Accuracy: 0.6126, Validation Accuracy: 0.6183, Loss: 0.7238
Epoch   2 Batch  172/269 - Train Accuracy: 0.6216, Validation Accuracy: 0.6226, Loss: 0.7059
Epoch   2 Batch  173/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6202, Loss: 0.6828
Epoch   2 Batch  174/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6205, Loss: 0.6947
Epoch   2 Batch  175/269 - Train Accuracy: 0.6216, Validation Accuracy: 0.6177, Loss: 0.7010
Epoch   2 Batch  176/269 - Train Accuracy: 0.5984, Validation Accuracy: 0.6239, Loss: 0.7380
Epoch   2 Batch  177/269 - Train Accuracy: 0.6200, Validation Accuracy: 0.6234, Loss: 0.6667
Epoch   2 Batch  178/269 - Train Accuracy: 0.5902, Validation Accuracy: 0.6147, Loss: 0.7029
Epoch   2 Batch  179/269 - Train Accuracy: 0.6247, Validation Accuracy: 0.6194, Loss: 0.6969
Epoch   2 Batch  180/269 - Train Accuracy: 0.6140, Validation Accuracy: 0.6268, Loss: 0.6824
Epoch   2 Batch  181/269 - Train Accuracy: 0.6073, Validation Accuracy: 0.6244, Loss: 0.6957
Epoch   2 Batch  182/269 - Train Accuracy: 0.6238, Validation Accuracy: 0.6207, Loss: 0.6998
Epoch   2 Batch  183/269 - Train Accuracy: 0.6766, Validation Accuracy: 0.6199, Loss: 0.6017
Epoch   2 Batch  184/269 - Train Accuracy: 0.5977, Validation Accuracy: 0.6209, Loss: 0.7131
Epoch   2 Batch  185/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6259, Loss: 0.6808
Epoch   2 Batch  186/269 - Train Accuracy: 0.6017, Validation Accuracy: 0.6230, Loss: 0.7017
Epoch   2 Batch  187/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6220, Loss: 0.6692
Epoch   2 Batch  188/269 - Train Accuracy: 0.6286, Validation Accuracy: 0.6255, Loss: 0.6697
Epoch   2 Batch  189/269 - Train Accuracy: 0.6211, Validation Accuracy: 0.6231, Loss: 0.6649
Epoch   2 Batch  190/269 - Train Accuracy: 0.6065, Validation Accuracy: 0.6175, Loss: 0.6683
Epoch   2 Batch  191/269 - Train Accuracy: 0.6310, Validation Accuracy: 0.6174, Loss: 0.6746
Epoch   2 Batch  192/269 - Train Accuracy: 0.6258, Validation Accuracy: 0.6165, Loss: 0.6798
Epoch   2 Batch  193/269 - Train Accuracy: 0.6212, Validation Accuracy: 0.6156, Loss: 0.6753
Epoch   2 Batch  194/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6205, Loss: 0.6795
Epoch   2 Batch  195/269 - Train Accuracy: 0.6197, Validation Accuracy: 0.6175, Loss: 0.6845
Epoch   2 Batch  196/269 - Train Accuracy: 0.6002, Validation Accuracy: 0.6190, Loss: 0.6766
Epoch   2 Batch  197/269 - Train Accuracy: 0.5965, Validation Accuracy: 0.6210, Loss: 0.7096
Epoch   2 Batch  198/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.6222, Loss: 0.7214
Epoch   2 Batch  199/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6220, Loss: 0.6942
Epoch   2 Batch  200/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6211, Loss: 0.6968
Epoch   2 Batch  201/269 - Train Accuracy: 0.6201, Validation Accuracy: 0.6197, Loss: 0.6746
Epoch   2 Batch  202/269 - Train Accuracy: 0.6150, Validation Accuracy: 0.6157, Loss: 0.6729
Epoch   2 Batch  203/269 - Train Accuracy: 0.5958, Validation Accuracy: 0.6218, Loss: 0.7218
Epoch   2 Batch  204/269 - Train Accuracy: 0.6043, Validation Accuracy: 0.6228, Loss: 0.7039
Epoch   2 Batch  205/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6234, Loss: 0.6628
Epoch   2 Batch  206/269 - Train Accuracy: 0.6109, Validation Accuracy: 0.6251, Loss: 0.7012
Epoch   2 Batch  207/269 - Train Accuracy: 0.6435, Validation Accuracy: 0.6245, Loss: 0.6527
Epoch   2 Batch  208/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6248, Loss: 0.7057
Epoch   2 Batch  209/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6236, Loss: 0.6777
Epoch   2 Batch  210/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6236, Loss: 0.6579
Epoch   2 Batch  211/269 - Train Accuracy: 0.6202, Validation Accuracy: 0.6237, Loss: 0.6753
Epoch   2 Batch  212/269 - Train Accuracy: 0.6383, Validation Accuracy: 0.6222, Loss: 0.6613
Epoch   2 Batch  213/269 - Train Accuracy: 0.6278, Validation Accuracy: 0.6255, Loss: 0.6628
Epoch   2 Batch  214/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6253, Loss: 0.6662
Epoch   2 Batch  215/269 - Train Accuracy: 0.6493, Validation Accuracy: 0.6222, Loss: 0.6275
Epoch   2 Batch  216/269 - Train Accuracy: 0.6006, Validation Accuracy: 0.6243, Loss: 0.7194
Epoch   2 Batch  217/269 - Train Accuracy: 0.5963, Validation Accuracy: 0.6291, Loss: 0.6968
Epoch   2 Batch  218/269 - Train Accuracy: 0.6104, Validation Accuracy: 0.6286, Loss: 0.6961
Epoch   2 Batch  219/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6287, Loss: 0.6955
Epoch   2 Batch  220/269 - Train Accuracy: 0.6303, Validation Accuracy: 0.6301, Loss: 0.6311
Epoch   2 Batch  221/269 - Train Accuracy: 0.6550, Validation Accuracy: 0.6288, Loss: 0.6598
Epoch   2 Batch  222/269 - Train Accuracy: 0.6464, Validation Accuracy: 0.6288, Loss: 0.6469
Epoch   2 Batch  223/269 - Train Accuracy: 0.6229, Validation Accuracy: 0.6278, Loss: 0.6506
Epoch   2 Batch  224/269 - Train Accuracy: 0.6347, Validation Accuracy: 0.6325, Loss: 0.6840
Epoch   2 Batch  225/269 - Train Accuracy: 0.6182, Validation Accuracy: 0.6289, Loss: 0.6799
Epoch   2 Batch  226/269 - Train Accuracy: 0.6235, Validation Accuracy: 0.6313, Loss: 0.6623
Epoch   2 Batch  227/269 - Train Accuracy: 0.6780, Validation Accuracy: 0.6364, Loss: 0.5835
Epoch   2 Batch  228/269 - Train Accuracy: 0.6331, Validation Accuracy: 0.6412, Loss: 0.6566
Epoch   2 Batch  229/269 - Train Accuracy: 0.6370, Validation Accuracy: 0.6355, Loss: 0.6514
Epoch   2 Batch  230/269 - Train Accuracy: 0.6314, Validation Accuracy: 0.6358, Loss: 0.6614
Epoch   2 Batch  231/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6351, Loss: 0.6984
Epoch   2 Batch  232/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.6345, Loss: 0.6898
Epoch   2 Batch  233/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6308, Loss: 0.6691
Epoch   2 Batch  234/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6349, Loss: 0.6580
Epoch   2 Batch  235/269 - Train Accuracy: 0.6345, Validation Accuracy: 0.6323, Loss: 0.6433
Epoch   2 Batch  236/269 - Train Accuracy: 0.6180, Validation Accuracy: 0.6354, Loss: 0.6542
Epoch   2 Batch  237/269 - Train Accuracy: 0.6078, Validation Accuracy: 0.6342, Loss: 0.6520
Epoch   2 Batch  238/269 - Train Accuracy: 0.6472, Validation Accuracy: 0.6345, Loss: 0.6474
Epoch   2 Batch  239/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6362, Loss: 0.6480
Epoch   2 Batch  240/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6369, Loss: 0.5966
Epoch   2 Batch  241/269 - Train Accuracy: 0.6300, Validation Accuracy: 0.6386, Loss: 0.6634
Epoch   2 Batch  242/269 - Train Accuracy: 0.6173, Validation Accuracy: 0.6355, Loss: 0.6503
Epoch   2 Batch  243/269 - Train Accuracy: 0.6544, Validation Accuracy: 0.6381, Loss: 0.6357
Epoch   2 Batch  244/269 - Train Accuracy: 0.6217, Validation Accuracy: 0.6371, Loss: 0.6582
Epoch   2 Batch  245/269 - Train Accuracy: 0.6226, Validation Accuracy: 0.6349, Loss: 0.6920
Epoch   2 Batch  246/269 - Train Accuracy: 0.6141, Validation Accuracy: 0.6357, Loss: 0.6602
Epoch   2 Batch  247/269 - Train Accuracy: 0.6246, Validation Accuracy: 0.6323, Loss: 0.6805
Epoch   2 Batch  248/269 - Train Accuracy: 0.6254, Validation Accuracy: 0.6363, Loss: 0.6484
Epoch   2 Batch  249/269 - Train Accuracy: 0.6517, Validation Accuracy: 0.6343, Loss: 0.6152
Epoch   2 Batch  250/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6321, Loss: 0.6684
Epoch   2 Batch  251/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6353, Loss: 0.6347
Epoch   2 Batch  252/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6329, Loss: 0.6600
Epoch   2 Batch  253/269 - Train Accuracy: 0.6166, Validation Accuracy: 0.6339, Loss: 0.6574
Epoch   2 Batch  254/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6341, Loss: 0.6490
Epoch   2 Batch  255/269 - Train Accuracy: 0.6501, Validation Accuracy: 0.6347, Loss: 0.6300
Epoch   2 Batch  256/269 - Train Accuracy: 0.6131, Validation Accuracy: 0.6358, Loss: 0.6559
Epoch   2 Batch  257/269 - Train Accuracy: 0.6025, Validation Accuracy: 0.6401, Loss: 0.6540
Epoch   2 Batch  258/269 - Train Accuracy: 0.6212, Validation Accuracy: 0.6343, Loss: 0.6558
Epoch   2 Batch  259/269 - Train Accuracy: 0.6424, Validation Accuracy: 0.6323, Loss: 0.6451
Epoch   2 Batch  260/269 - Train Accuracy: 0.6214, Validation Accuracy: 0.6368, Loss: 0.6704
Epoch   2 Batch  261/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6364, Loss: 0.6866
Epoch   2 Batch  262/269 - Train Accuracy: 0.6387, Validation Accuracy: 0.6368, Loss: 0.6475
Epoch   2 Batch  263/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6387, Loss: 0.6691
Epoch   2 Batch  264/269 - Train Accuracy: 0.6113, Validation Accuracy: 0.6347, Loss: 0.6719
Epoch   2 Batch  265/269 - Train Accuracy: 0.6156, Validation Accuracy: 0.6355, Loss: 0.6629
Epoch   2 Batch  266/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6376, Loss: 0.6330
Epoch   2 Batch  267/269 - Train Accuracy: 0.6418, Validation Accuracy: 0.6383, Loss: 0.6596
Epoch   3 Batch    1/269 - Train Accuracy: 0.6153, Validation Accuracy: 0.6424, Loss: 0.6634
Epoch   3 Batch    2/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6401, Loss: 0.6483
Epoch   3 Batch    3/269 - Train Accuracy: 0.6213, Validation Accuracy: 0.6366, Loss: 0.6555
Epoch   3 Batch    4/269 - Train Accuracy: 0.6004, Validation Accuracy: 0.6375, Loss: 0.6716
Epoch   3 Batch    5/269 - Train Accuracy: 0.5977, Validation Accuracy: 0.6351, Loss: 0.6657
Epoch   3 Batch    6/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6405, Loss: 0.6273
Epoch   3 Batch    7/269 - Train Accuracy: 0.6371, Validation Accuracy: 0.6404, Loss: 0.6334
Epoch   3 Batch    8/269 - Train Accuracy: 0.6129, Validation Accuracy: 0.6356, Loss: 0.6778
Epoch   3 Batch    9/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6389, Loss: 0.6539
Epoch   3 Batch   10/269 - Train Accuracy: 0.6208, Validation Accuracy: 0.6418, Loss: 0.6591
Epoch   3 Batch   11/269 - Train Accuracy: 0.6148, Validation Accuracy: 0.6384, Loss: 0.6514
Epoch   3 Batch   12/269 - Train Accuracy: 0.6085, Validation Accuracy: 0.6410, Loss: 0.6795
Epoch   3 Batch   13/269 - Train Accuracy: 0.6516, Validation Accuracy: 0.6388, Loss: 0.6011
Epoch   3 Batch   14/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6416, Loss: 0.6397
Epoch   3 Batch   15/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6433, Loss: 0.6335
Epoch   3 Batch   16/269 - Train Accuracy: 0.6489, Validation Accuracy: 0.6437, Loss: 0.6370
Epoch   3 Batch   17/269 - Train Accuracy: 0.6367, Validation Accuracy: 0.6426, Loss: 0.6254
Epoch   3 Batch   18/269 - Train Accuracy: 0.6054, Validation Accuracy: 0.6393, Loss: 0.6490
Epoch   3 Batch   19/269 - Train Accuracy: 0.6529, Validation Accuracy: 0.6385, Loss: 0.5985
Epoch   3 Batch   20/269 - Train Accuracy: 0.6321, Validation Accuracy: 0.6445, Loss: 0.6600
Epoch   3 Batch   21/269 - Train Accuracy: 0.6154, Validation Accuracy: 0.6415, Loss: 0.6743
Epoch   3 Batch   22/269 - Train Accuracy: 0.6408, Validation Accuracy: 0.6414, Loss: 0.6121
Epoch   3 Batch   23/269 - Train Accuracy: 0.6356, Validation Accuracy: 0.6441, Loss: 0.6277
Epoch   3 Batch   24/269 - Train Accuracy: 0.6169, Validation Accuracy: 0.6454, Loss: 0.6650
Epoch   3 Batch   25/269 - Train Accuracy: 0.6092, Validation Accuracy: 0.6436, Loss: 0.6717
Epoch   3 Batch   26/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6429, Loss: 0.5902
Epoch   3 Batch   27/269 - Train Accuracy: 0.6249, Validation Accuracy: 0.6456, Loss: 0.6210
Epoch   3 Batch   28/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.6428, Loss: 0.6729
Epoch   3 Batch   29/269 - Train Accuracy: 0.6208, Validation Accuracy: 0.6437, Loss: 0.6511
Epoch   3 Batch   30/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6430, Loss: 0.6182
Epoch   3 Batch   31/269 - Train Accuracy: 0.6395, Validation Accuracy: 0.6422, Loss: 0.6185
Epoch   3 Batch   32/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6428, Loss: 0.6155
Epoch   3 Batch   33/269 - Train Accuracy: 0.6447, Validation Accuracy: 0.6449, Loss: 0.6073
Epoch   3 Batch   34/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6419, Loss: 0.6220
Epoch   3 Batch   35/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6488, Loss: 0.6385
Epoch   3 Batch   36/269 - Train Accuracy: 0.6294, Validation Accuracy: 0.6440, Loss: 0.6214
Epoch   3 Batch   37/269 - Train Accuracy: 0.6417, Validation Accuracy: 0.6456, Loss: 0.6189
Epoch   3 Batch   38/269 - Train Accuracy: 0.6394, Validation Accuracy: 0.6451, Loss: 0.6248
Epoch   3 Batch   39/269 - Train Accuracy: 0.6434, Validation Accuracy: 0.6444, Loss: 0.6198
Epoch   3 Batch   40/269 - Train Accuracy: 0.6220, Validation Accuracy: 0.6456, Loss: 0.6463
Epoch   3 Batch   41/269 - Train Accuracy: 0.6274, Validation Accuracy: 0.6465, Loss: 0.6369
Epoch   3 Batch   42/269 - Train Accuracy: 0.6613, Validation Accuracy: 0.6468, Loss: 0.5961
Epoch   3 Batch   43/269 - Train Accuracy: 0.6215, Validation Accuracy: 0.6486, Loss: 0.6386
Epoch   3 Batch   44/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6435, Loss: 0.6336
Epoch   3 Batch   45/269 - Train Accuracy: 0.6242, Validation Accuracy: 0.6444, Loss: 0.6539
Epoch   3 Batch   46/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6412, Loss: 0.6383
Epoch   3 Batch   47/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6404, Loss: 0.5784
Epoch   3 Batch   48/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6475, Loss: 0.6104
Epoch   3 Batch   49/269 - Train Accuracy: 0.6214, Validation Accuracy: 0.6475, Loss: 0.6315
Epoch   3 Batch   50/269 - Train Accuracy: 0.6260, Validation Accuracy: 0.6388, Loss: 0.6450
Epoch   3 Batch   51/269 - Train Accuracy: 0.6264, Validation Accuracy: 0.6424, Loss: 0.6196
Epoch   3 Batch   52/269 - Train Accuracy: 0.6368, Validation Accuracy: 0.6473, Loss: 0.6008
Epoch   3 Batch   53/269 - Train Accuracy: 0.6139, Validation Accuracy: 0.6441, Loss: 0.6536
Epoch   3 Batch   54/269 - Train Accuracy: 0.6309, Validation Accuracy: 0.6445, Loss: 0.6380
Epoch   3 Batch   55/269 - Train Accuracy: 0.6491, Validation Accuracy: 0.6440, Loss: 0.6056
Epoch   3 Batch   56/269 - Train Accuracy: 0.6442, Validation Accuracy: 0.6418, Loss: 0.6208
Epoch   3 Batch   57/269 - Train Accuracy: 0.6385, Validation Accuracy: 0.6460, Loss: 0.6285
Epoch   3 Batch   58/269 - Train Accuracy: 0.6440, Validation Accuracy: 0.6452, Loss: 0.6075
Epoch   3 Batch   59/269 - Train Accuracy: 0.6526, Validation Accuracy: 0.6443, Loss: 0.5927
Epoch   3 Batch   60/269 - Train Accuracy: 0.6463, Validation Accuracy: 0.6401, Loss: 0.5902
Epoch   3 Batch   61/269 - Train Accuracy: 0.6494, Validation Accuracy: 0.6439, Loss: 0.5744
Epoch   3 Batch   62/269 - Train Accuracy: 0.6528, Validation Accuracy: 0.6468, Loss: 0.5929
Epoch   3 Batch   63/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6413, Loss: 0.6193
Epoch   3 Batch   64/269 - Train Accuracy: 0.6288, Validation Accuracy: 0.6455, Loss: 0.6080
Epoch   3 Batch   65/269 - Train Accuracy: 0.6328, Validation Accuracy: 0.6444, Loss: 0.6049
Epoch   3 Batch   66/269 - Train Accuracy: 0.6413, Validation Accuracy: 0.6432, Loss: 0.5885
Epoch   3 Batch   67/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6430, Loss: 0.6166
Epoch   3 Batch   68/269 - Train Accuracy: 0.6193, Validation Accuracy: 0.6459, Loss: 0.6130
Epoch   3 Batch   69/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6442, Loss: 0.6619
Epoch   3 Batch   70/269 - Train Accuracy: 0.6421, Validation Accuracy: 0.6450, Loss: 0.6150
Epoch   3 Batch   71/269 - Train Accuracy: 0.6243, Validation Accuracy: 0.6468, Loss: 0.6378
Epoch   3 Batch   72/269 - Train Accuracy: 0.6375, Validation Accuracy: 0.6428, Loss: 0.6026
Epoch   3 Batch   73/269 - Train Accuracy: 0.6350, Validation Accuracy: 0.6425, Loss: 0.6205
Epoch   3 Batch   74/269 - Train Accuracy: 0.6379, Validation Accuracy: 0.6453, Loss: 0.6217
Epoch   3 Batch   75/269 - Train Accuracy: 0.6414, Validation Accuracy: 0.6411, Loss: 0.6007
Epoch   3 Batch   76/269 - Train Accuracy: 0.6166, Validation Accuracy: 0.6454, Loss: 0.6191
Epoch   3 Batch   77/269 - Train Accuracy: 0.6562, Validation Accuracy: 0.6456, Loss: 0.6047
Epoch   3 Batch   78/269 - Train Accuracy: 0.6402, Validation Accuracy: 0.6404, Loss: 0.5976
Epoch   3 Batch   79/269 - Train Accuracy: 0.6284, Validation Accuracy: 0.6404, Loss: 0.6070
Epoch   3 Batch   80/269 - Train Accuracy: 0.6580, Validation Accuracy: 0.6423, Loss: 0.6021
Epoch   3 Batch   81/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6362, Loss: 0.6136
Epoch   3 Batch   82/269 - Train Accuracy: 0.6518, Validation Accuracy: 0.6416, Loss: 0.5843
Epoch   3 Batch   83/269 - Train Accuracy: 0.6412, Validation Accuracy: 0.6418, Loss: 0.6101
Epoch   3 Batch   84/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6386, Loss: 0.5898
Epoch   3 Batch   85/269 - Train Accuracy: 0.6309, Validation Accuracy: 0.6435, Loss: 0.6109
Epoch   3 Batch   86/269 - Train Accuracy: 0.6162, Validation Accuracy: 0.6474, Loss: 0.6012
Epoch   3 Batch   87/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6419, Loss: 0.6396
Epoch   3 Batch   88/269 - Train Accuracy: 0.6405, Validation Accuracy: 0.6504, Loss: 0.6045
Epoch   3 Batch   89/269 - Train Accuracy: 0.6551, Validation Accuracy: 0.6509, Loss: 0.5963
Epoch   3 Batch   90/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6422, Loss: 0.6425
Epoch   3 Batch   91/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6476, Loss: 0.5847
Epoch   3 Batch   92/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6529, Loss: 0.5917
Epoch   3 Batch   93/269 - Train Accuracy: 0.6463, Validation Accuracy: 0.6481, Loss: 0.5813
Epoch   3 Batch   94/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6373, Loss: 0.6088
Epoch   3 Batch   95/269 - Train Accuracy: 0.6294, Validation Accuracy: 0.6437, Loss: 0.6027
Epoch   3 Batch   96/269 - Train Accuracy: 0.6352, Validation Accuracy: 0.6406, Loss: 0.6054
Epoch   3 Batch   97/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6378, Loss: 0.5913
Epoch   3 Batch   98/269 - Train Accuracy: 0.6343, Validation Accuracy: 0.6501, Loss: 0.6052
Epoch   3 Batch   99/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6488, Loss: 0.6148
Epoch   3 Batch  100/269 - Train Accuracy: 0.6568, Validation Accuracy: 0.6441, Loss: 0.5916
Epoch   3 Batch  101/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6413, Loss: 0.6325
Epoch   3 Batch  102/269 - Train Accuracy: 0.6413, Validation Accuracy: 0.6435, Loss: 0.5973
Epoch   3 Batch  103/269 - Train Accuracy: 0.6350, Validation Accuracy: 0.6460, Loss: 0.5896
Epoch   3 Batch  104/269 - Train Accuracy: 0.6309, Validation Accuracy: 0.6469, Loss: 0.5896
Epoch   3 Batch  105/269 - Train Accuracy: 0.6307, Validation Accuracy: 0.6483, Loss: 0.6070
Epoch   3 Batch  106/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6493, Loss: 0.5837
Epoch   3 Batch  107/269 - Train Accuracy: 0.6010, Validation Accuracy: 0.6452, Loss: 0.6305
Epoch   3 Batch  108/269 - Train Accuracy: 0.6357, Validation Accuracy: 0.6453, Loss: 0.5871
Epoch   3 Batch  109/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6456, Loss: 0.6005
Epoch   3 Batch  110/269 - Train Accuracy: 0.6381, Validation Accuracy: 0.6450, Loss: 0.5786
Epoch   3 Batch  111/269 - Train Accuracy: 0.6118, Validation Accuracy: 0.6472, Loss: 0.6259
Epoch   3 Batch  112/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6477, Loss: 0.5901
Epoch   3 Batch  113/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6453, Loss: 0.5636
Epoch   3 Batch  114/269 - Train Accuracy: 0.6394, Validation Accuracy: 0.6397, Loss: 0.5803
Epoch   3 Batch  115/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6404, Loss: 0.6150
Epoch   3 Batch  116/269 - Train Accuracy: 0.6450, Validation Accuracy: 0.6388, Loss: 0.6021
Epoch   3 Batch  117/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6384, Loss: 0.5877
Epoch   3 Batch  118/269 - Train Accuracy: 0.6593, Validation Accuracy: 0.6412, Loss: 0.5728
Epoch   3 Batch  119/269 - Train Accuracy: 0.6354, Validation Accuracy: 0.6444, Loss: 0.6080
Epoch   3 Batch  120/269 - Train Accuracy: 0.6421, Validation Accuracy: 0.6452, Loss: 0.5985
Epoch   3 Batch  121/269 - Train Accuracy: 0.6438, Validation Accuracy: 0.6402, Loss: 0.5777
Epoch   3 Batch  122/269 - Train Accuracy: 0.6430, Validation Accuracy: 0.6453, Loss: 0.5845
Epoch   3 Batch  123/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6452, Loss: 0.6066
Epoch   3 Batch  124/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6444, Loss: 0.5752
Epoch   3 Batch  125/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6452, Loss: 0.5669
Epoch   3 Batch  126/269 - Train Accuracy: 0.6450, Validation Accuracy: 0.6450, Loss: 0.5738
Epoch   3 Batch  127/269 - Train Accuracy: 0.6309, Validation Accuracy: 0.6475, Loss: 0.6097
Epoch   3 Batch  128/269 - Train Accuracy: 0.6574, Validation Accuracy: 0.6509, Loss: 0.5854
Epoch   3 Batch  129/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6499, Loss: 0.5755
Epoch   3 Batch  130/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6495, Loss: 0.6082
Epoch   3 Batch  131/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6541, Loss: 0.5971
Epoch   3 Batch  132/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6505, Loss: 0.5846
Epoch   3 Batch  133/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6425, Loss: 0.5636
Epoch   3 Batch  134/269 - Train Accuracy: 0.6241, Validation Accuracy: 0.6456, Loss: 0.5883
Epoch   3 Batch  135/269 - Train Accuracy: 0.6048, Validation Accuracy: 0.6432, Loss: 0.6170
Epoch   3 Batch  136/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6470, Loss: 0.6175
Epoch   3 Batch  137/269 - Train Accuracy: 0.6266, Validation Accuracy: 0.6525, Loss: 0.6133
Epoch   3 Batch  138/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6443, Loss: 0.5997
Epoch   3 Batch  139/269 - Train Accuracy: 0.6623, Validation Accuracy: 0.6527, Loss: 0.5640
Epoch   3 Batch  140/269 - Train Accuracy: 0.6386, Validation Accuracy: 0.6523, Loss: 0.5924
Epoch   3 Batch  141/269 - Train Accuracy: 0.6427, Validation Accuracy: 0.6530, Loss: 0.5942
Epoch   3 Batch  142/269 - Train Accuracy: 0.6466, Validation Accuracy: 0.6434, Loss: 0.5637
Epoch   3 Batch  143/269 - Train Accuracy: 0.6392, Validation Accuracy: 0.6510, Loss: 0.5739
Epoch   3 Batch  144/269 - Train Accuracy: 0.6585, Validation Accuracy: 0.6530, Loss: 0.5608
Epoch   3 Batch  145/269 - Train Accuracy: 0.6483, Validation Accuracy: 0.6520, Loss: 0.5748
Epoch   3 Batch  146/269 - Train Accuracy: 0.6410, Validation Accuracy: 0.6452, Loss: 0.5620
Epoch   3 Batch  147/269 - Train Accuracy: 0.6535, Validation Accuracy: 0.6507, Loss: 0.5576
Epoch   3 Batch  148/269 - Train Accuracy: 0.6479, Validation Accuracy: 0.6543, Loss: 0.5838
Epoch   3 Batch  149/269 - Train Accuracy: 0.6369, Validation Accuracy: 0.6484, Loss: 0.5784
Epoch   3 Batch  150/269 - Train Accuracy: 0.6538, Validation Accuracy: 0.6524, Loss: 0.5812
Epoch   3 Batch  151/269 - Train Accuracy: 0.6754, Validation Accuracy: 0.6570, Loss: 0.5553
Epoch   3 Batch  152/269 - Train Accuracy: 0.6567, Validation Accuracy: 0.6557, Loss: 0.5708
Epoch   3 Batch  153/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6620, Loss: 0.5650
Epoch   3 Batch  154/269 - Train Accuracy: 0.6330, Validation Accuracy: 0.6601, Loss: 0.5878
Epoch   3 Batch  155/269 - Train Accuracy: 0.6809, Validation Accuracy: 0.6535, Loss: 0.5458
Epoch   3 Batch  156/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6505, Loss: 0.5973
Epoch   3 Batch  157/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6515, Loss: 0.5708
Epoch   3 Batch  158/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6450, Loss: 0.5694
Epoch   3 Batch  159/269 - Train Accuracy: 0.6302, Validation Accuracy: 0.6407, Loss: 0.5749
Epoch   3 Batch  160/269 - Train Accuracy: 0.6491, Validation Accuracy: 0.6552, Loss: 0.5646
Epoch   3 Batch  161/269 - Train Accuracy: 0.6508, Validation Accuracy: 0.6577, Loss: 0.5675
Epoch   3 Batch  162/269 - Train Accuracy: 0.6452, Validation Accuracy: 0.6499, Loss: 0.5694
Epoch   3 Batch  163/269 - Train Accuracy: 0.6610, Validation Accuracy: 0.6483, Loss: 0.5603
Epoch   3 Batch  164/269 - Train Accuracy: 0.6508, Validation Accuracy: 0.6531, Loss: 0.5597
Epoch   3 Batch  165/269 - Train Accuracy: 0.6353, Validation Accuracy: 0.6588, Loss: 0.5813
Epoch   3 Batch  166/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6557, Loss: 0.5294
Epoch   3 Batch  167/269 - Train Accuracy: 0.6392, Validation Accuracy: 0.6491, Loss: 0.5625
Epoch   3 Batch  168/269 - Train Accuracy: 0.6383, Validation Accuracy: 0.6613, Loss: 0.5661
Epoch   3 Batch  169/269 - Train Accuracy: 0.6442, Validation Accuracy: 0.6620, Loss: 0.5662
Epoch   3 Batch  170/269 - Train Accuracy: 0.6488, Validation Accuracy: 0.6611, Loss: 0.5580
Epoch   3 Batch  171/269 - Train Accuracy: 0.6544, Validation Accuracy: 0.6513, Loss: 0.5788
Epoch   3 Batch  172/269 - Train Accuracy: 0.6424, Validation Accuracy: 0.6582, Loss: 0.5692
Epoch   3 Batch  173/269 - Train Accuracy: 0.6472, Validation Accuracy: 0.6549, Loss: 0.5476
Epoch   3 Batch  174/269 - Train Accuracy: 0.6397, Validation Accuracy: 0.6577, Loss: 0.5633
Epoch   3 Batch  175/269 - Train Accuracy: 0.6479, Validation Accuracy: 0.6547, Loss: 0.5717
Epoch   3 Batch  176/269 - Train Accuracy: 0.6233, Validation Accuracy: 0.6564, Loss: 0.6035
Epoch   3 Batch  177/269 - Train Accuracy: 0.6574, Validation Accuracy: 0.6554, Loss: 0.5399
Epoch   3 Batch  178/269 - Train Accuracy: 0.6404, Validation Accuracy: 0.6558, Loss: 0.5707
Epoch   3 Batch  179/269 - Train Accuracy: 0.6593, Validation Accuracy: 0.6531, Loss: 0.5668
Epoch   3 Batch  180/269 - Train Accuracy: 0.6519, Validation Accuracy: 0.6570, Loss: 0.5626
Epoch   3 Batch  181/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6573, Loss: 0.5621
Epoch   3 Batch  182/269 - Train Accuracy: 0.6588, Validation Accuracy: 0.6567, Loss: 0.5593
Epoch   3 Batch  183/269 - Train Accuracy: 0.6936, Validation Accuracy: 0.6588, Loss: 0.4853
Epoch   3 Batch  184/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6620, Loss: 0.5686
Epoch   3 Batch  185/269 - Train Accuracy: 0.6624, Validation Accuracy: 0.6587, Loss: 0.5506
Epoch   3 Batch  186/269 - Train Accuracy: 0.6429, Validation Accuracy: 0.6555, Loss: 0.5672
Epoch   3 Batch  187/269 - Train Accuracy: 0.6586, Validation Accuracy: 0.6589, Loss: 0.5464
Epoch   3 Batch  188/269 - Train Accuracy: 0.6655, Validation Accuracy: 0.6592, Loss: 0.5378
Epoch   3 Batch  189/269 - Train Accuracy: 0.6510, Validation Accuracy: 0.6526, Loss: 0.5350
Epoch   3 Batch  190/269 - Train Accuracy: 0.6346, Validation Accuracy: 0.6576, Loss: 0.5469
Epoch   3 Batch  191/269 - Train Accuracy: 0.6595, Validation Accuracy: 0.6606, Loss: 0.5436
Epoch   3 Batch  192/269 - Train Accuracy: 0.6671, Validation Accuracy: 0.6629, Loss: 0.5536
Epoch   3 Batch  193/269 - Train Accuracy: 0.6660, Validation Accuracy: 0.6681, Loss: 0.5418
Epoch   3 Batch  194/269 - Train Accuracy: 0.6633, Validation Accuracy: 0.6659, Loss: 0.5506
Epoch   3 Batch  195/269 - Train Accuracy: 0.6377, Validation Accuracy: 0.6618, Loss: 0.5532
Epoch   3 Batch  196/269 - Train Accuracy: 0.6462, Validation Accuracy: 0.6614, Loss: 0.5482
Epoch   3 Batch  197/269 - Train Accuracy: 0.6259, Validation Accuracy: 0.6653, Loss: 0.5758
Epoch   3 Batch  198/269 - Train Accuracy: 0.6291, Validation Accuracy: 0.6591, Loss: 0.5796
Epoch   3 Batch  199/269 - Train Accuracy: 0.6493, Validation Accuracy: 0.6569, Loss: 0.5597
Epoch   3 Batch  200/269 - Train Accuracy: 0.6511, Validation Accuracy: 0.6588, Loss: 0.5636
Epoch   3 Batch  201/269 - Train Accuracy: 0.6520, Validation Accuracy: 0.6600, Loss: 0.5458
Epoch   3 Batch  202/269 - Train Accuracy: 0.6461, Validation Accuracy: 0.6507, Loss: 0.5456
Epoch   3 Batch  203/269 - Train Accuracy: 0.6329, Validation Accuracy: 0.6638, Loss: 0.5847
Epoch   3 Batch  204/269 - Train Accuracy: 0.6468, Validation Accuracy: 0.6622, Loss: 0.5739
Epoch   3 Batch  205/269 - Train Accuracy: 0.6563, Validation Accuracy: 0.6574, Loss: 0.5389
Epoch   3 Batch  206/269 - Train Accuracy: 0.6383, Validation Accuracy: 0.6594, Loss: 0.5697
Epoch   3 Batch  207/269 - Train Accuracy: 0.6746, Validation Accuracy: 0.6616, Loss: 0.5282
Epoch   3 Batch  208/269 - Train Accuracy: 0.6419, Validation Accuracy: 0.6551, Loss: 0.5734
Epoch   3 Batch  209/269 - Train Accuracy: 0.6548, Validation Accuracy: 0.6585, Loss: 0.5513
Epoch   3 Batch  210/269 - Train Accuracy: 0.6740, Validation Accuracy: 0.6715, Loss: 0.5334
Epoch   3 Batch  211/269 - Train Accuracy: 0.6417, Validation Accuracy: 0.6688, Loss: 0.5527
Epoch   3 Batch  212/269 - Train Accuracy: 0.6614, Validation Accuracy: 0.6635, Loss: 0.5393
Epoch   3 Batch  213/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6702, Loss: 0.5464
Epoch   3 Batch  214/269 - Train Accuracy: 0.6777, Validation Accuracy: 0.6665, Loss: 0.5483
Epoch   3 Batch  215/269 - Train Accuracy: 0.6822, Validation Accuracy: 0.6547, Loss: 0.5059
Epoch   3 Batch  216/269 - Train Accuracy: 0.6244, Validation Accuracy: 0.6650, Loss: 0.5910
Epoch   3 Batch  217/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6680, Loss: 0.5637
Epoch   3 Batch  218/269 - Train Accuracy: 0.6431, Validation Accuracy: 0.6610, Loss: 0.5609
Epoch   3 Batch  219/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6541, Loss: 0.5547
Epoch   3 Batch  220/269 - Train Accuracy: 0.6554, Validation Accuracy: 0.6629, Loss: 0.5156
Epoch   3 Batch  221/269 - Train Accuracy: 0.6702, Validation Accuracy: 0.6750, Loss: 0.5360
Epoch   3 Batch  222/269 - Train Accuracy: 0.6719, Validation Accuracy: 0.6649, Loss: 0.5245
Epoch   3 Batch  223/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6619, Loss: 0.5312
Epoch   3 Batch  224/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6621, Loss: 0.5536
Epoch   3 Batch  225/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6716, Loss: 0.5410
Epoch   3 Batch  226/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.6705, Loss: 0.5323
Epoch   3 Batch  227/269 - Train Accuracy: 0.7017, Validation Accuracy: 0.6614, Loss: 0.4794
Epoch   3 Batch  228/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6664, Loss: 0.5332
Epoch   3 Batch  229/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6745, Loss: 0.5325
Epoch   3 Batch  230/269 - Train Accuracy: 0.6636, Validation Accuracy: 0.6701, Loss: 0.5295
Epoch   3 Batch  231/269 - Train Accuracy: 0.6426, Validation Accuracy: 0.6647, Loss: 0.5578
Epoch   3 Batch  232/269 - Train Accuracy: 0.6519, Validation Accuracy: 0.6776, Loss: 0.5551
Epoch   3 Batch  233/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6758, Loss: 0.5430
Epoch   3 Batch  234/269 - Train Accuracy: 0.6615, Validation Accuracy: 0.6694, Loss: 0.5381
Epoch   3 Batch  235/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.6610, Loss: 0.5210
Epoch   3 Batch  236/269 - Train Accuracy: 0.6650, Validation Accuracy: 0.6699, Loss: 0.5274
Epoch   3 Batch  237/269 - Train Accuracy: 0.6479, Validation Accuracy: 0.6817, Loss: 0.5278
Epoch   3 Batch  238/269 - Train Accuracy: 0.6934, Validation Accuracy: 0.6713, Loss: 0.5239
Epoch   3 Batch  239/269 - Train Accuracy: 0.6711, Validation Accuracy: 0.6671, Loss: 0.5250
Epoch   3 Batch  240/269 - Train Accuracy: 0.6973, Validation Accuracy: 0.6702, Loss: 0.4829
Epoch   3 Batch  241/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.6752, Loss: 0.5317
Epoch   3 Batch  242/269 - Train Accuracy: 0.6702, Validation Accuracy: 0.6791, Loss: 0.5248
Epoch   3 Batch  243/269 - Train Accuracy: 0.6778, Validation Accuracy: 0.6638, Loss: 0.5118
Epoch   3 Batch  244/269 - Train Accuracy: 0.6471, Validation Accuracy: 0.6657, Loss: 0.5275
Epoch   3 Batch  245/269 - Train Accuracy: 0.6492, Validation Accuracy: 0.6794, Loss: 0.5557
Epoch   3 Batch  246/269 - Train Accuracy: 0.6629, Validation Accuracy: 0.6764, Loss: 0.5290
Epoch   3 Batch  247/269 - Train Accuracy: 0.6487, Validation Accuracy: 0.6633, Loss: 0.5424
Epoch   3 Batch  248/269 - Train Accuracy: 0.6623, Validation Accuracy: 0.6759, Loss: 0.5248
Epoch   3 Batch  249/269 - Train Accuracy: 0.6850, Validation Accuracy: 0.6801, Loss: 0.5003
Epoch   3 Batch  250/269 - Train Accuracy: 0.6627, Validation Accuracy: 0.6699, Loss: 0.5336
Epoch   3 Batch  251/269 - Train Accuracy: 0.6847, Validation Accuracy: 0.6582, Loss: 0.5151
Epoch   3 Batch  252/269 - Train Accuracy: 0.6479, Validation Accuracy: 0.6540, Loss: 0.5371
Epoch   3 Batch  253/269 - Train Accuracy: 0.6380, Validation Accuracy: 0.6728, Loss: 0.5295
Epoch   3 Batch  254/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6764, Loss: 0.5206
Epoch   3 Batch  255/269 - Train Accuracy: 0.6780, Validation Accuracy: 0.6601, Loss: 0.5120
Epoch   3 Batch  256/269 - Train Accuracy: 0.6388, Validation Accuracy: 0.6589, Loss: 0.5413
Epoch   3 Batch  257/269 - Train Accuracy: 0.6569, Validation Accuracy: 0.6798, Loss: 0.5286
Epoch   3 Batch  258/269 - Train Accuracy: 0.6596, Validation Accuracy: 0.6760, Loss: 0.5328
Epoch   3 Batch  259/269 - Train Accuracy: 0.6697, Validation Accuracy: 0.6686, Loss: 0.5220
Epoch   3 Batch  260/269 - Train Accuracy: 0.6467, Validation Accuracy: 0.6715, Loss: 0.5485
Epoch   3 Batch  261/269 - Train Accuracy: 0.6459, Validation Accuracy: 0.6680, Loss: 0.5523
Epoch   3 Batch  262/269 - Train Accuracy: 0.6687, Validation Accuracy: 0.6662, Loss: 0.5278
Epoch   3 Batch  263/269 - Train Accuracy: 0.6674, Validation Accuracy: 0.6724, Loss: 0.5402
Epoch   3 Batch  264/269 - Train Accuracy: 0.6528, Validation Accuracy: 0.6630, Loss: 0.5505
Epoch   3 Batch  265/269 - Train Accuracy: 0.6561, Validation Accuracy: 0.6725, Loss: 0.5353
Epoch   3 Batch  266/269 - Train Accuracy: 0.6819, Validation Accuracy: 0.6808, Loss: 0.5106
Epoch   3 Batch  267/269 - Train Accuracy: 0.6657, Validation Accuracy: 0.6719, Loss: 0.5222
Epoch   4 Batch    1/269 - Train Accuracy: 0.6647, Validation Accuracy: 0.6859, Loss: 0.5400
Epoch   4 Batch    2/269 - Train Accuracy: 0.6552, Validation Accuracy: 0.6810, Loss: 0.5228
Epoch   4 Batch    3/269 - Train Accuracy: 0.6757, Validation Accuracy: 0.6641, Loss: 0.5264
Epoch   4 Batch    4/269 - Train Accuracy: 0.6358, Validation Accuracy: 0.6749, Loss: 0.5398
Epoch   4 Batch    5/269 - Train Accuracy: 0.6463, Validation Accuracy: 0.6857, Loss: 0.5322
Epoch   4 Batch    6/269 - Train Accuracy: 0.6716, Validation Accuracy: 0.6687, Loss: 0.5031
Epoch   4 Batch    7/269 - Train Accuracy: 0.6588, Validation Accuracy: 0.6590, Loss: 0.5094
Epoch   4 Batch    8/269 - Train Accuracy: 0.6657, Validation Accuracy: 0.6758, Loss: 0.5442
Epoch   4 Batch    9/269 - Train Accuracy: 0.6532, Validation Accuracy: 0.6776, Loss: 0.5190
Epoch   4 Batch   10/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6729, Loss: 0.5275
Epoch   4 Batch   11/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.6612, Loss: 0.5306
Epoch   4 Batch   12/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6699, Loss: 0.5531
Epoch   4 Batch   13/269 - Train Accuracy: 0.6800, Validation Accuracy: 0.6810, Loss: 0.4864
Epoch   4 Batch   14/269 - Train Accuracy: 0.6665, Validation Accuracy: 0.6752, Loss: 0.5080
Epoch   4 Batch   15/269 - Train Accuracy: 0.6522, Validation Accuracy: 0.6730, Loss: 0.5069
Epoch   4 Batch   16/269 - Train Accuracy: 0.6693, Validation Accuracy: 0.6859, Loss: 0.5271
Epoch   4 Batch   17/269 - Train Accuracy: 0.6684, Validation Accuracy: 0.6763, Loss: 0.5025
Epoch   4 Batch   18/269 - Train Accuracy: 0.6622, Validation Accuracy: 0.6765, Loss: 0.5319
Epoch   4 Batch   19/269 - Train Accuracy: 0.6869, Validation Accuracy: 0.6721, Loss: 0.4862
Epoch   4 Batch   20/269 - Train Accuracy: 0.6559, Validation Accuracy: 0.6736, Loss: 0.5291
Epoch   4 Batch   21/269 - Train Accuracy: 0.6553, Validation Accuracy: 0.6794, Loss: 0.5584
Epoch   4 Batch   22/269 - Train Accuracy: 0.6793, Validation Accuracy: 0.6805, Loss: 0.4920
Epoch   4 Batch   23/269 - Train Accuracy: 0.6617, Validation Accuracy: 0.6671, Loss: 0.5125
Epoch   4 Batch   24/269 - Train Accuracy: 0.6422, Validation Accuracy: 0.6819, Loss: 0.5345
Epoch   4 Batch   25/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6733, Loss: 0.5441
Epoch   4 Batch   26/269 - Train Accuracy: 0.6894, Validation Accuracy: 0.6737, Loss: 0.4778
Epoch   4 Batch   27/269 - Train Accuracy: 0.6553, Validation Accuracy: 0.6826, Loss: 0.5014
Epoch   4 Batch   28/269 - Train Accuracy: 0.6349, Validation Accuracy: 0.6780, Loss: 0.5423
Epoch   4 Batch   29/269 - Train Accuracy: 0.6553, Validation Accuracy: 0.6684, Loss: 0.5238
Epoch   4 Batch   30/269 - Train Accuracy: 0.6917, Validation Accuracy: 0.6777, Loss: 0.5013
Epoch   4 Batch   31/269 - Train Accuracy: 0.6712, Validation Accuracy: 0.6797, Loss: 0.4930
Epoch   4 Batch   32/269 - Train Accuracy: 0.6801, Validation Accuracy: 0.6788, Loss: 0.5028
Epoch   4 Batch   33/269 - Train Accuracy: 0.6829, Validation Accuracy: 0.6728, Loss: 0.4825
Epoch   4 Batch   34/269 - Train Accuracy: 0.6677, Validation Accuracy: 0.6740, Loss: 0.5015
Epoch   4 Batch   35/269 - Train Accuracy: 0.6750, Validation Accuracy: 0.6728, Loss: 0.5138
Epoch   4 Batch   36/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.6791, Loss: 0.5035
Epoch   4 Batch   37/269 - Train Accuracy: 0.6782, Validation Accuracy: 0.6688, Loss: 0.5041
Epoch   4 Batch   38/269 - Train Accuracy: 0.6851, Validation Accuracy: 0.6774, Loss: 0.5019
Epoch   4 Batch   39/269 - Train Accuracy: 0.6676, Validation Accuracy: 0.6808, Loss: 0.4967
Epoch   4 Batch   40/269 - Train Accuracy: 0.6454, Validation Accuracy: 0.6714, Loss: 0.5159
Epoch   4 Batch   41/269 - Train Accuracy: 0.6722, Validation Accuracy: 0.6904, Loss: 0.5140
Epoch   4 Batch   42/269 - Train Accuracy: 0.6930, Validation Accuracy: 0.6821, Loss: 0.4802
Epoch   4 Batch   43/269 - Train Accuracy: 0.6676, Validation Accuracy: 0.6606, Loss: 0.5157
Epoch   4 Batch   44/269 - Train Accuracy: 0.6807, Validation Accuracy: 0.6824, Loss: 0.5059
Epoch   4 Batch   45/269 - Train Accuracy: 0.6604, Validation Accuracy: 0.6824, Loss: 0.5197
Epoch   4 Batch   46/269 - Train Accuracy: 0.6581, Validation Accuracy: 0.6745, Loss: 0.5191
Epoch   4 Batch   47/269 - Train Accuracy: 0.6934, Validation Accuracy: 0.6745, Loss: 0.4712
Epoch   4 Batch   48/269 - Train Accuracy: 0.6803, Validation Accuracy: 0.6807, Loss: 0.4804
Epoch   4 Batch   49/269 - Train Accuracy: 0.6733, Validation Accuracy: 0.6876, Loss: 0.5068
Epoch   4 Batch   50/269 - Train Accuracy: 0.6627, Validation Accuracy: 0.6894, Loss: 0.5128
Epoch   4 Batch   51/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6898, Loss: 0.4970
Epoch   4 Batch   52/269 - Train Accuracy: 0.6624, Validation Accuracy: 0.6900, Loss: 0.4843
Epoch   4 Batch   53/269 - Train Accuracy: 0.6577, Validation Accuracy: 0.6833, Loss: 0.5176
Epoch   4 Batch   54/269 - Train Accuracy: 0.6857, Validation Accuracy: 0.6882, Loss: 0.5093
Epoch   4 Batch   55/269 - Train Accuracy: 0.6884, Validation Accuracy: 0.6886, Loss: 0.4832
Epoch   4 Batch   56/269 - Train Accuracy: 0.6778, Validation Accuracy: 0.6894, Loss: 0.4960
Epoch   4 Batch   57/269 - Train Accuracy: 0.6766, Validation Accuracy: 0.6936, Loss: 0.5052
Epoch   4 Batch   58/269 - Train Accuracy: 0.6844, Validation Accuracy: 0.6899, Loss: 0.4884
Epoch   4 Batch   59/269 - Train Accuracy: 0.7054, Validation Accuracy: 0.6814, Loss: 0.4647
Epoch   4 Batch   60/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.6868, Loss: 0.4656
Epoch   4 Batch   61/269 - Train Accuracy: 0.6885, Validation Accuracy: 0.6951, Loss: 0.4588
Epoch   4 Batch   62/269 - Train Accuracy: 0.6907, Validation Accuracy: 0.6922, Loss: 0.4763
Epoch   4 Batch   63/269 - Train Accuracy: 0.6803, Validation Accuracy: 0.6804, Loss: 0.5020
Epoch   4 Batch   64/269 - Train Accuracy: 0.6750, Validation Accuracy: 0.6839, Loss: 0.4843
Epoch   4 Batch   65/269 - Train Accuracy: 0.6824, Validation Accuracy: 0.6968, Loss: 0.4890
Epoch   4 Batch   66/269 - Train Accuracy: 0.6935, Validation Accuracy: 0.6926, Loss: 0.4770
Epoch   4 Batch   67/269 - Train Accuracy: 0.6826, Validation Accuracy: 0.6867, Loss: 0.5030
Epoch   4 Batch   68/269 - Train Accuracy: 0.6526, Validation Accuracy: 0.6832, Loss: 0.4945
Epoch   4 Batch   69/269 - Train Accuracy: 0.6471, Validation Accuracy: 0.6918, Loss: 0.5349
Epoch   4 Batch   70/269 - Train Accuracy: 0.6855, Validation Accuracy: 0.6942, Loss: 0.4938
Epoch   4 Batch   71/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6718, Loss: 0.5151
Epoch   4 Batch   72/269 - Train Accuracy: 0.6799, Validation Accuracy: 0.6887, Loss: 0.4919
Epoch   4 Batch   73/269 - Train Accuracy: 0.6642, Validation Accuracy: 0.6931, Loss: 0.5002
Epoch   4 Batch   74/269 - Train Accuracy: 0.6779, Validation Accuracy: 0.6797, Loss: 0.5023
Epoch   4 Batch   75/269 - Train Accuracy: 0.6908, Validation Accuracy: 0.6936, Loss: 0.4779
Epoch   4 Batch   76/269 - Train Accuracy: 0.6806, Validation Accuracy: 0.6957, Loss: 0.4962
Epoch   4 Batch   77/269 - Train Accuracy: 0.6964, Validation Accuracy: 0.6995, Loss: 0.4774
Epoch   4 Batch   78/269 - Train Accuracy: 0.6908, Validation Accuracy: 0.6831, Loss: 0.4746
Epoch   4 Batch   79/269 - Train Accuracy: 0.6824, Validation Accuracy: 0.6835, Loss: 0.4816
Epoch   4 Batch   80/269 - Train Accuracy: 0.6958, Validation Accuracy: 0.6978, Loss: 0.4746
Epoch   4 Batch   81/269 - Train Accuracy: 0.6983, Validation Accuracy: 0.6984, Loss: 0.4920
Epoch   4 Batch   82/269 - Train Accuracy: 0.6898, Validation Accuracy: 0.6746, Loss: 0.4645
Epoch   4 Batch   83/269 - Train Accuracy: 0.6756, Validation Accuracy: 0.6845, Loss: 0.4851
Epoch   4 Batch   84/269 - Train Accuracy: 0.6907, Validation Accuracy: 0.7014, Loss: 0.4684
Epoch   4 Batch   85/269 - Train Accuracy: 0.6871, Validation Accuracy: 0.6961, Loss: 0.4790
Epoch   4 Batch   86/269 - Train Accuracy: 0.6755, Validation Accuracy: 0.6984, Loss: 0.4807
Epoch   4 Batch   87/269 - Train Accuracy: 0.6721, Validation Accuracy: 0.6886, Loss: 0.5128
Epoch   4 Batch   88/269 - Train Accuracy: 0.6638, Validation Accuracy: 0.6776, Loss: 0.4863
Epoch   4 Batch   89/269 - Train Accuracy: 0.7002, Validation Accuracy: 0.7030, Loss: 0.4800
Epoch   4 Batch   90/269 - Train Accuracy: 0.6539, Validation Accuracy: 0.6895, Loss: 0.5104
Epoch   4 Batch   91/269 - Train Accuracy: 0.6857, Validation Accuracy: 0.6923, Loss: 0.4701
Epoch   4 Batch   92/269 - Train Accuracy: 0.6923, Validation Accuracy: 0.6954, Loss: 0.4641
Epoch   4 Batch   93/269 - Train Accuracy: 0.6895, Validation Accuracy: 0.6948, Loss: 0.4568
Epoch   4 Batch   94/269 - Train Accuracy: 0.6838, Validation Accuracy: 0.6915, Loss: 0.4854
Epoch   4 Batch   95/269 - Train Accuracy: 0.6796, Validation Accuracy: 0.6994, Loss: 0.4731
Epoch   4 Batch   96/269 - Train Accuracy: 0.6847, Validation Accuracy: 0.6893, Loss: 0.4755
Epoch   4 Batch   97/269 - Train Accuracy: 0.6789, Validation Accuracy: 0.6847, Loss: 0.4744
Epoch   4 Batch   98/269 - Train Accuracy: 0.6878, Validation Accuracy: 0.7078, Loss: 0.4784
Epoch   4 Batch   99/269 - Train Accuracy: 0.6672, Validation Accuracy: 0.6973, Loss: 0.4876
Epoch   4 Batch  100/269 - Train Accuracy: 0.6825, Validation Accuracy: 0.6839, Loss: 0.4767
Epoch   4 Batch  101/269 - Train Accuracy: 0.6776, Validation Accuracy: 0.7129, Loss: 0.5006
Epoch   4 Batch  102/269 - Train Accuracy: 0.6842, Validation Accuracy: 0.7091, Loss: 0.4740
Epoch   4 Batch  103/269 - Train Accuracy: 0.6946, Validation Accuracy: 0.6983, Loss: 0.4692
Epoch   4 Batch  104/269 - Train Accuracy: 0.6956, Validation Accuracy: 0.7044, Loss: 0.4661
Epoch   4 Batch  105/269 - Train Accuracy: 0.6813, Validation Accuracy: 0.7108, Loss: 0.4748
Epoch   4 Batch  106/269 - Train Accuracy: 0.6846, Validation Accuracy: 0.6904, Loss: 0.4748
Epoch   4 Batch  107/269 - Train Accuracy: 0.6923, Validation Accuracy: 0.7025, Loss: 0.4943
Epoch   4 Batch  108/269 - Train Accuracy: 0.6879, Validation Accuracy: 0.6991, Loss: 0.4666
Epoch   4 Batch  109/269 - Train Accuracy: 0.6742, Validation Accuracy: 0.7077, Loss: 0.4770
Epoch   4 Batch  110/269 - Train Accuracy: 0.6929, Validation Accuracy: 0.7005, Loss: 0.4612
Epoch   4 Batch  111/269 - Train Accuracy: 0.6650, Validation Accuracy: 0.6951, Loss: 0.5021
Epoch   4 Batch  112/269 - Train Accuracy: 0.6831, Validation Accuracy: 0.6943, Loss: 0.4736
Epoch   4 Batch  113/269 - Train Accuracy: 0.6961, Validation Accuracy: 0.6988, Loss: 0.4505
Epoch   4 Batch  114/269 - Train Accuracy: 0.7044, Validation Accuracy: 0.7027, Loss: 0.4691
Epoch   4 Batch  115/269 - Train Accuracy: 0.6809, Validation Accuracy: 0.7029, Loss: 0.4900
Epoch   4 Batch  116/269 - Train Accuracy: 0.6970, Validation Accuracy: 0.7034, Loss: 0.4796
Epoch   4 Batch  117/269 - Train Accuracy: 0.6935, Validation Accuracy: 0.7004, Loss: 0.4620
Epoch   4 Batch  118/269 - Train Accuracy: 0.7189, Validation Accuracy: 0.7039, Loss: 0.4569
Epoch   4 Batch  119/269 - Train Accuracy: 0.6940, Validation Accuracy: 0.7074, Loss: 0.4892
Epoch   4 Batch  120/269 - Train Accuracy: 0.6887, Validation Accuracy: 0.7025, Loss: 0.4806
Epoch   4 Batch  121/269 - Train Accuracy: 0.6960, Validation Accuracy: 0.7058, Loss: 0.4571
Epoch   4 Batch  122/269 - Train Accuracy: 0.6968, Validation Accuracy: 0.7053, Loss: 0.4583
Epoch   4 Batch  123/269 - Train Accuracy: 0.6906, Validation Accuracy: 0.7040, Loss: 0.4827
Epoch   4 Batch  124/269 - Train Accuracy: 0.6945, Validation Accuracy: 0.6962, Loss: 0.4591
Epoch   4 Batch  125/269 - Train Accuracy: 0.6912, Validation Accuracy: 0.6966, Loss: 0.4502
Epoch   4 Batch  126/269 - Train Accuracy: 0.6839, Validation Accuracy: 0.7029, Loss: 0.4653
Epoch   4 Batch  127/269 - Train Accuracy: 0.6638, Validation Accuracy: 0.7004, Loss: 0.4763
Epoch   4 Batch  128/269 - Train Accuracy: 0.7108, Validation Accuracy: 0.6926, Loss: 0.4748
Epoch   4 Batch  129/269 - Train Accuracy: 0.6917, Validation Accuracy: 0.6958, Loss: 0.4637
Epoch   4 Batch  130/269 - Train Accuracy: 0.6843, Validation Accuracy: 0.7059, Loss: 0.4819
Epoch   4 Batch  131/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.7037, Loss: 0.4776
Epoch   4 Batch  132/269 - Train Accuracy: 0.6878, Validation Accuracy: 0.6994, Loss: 0.4702
Epoch   4 Batch  133/269 - Train Accuracy: 0.6966, Validation Accuracy: 0.6926, Loss: 0.4565
Epoch   4 Batch  134/269 - Train Accuracy: 0.6592, Validation Accuracy: 0.7067, Loss: 0.4740
Epoch   4 Batch  135/269 - Train Accuracy: 0.6623, Validation Accuracy: 0.7095, Loss: 0.4978
Epoch   4 Batch  136/269 - Train Accuracy: 0.6619, Validation Accuracy: 0.7003, Loss: 0.4894
Epoch   4 Batch  137/269 - Train Accuracy: 0.6878, Validation Accuracy: 0.7150, Loss: 0.4977
Epoch   4 Batch  138/269 - Train Accuracy: 0.6865, Validation Accuracy: 0.7045, Loss: 0.4740
Epoch   4 Batch  139/269 - Train Accuracy: 0.7249, Validation Accuracy: 0.7040, Loss: 0.4507
Epoch   4 Batch  140/269 - Train Accuracy: 0.6886, Validation Accuracy: 0.7087, Loss: 0.4696
Epoch   4 Batch  141/269 - Train Accuracy: 0.6905, Validation Accuracy: 0.7048, Loss: 0.4756
Epoch   4 Batch  142/269 - Train Accuracy: 0.6987, Validation Accuracy: 0.7123, Loss: 0.4473
Epoch   4 Batch  143/269 - Train Accuracy: 0.6849, Validation Accuracy: 0.7116, Loss: 0.4584
Epoch   4 Batch  144/269 - Train Accuracy: 0.7116, Validation Accuracy: 0.7172, Loss: 0.4430
Epoch   4 Batch  145/269 - Train Accuracy: 0.7134, Validation Accuracy: 0.7158, Loss: 0.4508
Epoch   4 Batch  146/269 - Train Accuracy: 0.7026, Validation Accuracy: 0.7135, Loss: 0.4505
Epoch   4 Batch  147/269 - Train Accuracy: 0.7067, Validation Accuracy: 0.7206, Loss: 0.4434
Epoch   4 Batch  148/269 - Train Accuracy: 0.6873, Validation Accuracy: 0.7226, Loss: 0.4516
Epoch   4 Batch  149/269 - Train Accuracy: 0.7033, Validation Accuracy: 0.7132, Loss: 0.4716
Epoch   4 Batch  150/269 - Train Accuracy: 0.7141, Validation Accuracy: 0.7150, Loss: 0.4590
Epoch   4 Batch  151/269 - Train Accuracy: 0.7229, Validation Accuracy: 0.7147, Loss: 0.4382
Epoch   4 Batch  152/269 - Train Accuracy: 0.7080, Validation Accuracy: 0.7094, Loss: 0.4588
Epoch   4 Batch  153/269 - Train Accuracy: 0.7094, Validation Accuracy: 0.7148, Loss: 0.4485
Epoch   4 Batch  154/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7211, Loss: 0.4671
Epoch   4 Batch  155/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7110, Loss: 0.4302
Epoch   4 Batch  156/269 - Train Accuracy: 0.6729, Validation Accuracy: 0.7130, Loss: 0.4691
Epoch   4 Batch  157/269 - Train Accuracy: 0.6986, Validation Accuracy: 0.7262, Loss: 0.4523
Epoch   4 Batch  158/269 - Train Accuracy: 0.7046, Validation Accuracy: 0.7128, Loss: 0.4564
Epoch   4 Batch  159/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.7186, Loss: 0.4581
Epoch   4 Batch  160/269 - Train Accuracy: 0.7155, Validation Accuracy: 0.7281, Loss: 0.4476
Epoch   4 Batch  161/269 - Train Accuracy: 0.7012, Validation Accuracy: 0.7282, Loss: 0.4562
Epoch   4 Batch  162/269 - Train Accuracy: 0.7126, Validation Accuracy: 0.7253, Loss: 0.4416
Epoch   4 Batch  163/269 - Train Accuracy: 0.7114, Validation Accuracy: 0.7346, Loss: 0.4500
Epoch   4 Batch  164/269 - Train Accuracy: 0.7230, Validation Accuracy: 0.7266, Loss: 0.4434
Epoch   4 Batch  165/269 - Train Accuracy: 0.7030, Validation Accuracy: 0.7219, Loss: 0.4564
Epoch   4 Batch  166/269 - Train Accuracy: 0.7121, Validation Accuracy: 0.7248, Loss: 0.4285
Epoch   4 Batch  167/269 - Train Accuracy: 0.7136, Validation Accuracy: 0.7255, Loss: 0.4457
Epoch   4 Batch  168/269 - Train Accuracy: 0.7034, Validation Accuracy: 0.7234, Loss: 0.4487
Epoch   4 Batch  169/269 - Train Accuracy: 0.7210, Validation Accuracy: 0.7201, Loss: 0.4540
Epoch   4 Batch  170/269 - Train Accuracy: 0.7036, Validation Accuracy: 0.7203, Loss: 0.4440
Epoch   4 Batch  171/269 - Train Accuracy: 0.7126, Validation Accuracy: 0.7237, Loss: 0.4679
Epoch   4 Batch  172/269 - Train Accuracy: 0.7146, Validation Accuracy: 0.7205, Loss: 0.4578
Epoch   4 Batch  173/269 - Train Accuracy: 0.7012, Validation Accuracy: 0.7153, Loss: 0.4310
Epoch   4 Batch  174/269 - Train Accuracy: 0.6998, Validation Accuracy: 0.7097, Loss: 0.4540
Epoch   4 Batch  175/269 - Train Accuracy: 0.7233, Validation Accuracy: 0.7254, Loss: 0.4618
Epoch   4 Batch  176/269 - Train Accuracy: 0.6904, Validation Accuracy: 0.7227, Loss: 0.4712
Epoch   4 Batch  177/269 - Train Accuracy: 0.7156, Validation Accuracy: 0.7248, Loss: 0.4241
Epoch   4 Batch  178/269 - Train Accuracy: 0.7112, Validation Accuracy: 0.7219, Loss: 0.4583
Epoch   4 Batch  179/269 - Train Accuracy: 0.7028, Validation Accuracy: 0.7167, Loss: 0.4494
Epoch   4 Batch  180/269 - Train Accuracy: 0.7101, Validation Accuracy: 0.7293, Loss: 0.4400
Epoch   4 Batch  181/269 - Train Accuracy: 0.7226, Validation Accuracy: 0.7307, Loss: 0.4447
Epoch   4 Batch  182/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.6976, Loss: 0.4513
Epoch   4 Batch  183/269 - Train Accuracy: 0.7588, Validation Accuracy: 0.7288, Loss: 0.3896
Epoch   4 Batch  184/269 - Train Accuracy: 0.6918, Validation Accuracy: 0.7205, Loss: 0.4533
Epoch   4 Batch  185/269 - Train Accuracy: 0.7162, Validation Accuracy: 0.7185, Loss: 0.4376
Epoch   4 Batch  186/269 - Train Accuracy: 0.7159, Validation Accuracy: 0.7256, Loss: 0.4481
Epoch   4 Batch  187/269 - Train Accuracy: 0.7234, Validation Accuracy: 0.7277, Loss: 0.4281
Epoch   4 Batch  188/269 - Train Accuracy: 0.7185, Validation Accuracy: 0.7234, Loss: 0.4300
Epoch   4 Batch  189/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7218, Loss: 0.4305
Epoch   4 Batch  190/269 - Train Accuracy: 0.6996, Validation Accuracy: 0.7264, Loss: 0.4274
Epoch   4 Batch  191/269 - Train Accuracy: 0.7193, Validation Accuracy: 0.7305, Loss: 0.4277
Epoch   4 Batch  192/269 - Train Accuracy: 0.7121, Validation Accuracy: 0.7140, Loss: 0.4412
Epoch   4 Batch  193/269 - Train Accuracy: 0.7360, Validation Accuracy: 0.7243, Loss: 0.4359
Epoch   4 Batch  194/269 - Train Accuracy: 0.7222, Validation Accuracy: 0.7235, Loss: 0.4474
Epoch   4 Batch  195/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7241, Loss: 0.4430
Epoch   4 Batch  196/269 - Train Accuracy: 0.7067, Validation Accuracy: 0.7273, Loss: 0.4290
Epoch   4 Batch  197/269 - Train Accuracy: 0.6904, Validation Accuracy: 0.7318, Loss: 0.4551
Epoch   4 Batch  198/269 - Train Accuracy: 0.7097, Validation Accuracy: 0.7335, Loss: 0.4569
Epoch   4 Batch  199/269 - Train Accuracy: 0.7032, Validation Accuracy: 0.7251, Loss: 0.4444
Epoch   4 Batch  200/269 - Train Accuracy: 0.7213, Validation Accuracy: 0.7330, Loss: 0.4477
Epoch   4 Batch  201/269 - Train Accuracy: 0.7085, Validation Accuracy: 0.7301, Loss: 0.4384
Epoch   4 Batch  202/269 - Train Accuracy: 0.7251, Validation Accuracy: 0.7313, Loss: 0.4318
Epoch   4 Batch  203/269 - Train Accuracy: 0.6983, Validation Accuracy: 0.7256, Loss: 0.4712
Epoch   4 Batch  204/269 - Train Accuracy: 0.7074, Validation Accuracy: 0.7315, Loss: 0.4621
Epoch   4 Batch  205/269 - Train Accuracy: 0.7179, Validation Accuracy: 0.7297, Loss: 0.4278
Epoch   4 Batch  206/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.7285, Loss: 0.4552
Epoch   4 Batch  207/269 - Train Accuracy: 0.7276, Validation Accuracy: 0.7326, Loss: 0.4232
Epoch   4 Batch  208/269 - Train Accuracy: 0.7151, Validation Accuracy: 0.7265, Loss: 0.4463
Epoch   4 Batch  209/269 - Train Accuracy: 0.7306, Validation Accuracy: 0.7243, Loss: 0.4389
Epoch   4 Batch  210/269 - Train Accuracy: 0.7247, Validation Accuracy: 0.7380, Loss: 0.4241
Epoch   4 Batch  211/269 - Train Accuracy: 0.7100, Validation Accuracy: 0.7317, Loss: 0.4279
Epoch   4 Batch  212/269 - Train Accuracy: 0.7287, Validation Accuracy: 0.7303, Loss: 0.4328
Epoch   4 Batch  213/269 - Train Accuracy: 0.7251, Validation Accuracy: 0.7249, Loss: 0.4249
Epoch   4 Batch  214/269 - Train Accuracy: 0.7259, Validation Accuracy: 0.7369, Loss: 0.4304
Epoch   4 Batch  215/269 - Train Accuracy: 0.7472, Validation Accuracy: 0.7210, Loss: 0.3969
Epoch   4 Batch  216/269 - Train Accuracy: 0.6863, Validation Accuracy: 0.7354, Loss: 0.4675
Epoch   4 Batch  217/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.7214, Loss: 0.4467
Epoch   4 Batch  218/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7314, Loss: 0.4423
Epoch   4 Batch  219/269 - Train Accuracy: 0.7207, Validation Accuracy: 0.7175, Loss: 0.4401
Epoch   4 Batch  220/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7300, Loss: 0.4091
Epoch   4 Batch  221/269 - Train Accuracy: 0.7328, Validation Accuracy: 0.7242, Loss: 0.4214
Epoch   4 Batch  222/269 - Train Accuracy: 0.7325, Validation Accuracy: 0.7349, Loss: 0.4150
Epoch   4 Batch  223/269 - Train Accuracy: 0.7076, Validation Accuracy: 0.7305, Loss: 0.4182
Epoch   4 Batch  224/269 - Train Accuracy: 0.7287, Validation Accuracy: 0.7343, Loss: 0.4384
Epoch   4 Batch  225/269 - Train Accuracy: 0.7137, Validation Accuracy: 0.7269, Loss: 0.4241
Epoch   4 Batch  226/269 - Train Accuracy: 0.7221, Validation Accuracy: 0.7391, Loss: 0.4167
Epoch   4 Batch  227/269 - Train Accuracy: 0.7649, Validation Accuracy: 0.7389, Loss: 0.3888
Epoch   4 Batch  228/269 - Train Accuracy: 0.7105, Validation Accuracy: 0.7326, Loss: 0.4295
Epoch   4 Batch  229/269 - Train Accuracy: 0.7179, Validation Accuracy: 0.7323, Loss: 0.4281
Epoch   4 Batch  230/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7320, Loss: 0.4203
Epoch   4 Batch  231/269 - Train Accuracy: 0.6998, Validation Accuracy: 0.7284, Loss: 0.4443
Epoch   4 Batch  232/269 - Train Accuracy: 0.7068, Validation Accuracy: 0.7357, Loss: 0.4467
Epoch   4 Batch  233/269 - Train Accuracy: 0.7397, Validation Accuracy: 0.7398, Loss: 0.4319
Epoch   4 Batch  234/269 - Train Accuracy: 0.7266, Validation Accuracy: 0.7243, Loss: 0.4240
Epoch   4 Batch  235/269 - Train Accuracy: 0.7352, Validation Accuracy: 0.7322, Loss: 0.4240
Epoch   4 Batch  236/269 - Train Accuracy: 0.7208, Validation Accuracy: 0.7360, Loss: 0.4146
Epoch   4 Batch  237/269 - Train Accuracy: 0.7124, Validation Accuracy: 0.7305, Loss: 0.4185
Epoch   4 Batch  238/269 - Train Accuracy: 0.7350, Validation Accuracy: 0.7310, Loss: 0.4129
Epoch   4 Batch  239/269 - Train Accuracy: 0.7385, Validation Accuracy: 0.7330, Loss: 0.4230
Epoch   4 Batch  240/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7297, Loss: 0.3891
Epoch   4 Batch  241/269 - Train Accuracy: 0.7243, Validation Accuracy: 0.7251, Loss: 0.4362
Epoch   4 Batch  242/269 - Train Accuracy: 0.7091, Validation Accuracy: 0.7302, Loss: 0.4159
Epoch   4 Batch  243/269 - Train Accuracy: 0.7234, Validation Accuracy: 0.7320, Loss: 0.4091
Epoch   4 Batch  244/269 - Train Accuracy: 0.7159, Validation Accuracy: 0.7349, Loss: 0.4234
Epoch   4 Batch  245/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.7243, Loss: 0.4344
Epoch   4 Batch  246/269 - Train Accuracy: 0.7045, Validation Accuracy: 0.7333, Loss: 0.4205
Epoch   4 Batch  247/269 - Train Accuracy: 0.7086, Validation Accuracy: 0.7259, Loss: 0.4343
Epoch   4 Batch  248/269 - Train Accuracy: 0.7251, Validation Accuracy: 0.7346, Loss: 0.4133
Epoch   4 Batch  249/269 - Train Accuracy: 0.7402, Validation Accuracy: 0.7277, Loss: 0.3940
Epoch   4 Batch  250/269 - Train Accuracy: 0.7235, Validation Accuracy: 0.7330, Loss: 0.4286
Epoch   4 Batch  251/269 - Train Accuracy: 0.7269, Validation Accuracy: 0.7225, Loss: 0.4097
Epoch   4 Batch  252/269 - Train Accuracy: 0.7135, Validation Accuracy: 0.7322, Loss: 0.4260
Epoch   4 Batch  253/269 - Train Accuracy: 0.6979, Validation Accuracy: 0.7290, Loss: 0.4172
Epoch   4 Batch  254/269 - Train Accuracy: 0.7187, Validation Accuracy: 0.7381, Loss: 0.4119
Epoch   4 Batch  255/269 - Train Accuracy: 0.7425, Validation Accuracy: 0.7301, Loss: 0.4062
Epoch   4 Batch  256/269 - Train Accuracy: 0.7133, Validation Accuracy: 0.7299, Loss: 0.4197
Epoch   4 Batch  257/269 - Train Accuracy: 0.7158, Validation Accuracy: 0.7362, Loss: 0.4258
Epoch   4 Batch  258/269 - Train Accuracy: 0.7163, Validation Accuracy: 0.7248, Loss: 0.4252
Epoch   4 Batch  259/269 - Train Accuracy: 0.7273, Validation Accuracy: 0.7336, Loss: 0.4178
Epoch   4 Batch  260/269 - Train Accuracy: 0.7126, Validation Accuracy: 0.7287, Loss: 0.4280
Epoch   4 Batch  261/269 - Train Accuracy: 0.7129, Validation Accuracy: 0.7264, Loss: 0.4401
Epoch   4 Batch  262/269 - Train Accuracy: 0.7388, Validation Accuracy: 0.7343, Loss: 0.4192
Epoch   4 Batch  263/269 - Train Accuracy: 0.7325, Validation Accuracy: 0.7445, Loss: 0.4242
Epoch   4 Batch  264/269 - Train Accuracy: 0.7217, Validation Accuracy: 0.7396, Loss: 0.4410
Epoch   4 Batch  265/269 - Train Accuracy: 0.7186, Validation Accuracy: 0.7431, Loss: 0.4195
Epoch   4 Batch  266/269 - Train Accuracy: 0.7442, Validation Accuracy: 0.7446, Loss: 0.4021
Epoch   4 Batch  267/269 - Train Accuracy: 0.7372, Validation Accuracy: 0.7417, Loss: 0.4256
Epoch   5 Batch    1/269 - Train Accuracy: 0.7301, Validation Accuracy: 0.7382, Loss: 0.4234
Epoch   5 Batch    2/269 - Train Accuracy: 0.7217, Validation Accuracy: 0.7455, Loss: 0.4118
Epoch   5 Batch    3/269 - Train Accuracy: 0.7330, Validation Accuracy: 0.7432, Loss: 0.4207
Epoch   5 Batch    4/269 - Train Accuracy: 0.7158, Validation Accuracy: 0.7459, Loss: 0.4201
Epoch   5 Batch    5/269 - Train Accuracy: 0.7169, Validation Accuracy: 0.7448, Loss: 0.4228
Epoch   5 Batch    6/269 - Train Accuracy: 0.7450, Validation Accuracy: 0.7445, Loss: 0.3930
Epoch   5 Batch    7/269 - Train Accuracy: 0.7224, Validation Accuracy: 0.7443, Loss: 0.4028
Epoch   5 Batch    8/269 - Train Accuracy: 0.7104, Validation Accuracy: 0.7393, Loss: 0.4243
Epoch   5 Batch    9/269 - Train Accuracy: 0.7253, Validation Accuracy: 0.7325, Loss: 0.4162
Epoch   5 Batch   10/269 - Train Accuracy: 0.7250, Validation Accuracy: 0.7440, Loss: 0.4152
Epoch   5 Batch   11/269 - Train Accuracy: 0.7325, Validation Accuracy: 0.7485, Loss: 0.4162
Epoch   5 Batch   12/269 - Train Accuracy: 0.7091, Validation Accuracy: 0.7384, Loss: 0.4283
Epoch   5 Batch   13/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7400, Loss: 0.3788
Epoch   5 Batch   14/269 - Train Accuracy: 0.7349, Validation Accuracy: 0.7481, Loss: 0.4026
Epoch   5 Batch   15/269 - Train Accuracy: 0.7125, Validation Accuracy: 0.7454, Loss: 0.3950
Epoch   5 Batch   16/269 - Train Accuracy: 0.7387, Validation Accuracy: 0.7315, Loss: 0.4056
Epoch   5 Batch   17/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7485, Loss: 0.3905
Epoch   5 Batch   18/269 - Train Accuracy: 0.7292, Validation Accuracy: 0.7497, Loss: 0.4126
Epoch   5 Batch   19/269 - Train Accuracy: 0.7488, Validation Accuracy: 0.7441, Loss: 0.3742
Epoch   5 Batch   20/269 - Train Accuracy: 0.7298, Validation Accuracy: 0.7446, Loss: 0.4118
Epoch   5 Batch   21/269 - Train Accuracy: 0.6992, Validation Accuracy: 0.7440, Loss: 0.4381
Epoch   5 Batch   22/269 - Train Accuracy: 0.7355, Validation Accuracy: 0.7371, Loss: 0.3809
Epoch   5 Batch   23/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7361, Loss: 0.4025
Epoch   5 Batch   24/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7456, Loss: 0.4203
Epoch   5 Batch   25/269 - Train Accuracy: 0.7272, Validation Accuracy: 0.7442, Loss: 0.4237
Epoch   5 Batch   26/269 - Train Accuracy: 0.7452, Validation Accuracy: 0.7443, Loss: 0.3769
Epoch   5 Batch   27/269 - Train Accuracy: 0.7254, Validation Accuracy: 0.7475, Loss: 0.4045
Epoch   5 Batch   28/269 - Train Accuracy: 0.6928, Validation Accuracy: 0.7371, Loss: 0.4337
Epoch   5 Batch   29/269 - Train Accuracy: 0.7210, Validation Accuracy: 0.7430, Loss: 0.4165
Epoch   5 Batch   30/269 - Train Accuracy: 0.7342, Validation Accuracy: 0.7467, Loss: 0.3969
Epoch   5 Batch   31/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7481, Loss: 0.3904
Epoch   5 Batch   32/269 - Train Accuracy: 0.7300, Validation Accuracy: 0.7476, Loss: 0.3948
Epoch   5 Batch   33/269 - Train Accuracy: 0.7516, Validation Accuracy: 0.7374, Loss: 0.3817
Epoch   5 Batch   34/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7480, Loss: 0.3943
Epoch   5 Batch   35/269 - Train Accuracy: 0.7407, Validation Accuracy: 0.7459, Loss: 0.4008
Epoch   5 Batch   36/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7345, Loss: 0.3972
Epoch   5 Batch   37/269 - Train Accuracy: 0.7343, Validation Accuracy: 0.7337, Loss: 0.3984
Epoch   5 Batch   38/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7455, Loss: 0.3995
Epoch   5 Batch   39/269 - Train Accuracy: 0.7321, Validation Accuracy: 0.7480, Loss: 0.3923
Epoch   5 Batch   40/269 - Train Accuracy: 0.7242, Validation Accuracy: 0.7423, Loss: 0.4061
Epoch   5 Batch   41/269 - Train Accuracy: 0.7372, Validation Accuracy: 0.7330, Loss: 0.3959
Epoch   5 Batch   42/269 - Train Accuracy: 0.7606, Validation Accuracy: 0.7507, Loss: 0.3720
Epoch   5 Batch   43/269 - Train Accuracy: 0.7385, Validation Accuracy: 0.7439, Loss: 0.4021
Epoch   5 Batch   44/269 - Train Accuracy: 0.7443, Validation Accuracy: 0.7322, Loss: 0.3964
Epoch   5 Batch   45/269 - Train Accuracy: 0.7508, Validation Accuracy: 0.7434, Loss: 0.4139
Epoch   5 Batch   46/269 - Train Accuracy: 0.7249, Validation Accuracy: 0.7425, Loss: 0.4047
Epoch   5 Batch   47/269 - Train Accuracy: 0.7657, Validation Accuracy: 0.7444, Loss: 0.3607
Epoch   5 Batch   48/269 - Train Accuracy: 0.7500, Validation Accuracy: 0.7415, Loss: 0.3814
Epoch   5 Batch   49/269 - Train Accuracy: 0.7411, Validation Accuracy: 0.7400, Loss: 0.3987
Epoch   5 Batch   50/269 - Train Accuracy: 0.7094, Validation Accuracy: 0.7393, Loss: 0.4127
Epoch   5 Batch   51/269 - Train Accuracy: 0.7286, Validation Accuracy: 0.7414, Loss: 0.3953
Epoch   5 Batch   52/269 - Train Accuracy: 0.7182, Validation Accuracy: 0.7297, Loss: 0.3815
Epoch   5 Batch   53/269 - Train Accuracy: 0.7156, Validation Accuracy: 0.7315, Loss: 0.4137
Epoch   5 Batch   54/269 - Train Accuracy: 0.7351, Validation Accuracy: 0.7363, Loss: 0.4043
Epoch   5 Batch   55/269 - Train Accuracy: 0.7541, Validation Accuracy: 0.7438, Loss: 0.3858
Epoch   5 Batch   56/269 - Train Accuracy: 0.7314, Validation Accuracy: 0.7320, Loss: 0.3934
Epoch   5 Batch   57/269 - Train Accuracy: 0.7328, Validation Accuracy: 0.7442, Loss: 0.3976
Epoch   5 Batch   58/269 - Train Accuracy: 0.7383, Validation Accuracy: 0.7516, Loss: 0.3886
Epoch   5 Batch   59/269 - Train Accuracy: 0.7492, Validation Accuracy: 0.7504, Loss: 0.3640
Epoch   5 Batch   60/269 - Train Accuracy: 0.7409, Validation Accuracy: 0.7435, Loss: 0.3703
Epoch   5 Batch   61/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7411, Loss: 0.3631
Epoch   5 Batch   62/269 - Train Accuracy: 0.7576, Validation Accuracy: 0.7519, Loss: 0.3770
Epoch   5 Batch   63/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7513, Loss: 0.3929
Epoch   5 Batch   64/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.7500, Loss: 0.3823
Epoch   5 Batch   65/269 - Train Accuracy: 0.7341, Validation Accuracy: 0.7390, Loss: 0.3816
Epoch   5 Batch   66/269 - Train Accuracy: 0.7468, Validation Accuracy: 0.7512, Loss: 0.3771
Epoch   5 Batch   67/269 - Train Accuracy: 0.7393, Validation Accuracy: 0.7503, Loss: 0.3869
Epoch   5 Batch   68/269 - Train Accuracy: 0.7143, Validation Accuracy: 0.7513, Loss: 0.3849
Epoch   5 Batch   69/269 - Train Accuracy: 0.7168, Validation Accuracy: 0.7525, Loss: 0.4213
Epoch   5 Batch   70/269 - Train Accuracy: 0.7476, Validation Accuracy: 0.7462, Loss: 0.3913
Epoch   5 Batch   71/269 - Train Accuracy: 0.7340, Validation Accuracy: 0.7494, Loss: 0.4070
Epoch   5 Batch   72/269 - Train Accuracy: 0.7383, Validation Accuracy: 0.7489, Loss: 0.3861
Epoch   5 Batch   73/269 - Train Accuracy: 0.7396, Validation Accuracy: 0.7518, Loss: 0.3930
Epoch   5 Batch   74/269 - Train Accuracy: 0.7519, Validation Accuracy: 0.7584, Loss: 0.3889
Epoch   5 Batch   75/269 - Train Accuracy: 0.7577, Validation Accuracy: 0.7538, Loss: 0.3778
Epoch   5 Batch   76/269 - Train Accuracy: 0.7238, Validation Accuracy: 0.7493, Loss: 0.3786
Epoch   5 Batch   77/269 - Train Accuracy: 0.7460, Validation Accuracy: 0.7493, Loss: 0.3750
Epoch   5 Batch   78/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7551, Loss: 0.3773
Epoch   5 Batch   79/269 - Train Accuracy: 0.7413, Validation Accuracy: 0.7529, Loss: 0.3784
Epoch   5 Batch   80/269 - Train Accuracy: 0.7494, Validation Accuracy: 0.7529, Loss: 0.3785
Epoch   5 Batch   81/269 - Train Accuracy: 0.7518, Validation Accuracy: 0.7513, Loss: 0.3959
Epoch   5 Batch   82/269 - Train Accuracy: 0.7598, Validation Accuracy: 0.7475, Loss: 0.3643
Epoch   5 Batch   83/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7487, Loss: 0.3841
Epoch   5 Batch   84/269 - Train Accuracy: 0.7492, Validation Accuracy: 0.7496, Loss: 0.3681
Epoch   5 Batch   85/269 - Train Accuracy: 0.7539, Validation Accuracy: 0.7480, Loss: 0.3778
Epoch   5 Batch   86/269 - Train Accuracy: 0.7333, Validation Accuracy: 0.7512, Loss: 0.3796
Epoch   5 Batch   87/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7511, Loss: 0.4042
Epoch   5 Batch   88/269 - Train Accuracy: 0.7248, Validation Accuracy: 0.7526, Loss: 0.3821
Epoch   5 Batch   89/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7507, Loss: 0.3789
Epoch   5 Batch   90/269 - Train Accuracy: 0.7089, Validation Accuracy: 0.7472, Loss: 0.4017
Epoch   5 Batch   91/269 - Train Accuracy: 0.7641, Validation Accuracy: 0.7456, Loss: 0.3700
Epoch   5 Batch   92/269 - Train Accuracy: 0.7655, Validation Accuracy: 0.7470, Loss: 0.3643
Epoch   5 Batch   93/269 - Train Accuracy: 0.7362, Validation Accuracy: 0.7536, Loss: 0.3640
Epoch   5 Batch   94/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7527, Loss: 0.3838
Epoch   5 Batch   95/269 - Train Accuracy: 0.7379, Validation Accuracy: 0.7480, Loss: 0.3796
Epoch   5 Batch   96/269 - Train Accuracy: 0.7267, Validation Accuracy: 0.7374, Loss: 0.3780
Epoch   5 Batch   97/269 - Train Accuracy: 0.7422, Validation Accuracy: 0.7559, Loss: 0.3700
Epoch   5 Batch   98/269 - Train Accuracy: 0.7276, Validation Accuracy: 0.7532, Loss: 0.3771
Epoch   5 Batch   99/269 - Train Accuracy: 0.7301, Validation Accuracy: 0.7490, Loss: 0.3849
Epoch   5 Batch  100/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7536, Loss: 0.3684
Epoch   5 Batch  101/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7346, Loss: 0.3966
Epoch   5 Batch  102/269 - Train Accuracy: 0.7410, Validation Accuracy: 0.7574, Loss: 0.3802
Epoch   5 Batch  103/269 - Train Accuracy: 0.7418, Validation Accuracy: 0.7409, Loss: 0.3759
Epoch   5 Batch  104/269 - Train Accuracy: 0.7501, Validation Accuracy: 0.7401, Loss: 0.3725
Epoch   5 Batch  105/269 - Train Accuracy: 0.7338, Validation Accuracy: 0.7567, Loss: 0.3883
Epoch   5 Batch  106/269 - Train Accuracy: 0.7450, Validation Accuracy: 0.7498, Loss: 0.3696
Epoch   5 Batch  107/269 - Train Accuracy: 0.7309, Validation Accuracy: 0.7425, Loss: 0.3937
Epoch   5 Batch  108/269 - Train Accuracy: 0.7446, Validation Accuracy: 0.7508, Loss: 0.3833
Epoch   5 Batch  109/269 - Train Accuracy: 0.7234, Validation Accuracy: 0.7444, Loss: 0.3729
Epoch   5 Batch  110/269 - Train Accuracy: 0.7328, Validation Accuracy: 0.7474, Loss: 0.3845
Epoch   5 Batch  111/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7366, Loss: 0.4183
Epoch   5 Batch  112/269 - Train Accuracy: 0.7505, Validation Accuracy: 0.7515, Loss: 0.3813
Epoch   5 Batch  113/269 - Train Accuracy: 0.7425, Validation Accuracy: 0.7410, Loss: 0.3694
Epoch   5 Batch  114/269 - Train Accuracy: 0.7444, Validation Accuracy: 0.7485, Loss: 0.3731
Epoch   5 Batch  115/269 - Train Accuracy: 0.6940, Validation Accuracy: 0.7197, Loss: 0.3959
Epoch   5 Batch  116/269 - Train Accuracy: 0.7569, Validation Accuracy: 0.7473, Loss: 0.3942
Epoch   5 Batch  117/269 - Train Accuracy: 0.7319, Validation Accuracy: 0.7322, Loss: 0.3717
Epoch   5 Batch  118/269 - Train Accuracy: 0.7612, Validation Accuracy: 0.7395, Loss: 0.3635
Epoch   5 Batch  119/269 - Train Accuracy: 0.7224, Validation Accuracy: 0.7244, Loss: 0.4001
Epoch   5 Batch  120/269 - Train Accuracy: 0.7231, Validation Accuracy: 0.7343, Loss: 0.3825
Epoch   5 Batch  121/269 - Train Accuracy: 0.7538, Validation Accuracy: 0.7449, Loss: 0.3697
Epoch   5 Batch  122/269 - Train Accuracy: 0.7300, Validation Accuracy: 0.7312, Loss: 0.3606
Epoch   5 Batch  123/269 - Train Accuracy: 0.7449, Validation Accuracy: 0.7530, Loss: 0.3930
Epoch   5 Batch  124/269 - Train Accuracy: 0.7345, Validation Accuracy: 0.7317, Loss: 0.3546
Epoch   5 Batch  125/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7451, Loss: 0.3620
Epoch   5 Batch  126/269 - Train Accuracy: 0.7278, Validation Accuracy: 0.7449, Loss: 0.3564
Epoch   5 Batch  127/269 - Train Accuracy: 0.7295, Validation Accuracy: 0.7539, Loss: 0.3820
Epoch   5 Batch  128/269 - Train Accuracy: 0.7525, Validation Accuracy: 0.7391, Loss: 0.3693
Epoch   5 Batch  129/269 - Train Accuracy: 0.7477, Validation Accuracy: 0.7455, Loss: 0.3657
Epoch   5 Batch  130/269 - Train Accuracy: 0.7398, Validation Accuracy: 0.7614, Loss: 0.3825
Epoch   5 Batch  131/269 - Train Accuracy: 0.7295, Validation Accuracy: 0.7563, Loss: 0.3754
Epoch   5 Batch  132/269 - Train Accuracy: 0.7332, Validation Accuracy: 0.7444, Loss: 0.3738
Epoch   5 Batch  133/269 - Train Accuracy: 0.7570, Validation Accuracy: 0.7417, Loss: 0.3574
Epoch   5 Batch  134/269 - Train Accuracy: 0.7244, Validation Accuracy: 0.7509, Loss: 0.3754
Epoch   5 Batch  135/269 - Train Accuracy: 0.7275, Validation Accuracy: 0.7621, Loss: 0.3951
Epoch   5 Batch  136/269 - Train Accuracy: 0.7285, Validation Accuracy: 0.7559, Loss: 0.3918
Epoch   5 Batch  137/269 - Train Accuracy: 0.7224, Validation Accuracy: 0.7512, Loss: 0.3917
Epoch   5 Batch  138/269 - Train Accuracy: 0.7411, Validation Accuracy: 0.7561, Loss: 0.3672
Epoch   5 Batch  139/269 - Train Accuracy: 0.7692, Validation Accuracy: 0.7552, Loss: 0.3513
Epoch   5 Batch  140/269 - Train Accuracy: 0.7482, Validation Accuracy: 0.7569, Loss: 0.3777
Epoch   5 Batch  141/269 - Train Accuracy: 0.7413, Validation Accuracy: 0.7537, Loss: 0.3729
Epoch   5 Batch  142/269 - Train Accuracy: 0.7507, Validation Accuracy: 0.7543, Loss: 0.3615
Epoch   5 Batch  143/269 - Train Accuracy: 0.7344, Validation Accuracy: 0.7566, Loss: 0.3602
Epoch   5 Batch  144/269 - Train Accuracy: 0.7467, Validation Accuracy: 0.7520, Loss: 0.3460
Epoch   5 Batch  145/269 - Train Accuracy: 0.7576, Validation Accuracy: 0.7598, Loss: 0.3541
Epoch   5 Batch  146/269 - Train Accuracy: 0.7531, Validation Accuracy: 0.7552, Loss: 0.3545
Epoch   5 Batch  147/269 - Train Accuracy: 0.7635, Validation Accuracy: 0.7528, Loss: 0.3433
Epoch   5 Batch  148/269 - Train Accuracy: 0.7499, Validation Accuracy: 0.7591, Loss: 0.3681
Epoch   5 Batch  149/269 - Train Accuracy: 0.7504, Validation Accuracy: 0.7547, Loss: 0.3662
Epoch   5 Batch  150/269 - Train Accuracy: 0.7570, Validation Accuracy: 0.7560, Loss: 0.3584
Epoch   5 Batch  151/269 - Train Accuracy: 0.7626, Validation Accuracy: 0.7510, Loss: 0.3441
Epoch   5 Batch  152/269 - Train Accuracy: 0.7607, Validation Accuracy: 0.7583, Loss: 0.3637
Epoch   5 Batch  153/269 - Train Accuracy: 0.7484, Validation Accuracy: 0.7620, Loss: 0.3531
Epoch   5 Batch  154/269 - Train Accuracy: 0.7515, Validation Accuracy: 0.7561, Loss: 0.3707
Epoch   5 Batch  155/269 - Train Accuracy: 0.7574, Validation Accuracy: 0.7545, Loss: 0.3367
Epoch   5 Batch  156/269 - Train Accuracy: 0.7387, Validation Accuracy: 0.7568, Loss: 0.3699
Epoch   5 Batch  157/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7615, Loss: 0.3540
Epoch   5 Batch  158/269 - Train Accuracy: 0.7524, Validation Accuracy: 0.7579, Loss: 0.3550
Epoch   5 Batch  159/269 - Train Accuracy: 0.7465, Validation Accuracy: 0.7533, Loss: 0.3600
Epoch   5 Batch  160/269 - Train Accuracy: 0.7617, Validation Accuracy: 0.7625, Loss: 0.3579
Epoch   5 Batch  161/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7606, Loss: 0.3603
Epoch   5 Batch  162/269 - Train Accuracy: 0.7603, Validation Accuracy: 0.7683, Loss: 0.3442
Epoch   5 Batch  163/269 - Train Accuracy: 0.7492, Validation Accuracy: 0.7636, Loss: 0.3531
Epoch   5 Batch  164/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7633, Loss: 0.3485
Epoch   5 Batch  165/269 - Train Accuracy: 0.7574, Validation Accuracy: 0.7490, Loss: 0.3568
Epoch   5 Batch  166/269 - Train Accuracy: 0.7544, Validation Accuracy: 0.7573, Loss: 0.3335
Epoch   5 Batch  167/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7615, Loss: 0.3515
Epoch   5 Batch  168/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7612, Loss: 0.3552
Epoch   5 Batch  169/269 - Train Accuracy: 0.7575, Validation Accuracy: 0.7536, Loss: 0.3463
Epoch   5 Batch  170/269 - Train Accuracy: 0.7532, Validation Accuracy: 0.7594, Loss: 0.3511
Epoch   5 Batch  171/269 - Train Accuracy: 0.7689, Validation Accuracy: 0.7644, Loss: 0.3626
Epoch   5 Batch  172/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7600, Loss: 0.3602
Epoch   5 Batch  173/269 - Train Accuracy: 0.7471, Validation Accuracy: 0.7610, Loss: 0.3385
Epoch   5 Batch  174/269 - Train Accuracy: 0.7602, Validation Accuracy: 0.7634, Loss: 0.3513
Epoch   5 Batch  175/269 - Train Accuracy: 0.7600, Validation Accuracy: 0.7595, Loss: 0.3659
Epoch   5 Batch  176/269 - Train Accuracy: 0.7434, Validation Accuracy: 0.7610, Loss: 0.3646
Epoch   5 Batch  177/269 - Train Accuracy: 0.7638, Validation Accuracy: 0.7606, Loss: 0.3353
Epoch   5 Batch  178/269 - Train Accuracy: 0.7603, Validation Accuracy: 0.7636, Loss: 0.3549
Epoch   5 Batch  179/269 - Train Accuracy: 0.7554, Validation Accuracy: 0.7634, Loss: 0.3450
Epoch   5 Batch  180/269 - Train Accuracy: 0.7659, Validation Accuracy: 0.7611, Loss: 0.3458
Epoch   5 Batch  181/269 - Train Accuracy: 0.7654, Validation Accuracy: 0.7593, Loss: 0.3555
Epoch   5 Batch  182/269 - Train Accuracy: 0.7675, Validation Accuracy: 0.7524, Loss: 0.3457
Epoch   5 Batch  183/269 - Train Accuracy: 0.8009, Validation Accuracy: 0.7605, Loss: 0.3078
Epoch   5 Batch  184/269 - Train Accuracy: 0.7534, Validation Accuracy: 0.7580, Loss: 0.3583
Epoch   5 Batch  185/269 - Train Accuracy: 0.7802, Validation Accuracy: 0.7615, Loss: 0.3341
Epoch   5 Batch  186/269 - Train Accuracy: 0.7562, Validation Accuracy: 0.7638, Loss: 0.3541
Epoch   5 Batch  187/269 - Train Accuracy: 0.7638, Validation Accuracy: 0.7525, Loss: 0.3333
Epoch   5 Batch  188/269 - Train Accuracy: 0.7739, Validation Accuracy: 0.7603, Loss: 0.3336
Epoch   5 Batch  189/269 - Train Accuracy: 0.7605, Validation Accuracy: 0.7606, Loss: 0.3394
Epoch   5 Batch  190/269 - Train Accuracy: 0.7544, Validation Accuracy: 0.7573, Loss: 0.3374
Epoch   5 Batch  191/269 - Train Accuracy: 0.7632, Validation Accuracy: 0.7662, Loss: 0.3396
Epoch   5 Batch  192/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7668, Loss: 0.3433
Epoch   5 Batch  193/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.7638, Loss: 0.3427
Epoch   5 Batch  194/269 - Train Accuracy: 0.7731, Validation Accuracy: 0.7660, Loss: 0.3507
Epoch   5 Batch  195/269 - Train Accuracy: 0.7614, Validation Accuracy: 0.7696, Loss: 0.3527
Epoch   5 Batch  196/269 - Train Accuracy: 0.7530, Validation Accuracy: 0.7623, Loss: 0.3360
Epoch   5 Batch  197/269 - Train Accuracy: 0.7286, Validation Accuracy: 0.7641, Loss: 0.3618
Epoch   5 Batch  198/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7718, Loss: 0.3676
Epoch   5 Batch  199/269 - Train Accuracy: 0.7502, Validation Accuracy: 0.7646, Loss: 0.3587
Epoch   5 Batch  200/269 - Train Accuracy: 0.7580, Validation Accuracy: 0.7612, Loss: 0.3516
Epoch   5 Batch  201/269 - Train Accuracy: 0.7651, Validation Accuracy: 0.7665, Loss: 0.3461
Epoch   5 Batch  202/269 - Train Accuracy: 0.7612, Validation Accuracy: 0.7625, Loss: 0.3446
Epoch   5 Batch  203/269 - Train Accuracy: 0.7475, Validation Accuracy: 0.7646, Loss: 0.3678
Epoch   5 Batch  204/269 - Train Accuracy: 0.7610, Validation Accuracy: 0.7599, Loss: 0.3604
Epoch   5 Batch  205/269 - Train Accuracy: 0.7632, Validation Accuracy: 0.7601, Loss: 0.3371
Epoch   5 Batch  206/269 - Train Accuracy: 0.7416, Validation Accuracy: 0.7650, Loss: 0.3575
Epoch   5 Batch  207/269 - Train Accuracy: 0.7741, Validation Accuracy: 0.7612, Loss: 0.3325
Epoch   5 Batch  208/269 - Train Accuracy: 0.7676, Validation Accuracy: 0.7611, Loss: 0.3545
Epoch   5 Batch  209/269 - Train Accuracy: 0.7814, Validation Accuracy: 0.7623, Loss: 0.3469
Epoch   5 Batch  210/269 - Train Accuracy: 0.7654, Validation Accuracy: 0.7570, Loss: 0.3315
Epoch   5 Batch  211/269 - Train Accuracy: 0.7618, Validation Accuracy: 0.7591, Loss: 0.3436
Epoch   5 Batch  212/269 - Train Accuracy: 0.7861, Validation Accuracy: 0.7685, Loss: 0.3443
Epoch   5 Batch  213/269 - Train Accuracy: 0.7655, Validation Accuracy: 0.7599, Loss: 0.3371
Epoch   5 Batch  214/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7681, Loss: 0.3401
Epoch   5 Batch  215/269 - Train Accuracy: 0.7948, Validation Accuracy: 0.7707, Loss: 0.3168
Epoch   5 Batch  216/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7666, Loss: 0.3712
Epoch   5 Batch  217/269 - Train Accuracy: 0.7527, Validation Accuracy: 0.7678, Loss: 0.3480
Epoch   5 Batch  218/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7694, Loss: 0.3565
Epoch   5 Batch  219/269 - Train Accuracy: 0.7656, Validation Accuracy: 0.7669, Loss: 0.3541
Epoch   5 Batch  220/269 - Train Accuracy: 0.7641, Validation Accuracy: 0.7649, Loss: 0.3174
Epoch   5 Batch  221/269 - Train Accuracy: 0.7822, Validation Accuracy: 0.7592, Loss: 0.3400
Epoch   5 Batch  222/269 - Train Accuracy: 0.7872, Validation Accuracy: 0.7695, Loss: 0.3209
Epoch   5 Batch  223/269 - Train Accuracy: 0.7623, Validation Accuracy: 0.7637, Loss: 0.3212
Epoch   5 Batch  224/269 - Train Accuracy: 0.7769, Validation Accuracy: 0.7654, Loss: 0.3494
Epoch   5 Batch  225/269 - Train Accuracy: 0.7641, Validation Accuracy: 0.7597, Loss: 0.3350
Epoch   5 Batch  226/269 - Train Accuracy: 0.7798, Validation Accuracy: 0.7654, Loss: 0.3309
Epoch   5 Batch  227/269 - Train Accuracy: 0.7910, Validation Accuracy: 0.7707, Loss: 0.3025
Epoch   5 Batch  228/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7735, Loss: 0.3302
Epoch   5 Batch  229/269 - Train Accuracy: 0.7644, Validation Accuracy: 0.7569, Loss: 0.3335
Epoch   5 Batch  230/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7643, Loss: 0.3324
Epoch   5 Batch  231/269 - Train Accuracy: 0.7548, Validation Accuracy: 0.7616, Loss: 0.3515
Epoch   5 Batch  232/269 - Train Accuracy: 0.7434, Validation Accuracy: 0.7654, Loss: 0.3470
Epoch   5 Batch  233/269 - Train Accuracy: 0.7860, Validation Accuracy: 0.7667, Loss: 0.3340
Epoch   5 Batch  234/269 - Train Accuracy: 0.7765, Validation Accuracy: 0.7659, Loss: 0.3333
Epoch   5 Batch  235/269 - Train Accuracy: 0.7732, Validation Accuracy: 0.7708, Loss: 0.3243
Epoch   5 Batch  236/269 - Train Accuracy: 0.7710, Validation Accuracy: 0.7618, Loss: 0.3253
Epoch   5 Batch  237/269 - Train Accuracy: 0.7597, Validation Accuracy: 0.7582, Loss: 0.3293
Epoch   5 Batch  238/269 - Train Accuracy: 0.7728, Validation Accuracy: 0.7630, Loss: 0.3312
Epoch   5 Batch  239/269 - Train Accuracy: 0.7873, Validation Accuracy: 0.7717, Loss: 0.3352
Epoch   5 Batch  240/269 - Train Accuracy: 0.7838, Validation Accuracy: 0.7626, Loss: 0.3007
Epoch   5 Batch  241/269 - Train Accuracy: 0.7700, Validation Accuracy: 0.7733, Loss: 0.3419
Epoch   5 Batch  242/269 - Train Accuracy: 0.7761, Validation Accuracy: 0.7707, Loss: 0.3182
Epoch   5 Batch  243/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7616, Loss: 0.3227
Epoch   5 Batch  244/269 - Train Accuracy: 0.7618, Validation Accuracy: 0.7662, Loss: 0.3374
Epoch   5 Batch  245/269 - Train Accuracy: 0.7621, Validation Accuracy: 0.7676, Loss: 0.3500
Epoch   5 Batch  246/269 - Train Accuracy: 0.7608, Validation Accuracy: 0.7666, Loss: 0.3407
Epoch   5 Batch  247/269 - Train Accuracy: 0.7579, Validation Accuracy: 0.7700, Loss: 0.3466
Epoch   5 Batch  248/269 - Train Accuracy: 0.7802, Validation Accuracy: 0.7672, Loss: 0.3223
Epoch   5 Batch  249/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.7705, Loss: 0.3188
Epoch   5 Batch  250/269 - Train Accuracy: 0.7677, Validation Accuracy: 0.7710, Loss: 0.3366
Epoch   5 Batch  251/269 - Train Accuracy: 0.7880, Validation Accuracy: 0.7781, Loss: 0.3178
Epoch   5 Batch  252/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7705, Loss: 0.3272
Epoch   5 Batch  253/269 - Train Accuracy: 0.7420, Validation Accuracy: 0.7657, Loss: 0.3441
Epoch   5 Batch  254/269 - Train Accuracy: 0.7659, Validation Accuracy: 0.7724, Loss: 0.3311
Epoch   5 Batch  255/269 - Train Accuracy: 0.7851, Validation Accuracy: 0.7711, Loss: 0.3300
Epoch   5 Batch  256/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7652, Loss: 0.3368
Epoch   5 Batch  257/269 - Train Accuracy: 0.7567, Validation Accuracy: 0.7684, Loss: 0.3436
Epoch   5 Batch  258/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.7612, Loss: 0.3403
Epoch   5 Batch  259/269 - Train Accuracy: 0.7872, Validation Accuracy: 0.7622, Loss: 0.3224
Epoch   5 Batch  260/269 - Train Accuracy: 0.7591, Validation Accuracy: 0.7635, Loss: 0.3461
Epoch   5 Batch  261/269 - Train Accuracy: 0.7472, Validation Accuracy: 0.7676, Loss: 0.3439
Epoch   5 Batch  262/269 - Train Accuracy: 0.7806, Validation Accuracy: 0.7586, Loss: 0.3326
Epoch   5 Batch  263/269 - Train Accuracy: 0.7728, Validation Accuracy: 0.7722, Loss: 0.3392
Epoch   5 Batch  264/269 - Train Accuracy: 0.7648, Validation Accuracy: 0.7658, Loss: 0.3436
Epoch   5 Batch  265/269 - Train Accuracy: 0.7609, Validation Accuracy: 0.7590, Loss: 0.3287
Epoch   5 Batch  266/269 - Train Accuracy: 0.7728, Validation Accuracy: 0.7741, Loss: 0.3239
Epoch   5 Batch  267/269 - Train Accuracy: 0.7759, Validation Accuracy: 0.7664, Loss: 0.3284
Epoch   6 Batch    1/269 - Train Accuracy: 0.7644, Validation Accuracy: 0.7650, Loss: 0.3335
Epoch   6 Batch    2/269 - Train Accuracy: 0.7625, Validation Accuracy: 0.7622, Loss: 0.3292
Epoch   6 Batch    3/269 - Train Accuracy: 0.7797, Validation Accuracy: 0.7690, Loss: 0.3357
Epoch   6 Batch    4/269 - Train Accuracy: 0.7610, Validation Accuracy: 0.7710, Loss: 0.3357
Epoch   6 Batch    5/269 - Train Accuracy: 0.7496, Validation Accuracy: 0.7705, Loss: 0.3308
Epoch   6 Batch    6/269 - Train Accuracy: 0.7977, Validation Accuracy: 0.7701, Loss: 0.3080
Epoch   6 Batch    7/269 - Train Accuracy: 0.7749, Validation Accuracy: 0.7669, Loss: 0.3140
Epoch   6 Batch    8/269 - Train Accuracy: 0.7577, Validation Accuracy: 0.7663, Loss: 0.3286
Epoch   6 Batch    9/269 - Train Accuracy: 0.7693, Validation Accuracy: 0.7672, Loss: 0.3306
Epoch   6 Batch   10/269 - Train Accuracy: 0.7639, Validation Accuracy: 0.7570, Loss: 0.3240
Epoch   6 Batch   11/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7671, Loss: 0.3335
Epoch   6 Batch   12/269 - Train Accuracy: 0.7501, Validation Accuracy: 0.7747, Loss: 0.3366
Epoch   6 Batch   13/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7810, Loss: 0.2957
Epoch   6 Batch   14/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7766, Loss: 0.3153
Epoch   6 Batch   15/269 - Train Accuracy: 0.7586, Validation Accuracy: 0.7771, Loss: 0.3085
Epoch   6 Batch   16/269 - Train Accuracy: 0.7858, Validation Accuracy: 0.7749, Loss: 0.3169
Epoch   6 Batch   17/269 - Train Accuracy: 0.7920, Validation Accuracy: 0.7773, Loss: 0.3060
Epoch   6 Batch   18/269 - Train Accuracy: 0.7614, Validation Accuracy: 0.7780, Loss: 0.3182
Epoch   6 Batch   19/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7795, Loss: 0.3023
Epoch   6 Batch   20/269 - Train Accuracy: 0.7898, Validation Accuracy: 0.7883, Loss: 0.3231
Epoch   6 Batch   21/269 - Train Accuracy: 0.7510, Validation Accuracy: 0.7765, Loss: 0.3441
Epoch   6 Batch   22/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.7859, Loss: 0.3029
Epoch   6 Batch   23/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7864, Loss: 0.3230
Epoch   6 Batch   24/269 - Train Accuracy: 0.7738, Validation Accuracy: 0.7869, Loss: 0.3264
Epoch   6 Batch   25/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7747, Loss: 0.3378
Epoch   6 Batch   26/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.7869, Loss: 0.2951
Epoch   6 Batch   27/269 - Train Accuracy: 0.7560, Validation Accuracy: 0.7736, Loss: 0.3113
Epoch   6 Batch   28/269 - Train Accuracy: 0.7382, Validation Accuracy: 0.7639, Loss: 0.3466
Epoch   6 Batch   29/269 - Train Accuracy: 0.7840, Validation Accuracy: 0.7790, Loss: 0.3434
Epoch   6 Batch   30/269 - Train Accuracy: 0.7744, Validation Accuracy: 0.7759, Loss: 0.3130
Epoch   6 Batch   31/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.7756, Loss: 0.3102
Epoch   6 Batch   32/269 - Train Accuracy: 0.7778, Validation Accuracy: 0.7711, Loss: 0.3156
Epoch   6 Batch   33/269 - Train Accuracy: 0.7944, Validation Accuracy: 0.7749, Loss: 0.3121
Epoch   6 Batch   34/269 - Train Accuracy: 0.7901, Validation Accuracy: 0.7750, Loss: 0.3127
Epoch   6 Batch   35/269 - Train Accuracy: 0.7840, Validation Accuracy: 0.7777, Loss: 0.3296
Epoch   6 Batch   36/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7615, Loss: 0.3138
Epoch   6 Batch   37/269 - Train Accuracy: 0.7724, Validation Accuracy: 0.7726, Loss: 0.3218
Epoch   6 Batch   38/269 - Train Accuracy: 0.7824, Validation Accuracy: 0.7795, Loss: 0.3162
Epoch   6 Batch   39/269 - Train Accuracy: 0.7678, Validation Accuracy: 0.7706, Loss: 0.3140
Epoch   6 Batch   40/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7692, Loss: 0.3267
Epoch   6 Batch   41/269 - Train Accuracy: 0.7723, Validation Accuracy: 0.7812, Loss: 0.3194
Epoch   6 Batch   42/269 - Train Accuracy: 0.7951, Validation Accuracy: 0.7766, Loss: 0.2914
Epoch   6 Batch   43/269 - Train Accuracy: 0.7825, Validation Accuracy: 0.7702, Loss: 0.3172
Epoch   6 Batch   44/269 - Train Accuracy: 0.7796, Validation Accuracy: 0.7765, Loss: 0.3136
Epoch   6 Batch   45/269 - Train Accuracy: 0.7771, Validation Accuracy: 0.7795, Loss: 0.3195
Epoch   6 Batch   46/269 - Train Accuracy: 0.7724, Validation Accuracy: 0.7788, Loss: 0.3240
Epoch   6 Batch   47/269 - Train Accuracy: 0.7986, Validation Accuracy: 0.7757, Loss: 0.2834
Epoch   6 Batch   48/269 - Train Accuracy: 0.7920, Validation Accuracy: 0.7779, Loss: 0.3076
Epoch   6 Batch   49/269 - Train Accuracy: 0.7829, Validation Accuracy: 0.7741, Loss: 0.3180
Epoch   6 Batch   50/269 - Train Accuracy: 0.7614, Validation Accuracy: 0.7804, Loss: 0.3233
Epoch   6 Batch   51/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7735, Loss: 0.3079
Epoch   6 Batch   52/269 - Train Accuracy: 0.7703, Validation Accuracy: 0.7798, Loss: 0.2961
Epoch   6 Batch   53/269 - Train Accuracy: 0.7676, Validation Accuracy: 0.7789, Loss: 0.3268
Epoch   6 Batch   54/269 - Train Accuracy: 0.7905, Validation Accuracy: 0.7839, Loss: 0.3264
Epoch   6 Batch   55/269 - Train Accuracy: 0.8087, Validation Accuracy: 0.7799, Loss: 0.2956
Epoch   6 Batch   56/269 - Train Accuracy: 0.7843, Validation Accuracy: 0.7800, Loss: 0.3134
Epoch   6 Batch   57/269 - Train Accuracy: 0.7773, Validation Accuracy: 0.7838, Loss: 0.3161
Epoch   6 Batch   58/269 - Train Accuracy: 0.7743, Validation Accuracy: 0.7817, Loss: 0.3063
Epoch   6 Batch   59/269 - Train Accuracy: 0.8093, Validation Accuracy: 0.7741, Loss: 0.2875
Epoch   6 Batch   60/269 - Train Accuracy: 0.7843, Validation Accuracy: 0.7761, Loss: 0.2886
Epoch   6 Batch   61/269 - Train Accuracy: 0.7828, Validation Accuracy: 0.7784, Loss: 0.2825
Epoch   6 Batch   62/269 - Train Accuracy: 0.8051, Validation Accuracy: 0.7824, Loss: 0.2953
Epoch   6 Batch   63/269 - Train Accuracy: 0.7977, Validation Accuracy: 0.7821, Loss: 0.3090
Epoch   6 Batch   64/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7771, Loss: 0.2941
Epoch   6 Batch   65/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.7771, Loss: 0.3021
Epoch   6 Batch   66/269 - Train Accuracy: 0.7911, Validation Accuracy: 0.7847, Loss: 0.2970
Epoch   6 Batch   67/269 - Train Accuracy: 0.7884, Validation Accuracy: 0.7847, Loss: 0.3088
Epoch   6 Batch   68/269 - Train Accuracy: 0.7663, Validation Accuracy: 0.7957, Loss: 0.3127
Epoch   6 Batch   69/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7824, Loss: 0.3348
Epoch   6 Batch   70/269 - Train Accuracy: 0.8004, Validation Accuracy: 0.7837, Loss: 0.3121
Epoch   6 Batch   71/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7822, Loss: 0.3212
Epoch   6 Batch   72/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7812, Loss: 0.3016
Epoch   6 Batch   73/269 - Train Accuracy: 0.7762, Validation Accuracy: 0.7808, Loss: 0.3133
Epoch   6 Batch   74/269 - Train Accuracy: 0.7893, Validation Accuracy: 0.7860, Loss: 0.3059
Epoch   6 Batch   75/269 - Train Accuracy: 0.7929, Validation Accuracy: 0.7901, Loss: 0.2931
Epoch   6 Batch   76/269 - Train Accuracy: 0.7760, Validation Accuracy: 0.7805, Loss: 0.3028
Epoch   6 Batch   77/269 - Train Accuracy: 0.7848, Validation Accuracy: 0.7809, Loss: 0.2969
Epoch   6 Batch   78/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.7849, Loss: 0.2962
Epoch   6 Batch   79/269 - Train Accuracy: 0.7776, Validation Accuracy: 0.7801, Loss: 0.3015
Epoch   6 Batch   80/269 - Train Accuracy: 0.7836, Validation Accuracy: 0.7797, Loss: 0.2943
Epoch   6 Batch   81/269 - Train Accuracy: 0.7737, Validation Accuracy: 0.7852, Loss: 0.3104
Epoch   6 Batch   82/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.7852, Loss: 0.2916
Epoch   6 Batch   83/269 - Train Accuracy: 0.7831, Validation Accuracy: 0.7835, Loss: 0.3102
Epoch   6 Batch   84/269 - Train Accuracy: 0.8117, Validation Accuracy: 0.7804, Loss: 0.2931
Epoch   6 Batch   85/269 - Train Accuracy: 0.8020, Validation Accuracy: 0.7861, Loss: 0.2945
Epoch   6 Batch   86/269 - Train Accuracy: 0.7980, Validation Accuracy: 0.7884, Loss: 0.2965
Epoch   6 Batch   87/269 - Train Accuracy: 0.7787, Validation Accuracy: 0.7789, Loss: 0.3140
Epoch   6 Batch   88/269 - Train Accuracy: 0.7737, Validation Accuracy: 0.7819, Loss: 0.3034
Epoch   6 Batch   89/269 - Train Accuracy: 0.8026, Validation Accuracy: 0.7841, Loss: 0.2975
Epoch   6 Batch   90/269 - Train Accuracy: 0.7800, Validation Accuracy: 0.7843, Loss: 0.3094
Epoch   6 Batch   91/269 - Train Accuracy: 0.8232, Validation Accuracy: 0.7921, Loss: 0.2894
Epoch   6 Batch   92/269 - Train Accuracy: 0.7894, Validation Accuracy: 0.7901, Loss: 0.2839
Epoch   6 Batch   93/269 - Train Accuracy: 0.8002, Validation Accuracy: 0.7927, Loss: 0.2887
Epoch   6 Batch   94/269 - Train Accuracy: 0.7909, Validation Accuracy: 0.7928, Loss: 0.3075
Epoch   6 Batch   95/269 - Train Accuracy: 0.7874, Validation Accuracy: 0.7942, Loss: 0.2918
Epoch   6 Batch   96/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7937, Loss: 0.2935
Epoch   6 Batch   97/269 - Train Accuracy: 0.7872, Validation Accuracy: 0.7901, Loss: 0.2943
Epoch   6 Batch   98/269 - Train Accuracy: 0.7839, Validation Accuracy: 0.7968, Loss: 0.2939
Epoch   6 Batch   99/269 - Train Accuracy: 0.7743, Validation Accuracy: 0.7937, Loss: 0.2996
Epoch   6 Batch  100/269 - Train Accuracy: 0.8036, Validation Accuracy: 0.7831, Loss: 0.2876
Epoch   6 Batch  101/269 - Train Accuracy: 0.7754, Validation Accuracy: 0.7891, Loss: 0.3119
Epoch   6 Batch  102/269 - Train Accuracy: 0.7935, Validation Accuracy: 0.7879, Loss: 0.2932
Epoch   6 Batch  103/269 - Train Accuracy: 0.7924, Validation Accuracy: 0.7868, Loss: 0.2956
Epoch   6 Batch  104/269 - Train Accuracy: 0.7926, Validation Accuracy: 0.7815, Loss: 0.2895
Epoch   6 Batch  105/269 - Train Accuracy: 0.7910, Validation Accuracy: 0.7844, Loss: 0.2971
Epoch   6 Batch  106/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.7827, Loss: 0.2881
Epoch   6 Batch  107/269 - Train Accuracy: 0.7884, Validation Accuracy: 0.7779, Loss: 0.3093
Epoch   6 Batch  108/269 - Train Accuracy: 0.7816, Validation Accuracy: 0.7723, Loss: 0.2899
Epoch   6 Batch  109/269 - Train Accuracy: 0.7630, Validation Accuracy: 0.7649, Loss: 0.3011
Epoch   6 Batch  110/269 - Train Accuracy: 0.7861, Validation Accuracy: 0.7802, Loss: 0.2895
Epoch   6 Batch  111/269 - Train Accuracy: 0.7748, Validation Accuracy: 0.7784, Loss: 0.3125
Epoch   6 Batch  112/269 - Train Accuracy: 0.7882, Validation Accuracy: 0.7775, Loss: 0.2925
Epoch   6 Batch  113/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7759, Loss: 0.2800
Epoch   6 Batch  114/269 - Train Accuracy: 0.7816, Validation Accuracy: 0.7876, Loss: 0.2925
Epoch   6 Batch  115/269 - Train Accuracy: 0.7665, Validation Accuracy: 0.7828, Loss: 0.2969
Epoch   6 Batch  116/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7771, Loss: 0.3002
Epoch   6 Batch  117/269 - Train Accuracy: 0.7950, Validation Accuracy: 0.7942, Loss: 0.3035
Epoch   6 Batch  118/269 - Train Accuracy: 0.8118, Validation Accuracy: 0.7950, Loss: 0.2766
Epoch   6 Batch  119/269 - Train Accuracy: 0.7764, Validation Accuracy: 0.7770, Loss: 0.3167
Epoch   6 Batch  120/269 - Train Accuracy: 0.7972, Validation Accuracy: 0.7824, Loss: 0.3053
Epoch   6 Batch  121/269 - Train Accuracy: 0.7972, Validation Accuracy: 0.7840, Loss: 0.2860
Epoch   6 Batch  122/269 - Train Accuracy: 0.7768, Validation Accuracy: 0.7795, Loss: 0.2963
Epoch   6 Batch  123/269 - Train Accuracy: 0.8023, Validation Accuracy: 0.7837, Loss: 0.3041
Epoch   6 Batch  124/269 - Train Accuracy: 0.7974, Validation Accuracy: 0.7827, Loss: 0.2823
Epoch   6 Batch  125/269 - Train Accuracy: 0.7900, Validation Accuracy: 0.7887, Loss: 0.2840
Epoch   6 Batch  126/269 - Train Accuracy: 0.7740, Validation Accuracy: 0.7878, Loss: 0.2878
Epoch   6 Batch  127/269 - Train Accuracy: 0.7804, Validation Accuracy: 0.7752, Loss: 0.3025
Epoch   6 Batch  128/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.7959, Loss: 0.2990
Epoch   6 Batch  129/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.7926, Loss: 0.2873
Epoch   6 Batch  130/269 - Train Accuracy: 0.7880, Validation Accuracy: 0.7852, Loss: 0.3077
Epoch   6 Batch  131/269 - Train Accuracy: 0.7742, Validation Accuracy: 0.7916, Loss: 0.2950
Epoch   6 Batch  132/269 - Train Accuracy: 0.7803, Validation Accuracy: 0.7810, Loss: 0.2956
Epoch   6 Batch  133/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.7833, Loss: 0.2854
Epoch   6 Batch  134/269 - Train Accuracy: 0.7686, Validation Accuracy: 0.7852, Loss: 0.2948
Epoch   6 Batch  135/269 - Train Accuracy: 0.7790, Validation Accuracy: 0.7900, Loss: 0.3180
Epoch   6 Batch  136/269 - Train Accuracy: 0.7735, Validation Accuracy: 0.7830, Loss: 0.3149
Epoch   6 Batch  137/269 - Train Accuracy: 0.7775, Validation Accuracy: 0.7834, Loss: 0.3080
Epoch   6 Batch  138/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.7940, Loss: 0.2962
Epoch   6 Batch  139/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.8012, Loss: 0.2807
Epoch   6 Batch  140/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.7944, Loss: 0.3006
Epoch   6 Batch  141/269 - Train Accuracy: 0.7879, Validation Accuracy: 0.7984, Loss: 0.2972
Epoch   6 Batch  142/269 - Train Accuracy: 0.8011, Validation Accuracy: 0.7996, Loss: 0.2709
Epoch   6 Batch  143/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.7946, Loss: 0.2828
Epoch   6 Batch  144/269 - Train Accuracy: 0.7998, Validation Accuracy: 0.7892, Loss: 0.2713
Epoch   6 Batch  145/269 - Train Accuracy: 0.8030, Validation Accuracy: 0.8009, Loss: 0.2764
Epoch   6 Batch  146/269 - Train Accuracy: 0.8059, Validation Accuracy: 0.7976, Loss: 0.2819
Epoch   6 Batch  147/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.7912, Loss: 0.2737
Epoch   6 Batch  148/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.7965, Loss: 0.2887
Epoch   6 Batch  149/269 - Train Accuracy: 0.7926, Validation Accuracy: 0.7998, Loss: 0.2940
Epoch   6 Batch  150/269 - Train Accuracy: 0.7890, Validation Accuracy: 0.7956, Loss: 0.2854
Epoch   6 Batch  151/269 - Train Accuracy: 0.8109, Validation Accuracy: 0.8044, Loss: 0.2806
Epoch   6 Batch  152/269 - Train Accuracy: 0.8044, Validation Accuracy: 0.7981, Loss: 0.2875
Epoch   6 Batch  153/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.7906, Loss: 0.2899
Epoch   6 Batch  154/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.7975, Loss: 0.2928
Epoch   6 Batch  155/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.7986, Loss: 0.2699
Epoch   6 Batch  156/269 - Train Accuracy: 0.7856, Validation Accuracy: 0.8026, Loss: 0.2976
Epoch   6 Batch  157/269 - Train Accuracy: 0.7880, Validation Accuracy: 0.7985, Loss: 0.2787
Epoch   6 Batch  158/269 - Train Accuracy: 0.7857, Validation Accuracy: 0.7994, Loss: 0.2761
Epoch   6 Batch  159/269 - Train Accuracy: 0.7871, Validation Accuracy: 0.7987, Loss: 0.2852
Epoch   6 Batch  160/269 - Train Accuracy: 0.8106, Validation Accuracy: 0.8008, Loss: 0.2760
Epoch   6 Batch  161/269 - Train Accuracy: 0.8014, Validation Accuracy: 0.8073, Loss: 0.2756
Epoch   6 Batch  162/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8133, Loss: 0.2716
Epoch   6 Batch  163/269 - Train Accuracy: 0.7965, Validation Accuracy: 0.8001, Loss: 0.2765
Epoch   6 Batch  164/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8153, Loss: 0.2908
Epoch   6 Batch  165/269 - Train Accuracy: 0.7988, Validation Accuracy: 0.8001, Loss: 0.2758
Epoch   6 Batch  166/269 - Train Accuracy: 0.8192, Validation Accuracy: 0.8034, Loss: 0.2673
Epoch   6 Batch  167/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8013, Loss: 0.2759
Epoch   6 Batch  168/269 - Train Accuracy: 0.8087, Validation Accuracy: 0.8007, Loss: 0.2946
Epoch   6 Batch  169/269 - Train Accuracy: 0.8118, Validation Accuracy: 0.8054, Loss: 0.2849
Epoch   6 Batch  170/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.8025, Loss: 0.2698
Epoch   6 Batch  171/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.7992, Loss: 0.2872
Epoch   6 Batch  172/269 - Train Accuracy: 0.8057, Validation Accuracy: 0.7976, Loss: 0.2875
Epoch   6 Batch  173/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8017, Loss: 0.2675
Epoch   6 Batch  174/269 - Train Accuracy: 0.8066, Validation Accuracy: 0.8087, Loss: 0.2797
Epoch   6 Batch  175/269 - Train Accuracy: 0.8094, Validation Accuracy: 0.8061, Loss: 0.2966
Epoch   6 Batch  176/269 - Train Accuracy: 0.7935, Validation Accuracy: 0.8045, Loss: 0.2927
Epoch   6 Batch  177/269 - Train Accuracy: 0.8248, Validation Accuracy: 0.8010, Loss: 0.2606
Epoch   6 Batch  178/269 - Train Accuracy: 0.8067, Validation Accuracy: 0.8020, Loss: 0.2807
Epoch   6 Batch  179/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.7973, Loss: 0.2756
Epoch   6 Batch  180/269 - Train Accuracy: 0.8191, Validation Accuracy: 0.7992, Loss: 0.2721
Epoch   6 Batch  181/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8059, Loss: 0.2787
Epoch   6 Batch  182/269 - Train Accuracy: 0.8092, Validation Accuracy: 0.8039, Loss: 0.2784
Epoch   6 Batch  183/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8033, Loss: 0.2388
Epoch   6 Batch  184/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.8121, Loss: 0.2817
Epoch   6 Batch  185/269 - Train Accuracy: 0.8188, Validation Accuracy: 0.8077, Loss: 0.2734
Epoch   6 Batch  186/269 - Train Accuracy: 0.8068, Validation Accuracy: 0.8021, Loss: 0.2698
Epoch   6 Batch  187/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.8085, Loss: 0.2649
Epoch   6 Batch  188/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8095, Loss: 0.2651
Epoch   6 Batch  189/269 - Train Accuracy: 0.8049, Validation Accuracy: 0.8066, Loss: 0.2683
Epoch   6 Batch  190/269 - Train Accuracy: 0.8206, Validation Accuracy: 0.8074, Loss: 0.2684
Epoch   6 Batch  191/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8040, Loss: 0.2624
Epoch   6 Batch  192/269 - Train Accuracy: 0.8166, Validation Accuracy: 0.8004, Loss: 0.2768
Epoch   6 Batch  193/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8137, Loss: 0.2653
Epoch   6 Batch  194/269 - Train Accuracy: 0.8226, Validation Accuracy: 0.8086, Loss: 0.2783
Epoch   6 Batch  195/269 - Train Accuracy: 0.8092, Validation Accuracy: 0.8106, Loss: 0.2766
Epoch   6 Batch  196/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8122, Loss: 0.2609
Epoch   6 Batch  197/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.8113, Loss: 0.2891
Epoch   6 Batch  198/269 - Train Accuracy: 0.8081, Validation Accuracy: 0.8055, Loss: 0.2813
Epoch   6 Batch  199/269 - Train Accuracy: 0.8087, Validation Accuracy: 0.8144, Loss: 0.2738
Epoch   6 Batch  200/269 - Train Accuracy: 0.8116, Validation Accuracy: 0.8120, Loss: 0.2781
Epoch   6 Batch  201/269 - Train Accuracy: 0.8203, Validation Accuracy: 0.8138, Loss: 0.2704
Epoch   6 Batch  202/269 - Train Accuracy: 0.8038, Validation Accuracy: 0.8206, Loss: 0.2683
Epoch   6 Batch  203/269 - Train Accuracy: 0.8277, Validation Accuracy: 0.8164, Loss: 0.2918
Epoch   6 Batch  204/269 - Train Accuracy: 0.8084, Validation Accuracy: 0.8176, Loss: 0.2817
Epoch   6 Batch  205/269 - Train Accuracy: 0.8273, Validation Accuracy: 0.8063, Loss: 0.2702
Epoch   6 Batch  206/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.8074, Loss: 0.2865
Epoch   6 Batch  207/269 - Train Accuracy: 0.8077, Validation Accuracy: 0.8112, Loss: 0.2581
Epoch   6 Batch  208/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8055, Loss: 0.2785
Epoch   6 Batch  209/269 - Train Accuracy: 0.8335, Validation Accuracy: 0.8181, Loss: 0.2641
Epoch   6 Batch  210/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8228, Loss: 0.2631
Epoch   6 Batch  211/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8214, Loss: 0.2690
Epoch   6 Batch  212/269 - Train Accuracy: 0.8356, Validation Accuracy: 0.8153, Loss: 0.2707
Epoch   6 Batch  213/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8216, Loss: 0.2642
Epoch   6 Batch  214/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8238, Loss: 0.2725
Epoch   6 Batch  215/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8128, Loss: 0.2509
Epoch   6 Batch  216/269 - Train Accuracy: 0.8020, Validation Accuracy: 0.8232, Loss: 0.2942
Epoch   6 Batch  217/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8217, Loss: 0.2796
Epoch   6 Batch  218/269 - Train Accuracy: 0.8156, Validation Accuracy: 0.8129, Loss: 0.2775
Epoch   6 Batch  219/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8154, Loss: 0.2791
Epoch   6 Batch  220/269 - Train Accuracy: 0.8240, Validation Accuracy: 0.8177, Loss: 0.2456
Epoch   6 Batch  221/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8135, Loss: 0.2652
Epoch   6 Batch  222/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8086, Loss: 0.2544
Epoch   6 Batch  223/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8173, Loss: 0.2544
Epoch   6 Batch  224/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8145, Loss: 0.2736
Epoch   6 Batch  225/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8157, Loss: 0.2598
Epoch   6 Batch  226/269 - Train Accuracy: 0.8356, Validation Accuracy: 0.8174, Loss: 0.2652
Epoch   6 Batch  227/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8184, Loss: 0.2423
Epoch   6 Batch  228/269 - Train Accuracy: 0.8206, Validation Accuracy: 0.8210, Loss: 0.2657
Epoch   6 Batch  229/269 - Train Accuracy: 0.8229, Validation Accuracy: 0.8240, Loss: 0.2581
Epoch   6 Batch  230/269 - Train Accuracy: 0.8199, Validation Accuracy: 0.8273, Loss: 0.2590
Epoch   6 Batch  231/269 - Train Accuracy: 0.8166, Validation Accuracy: 0.8194, Loss: 0.2721
Epoch   6 Batch  232/269 - Train Accuracy: 0.8206, Validation Accuracy: 0.8216, Loss: 0.2663
Epoch   6 Batch  233/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8206, Loss: 0.2681
Epoch   6 Batch  234/269 - Train Accuracy: 0.8339, Validation Accuracy: 0.8278, Loss: 0.2616
Epoch   6 Batch  235/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8147, Loss: 0.2530
Epoch   6 Batch  236/269 - Train Accuracy: 0.8213, Validation Accuracy: 0.8149, Loss: 0.2516
Epoch   6 Batch  237/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8143, Loss: 0.2626
Epoch   6 Batch  238/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8155, Loss: 0.2600
Epoch   6 Batch  239/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8180, Loss: 0.2589
Epoch   6 Batch  240/269 - Train Accuracy: 0.8475, Validation Accuracy: 0.8230, Loss: 0.2399
Epoch   6 Batch  241/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8235, Loss: 0.2732
Epoch   6 Batch  242/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8256, Loss: 0.2496
Epoch   6 Batch  243/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8241, Loss: 0.2487
Epoch   6 Batch  244/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8192, Loss: 0.2640
Epoch   6 Batch  245/269 - Train Accuracy: 0.8249, Validation Accuracy: 0.8169, Loss: 0.2705
Epoch   6 Batch  246/269 - Train Accuracy: 0.8136, Validation Accuracy: 0.8208, Loss: 0.2627
Epoch   6 Batch  247/269 - Train Accuracy: 0.8212, Validation Accuracy: 0.8227, Loss: 0.2590
Epoch   6 Batch  248/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8217, Loss: 0.2491
Epoch   6 Batch  249/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8250, Loss: 0.2439
Epoch   6 Batch  250/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8278, Loss: 0.2577
Epoch   6 Batch  251/269 - Train Accuracy: 0.8455, Validation Accuracy: 0.8274, Loss: 0.2514
Epoch   6 Batch  252/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8303, Loss: 0.2532
Epoch   6 Batch  253/269 - Train Accuracy: 0.8052, Validation Accuracy: 0.8274, Loss: 0.2596
Epoch   6 Batch  254/269 - Train Accuracy: 0.8436, Validation Accuracy: 0.8346, Loss: 0.2558
Epoch   6 Batch  255/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8331, Loss: 0.2549
Epoch   6 Batch  256/269 - Train Accuracy: 0.8154, Validation Accuracy: 0.8314, Loss: 0.2540
Epoch   6 Batch  257/269 - Train Accuracy: 0.8272, Validation Accuracy: 0.8314, Loss: 0.2638
Epoch   6 Batch  258/269 - Train Accuracy: 0.8305, Validation Accuracy: 0.8196, Loss: 0.2667
Epoch   6 Batch  259/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8317, Loss: 0.2616
Epoch   6 Batch  260/269 - Train Accuracy: 0.8148, Validation Accuracy: 0.8230, Loss: 0.2719
Epoch   6 Batch  261/269 - Train Accuracy: 0.8107, Validation Accuracy: 0.8165, Loss: 0.2591
Epoch   6 Batch  262/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8210, Loss: 0.2667
Epoch   6 Batch  263/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8312, Loss: 0.2675
Epoch   6 Batch  264/269 - Train Accuracy: 0.8143, Validation Accuracy: 0.8313, Loss: 0.2734
Epoch   6 Batch  265/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8310, Loss: 0.2505
Epoch   6 Batch  266/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8245, Loss: 0.2545
Epoch   6 Batch  267/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8326, Loss: 0.2698
Epoch   7 Batch    1/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.8235, Loss: 0.2608
Epoch   7 Batch    2/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8405, Loss: 0.2593
Epoch   7 Batch    3/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8384, Loss: 0.2562
Epoch   7 Batch    4/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8263, Loss: 0.2620
Epoch   7 Batch    5/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8350, Loss: 0.2623
Epoch   7 Batch    6/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8332, Loss: 0.2370
Epoch   7 Batch    7/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8281, Loss: 0.2524
Epoch   7 Batch    8/269 - Train Accuracy: 0.8242, Validation Accuracy: 0.8346, Loss: 0.2602
Epoch   7 Batch    9/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8434, Loss: 0.2579
Epoch   7 Batch   10/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8344, Loss: 0.2499
Epoch   7 Batch   11/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8367, Loss: 0.2653
Epoch   7 Batch   12/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8385, Loss: 0.2721
Epoch   7 Batch   13/269 - Train Accuracy: 0.8221, Validation Accuracy: 0.8240, Loss: 0.2302
Epoch   7 Batch   14/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8278, Loss: 0.2546
Epoch   7 Batch   15/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8307, Loss: 0.2363
Epoch   7 Batch   16/269 - Train Accuracy: 0.8398, Validation Accuracy: 0.8402, Loss: 0.2525
Epoch   7 Batch   17/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8334, Loss: 0.2357
Epoch   7 Batch   18/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8272, Loss: 0.2489
Epoch   7 Batch   19/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8315, Loss: 0.2323
Epoch   7 Batch   20/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8467, Loss: 0.2513
Epoch   7 Batch   21/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8302, Loss: 0.2756
Epoch   7 Batch   22/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8439, Loss: 0.2408
Epoch   7 Batch   23/269 - Train Accuracy: 0.8357, Validation Accuracy: 0.8372, Loss: 0.2481
Epoch   7 Batch   24/269 - Train Accuracy: 0.8373, Validation Accuracy: 0.8302, Loss: 0.2674
Epoch   7 Batch   25/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8293, Loss: 0.2653
Epoch   7 Batch   26/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8351, Loss: 0.2289
Epoch   7 Batch   27/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8436, Loss: 0.2429
Epoch   7 Batch   28/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8444, Loss: 0.2679
Epoch   7 Batch   29/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8477, Loss: 0.2657
Epoch   7 Batch   30/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8353, Loss: 0.2431
Epoch   7 Batch   31/269 - Train Accuracy: 0.8507, Validation Accuracy: 0.8382, Loss: 0.2480
Epoch   7 Batch   32/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8485, Loss: 0.2375
Epoch   7 Batch   33/269 - Train Accuracy: 0.8462, Validation Accuracy: 0.8464, Loss: 0.2345
Epoch   7 Batch   34/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8459, Loss: 0.2383
Epoch   7 Batch   35/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8499, Loss: 0.2517
Epoch   7 Batch   36/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8461, Loss: 0.2451
Epoch   7 Batch   37/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8517, Loss: 0.2512
Epoch   7 Batch   38/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8442, Loss: 0.2429
Epoch   7 Batch   39/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8532, Loss: 0.2375
Epoch   7 Batch   40/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8569, Loss: 0.2509
Epoch   7 Batch   41/269 - Train Accuracy: 0.8453, Validation Accuracy: 0.8556, Loss: 0.2466
Epoch   7 Batch   42/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8509, Loss: 0.2271
Epoch   7 Batch   43/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8400, Loss: 0.2543
Epoch   7 Batch   44/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8487, Loss: 0.2418
Epoch   7 Batch   45/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8504, Loss: 0.2510
Epoch   7 Batch   46/269 - Train Accuracy: 0.8298, Validation Accuracy: 0.8507, Loss: 0.2489
Epoch   7 Batch   47/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8526, Loss: 0.2241
Epoch   7 Batch   48/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8465, Loss: 0.2364
Epoch   7 Batch   49/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8519, Loss: 0.2405
Epoch   7 Batch   50/269 - Train Accuracy: 0.8297, Validation Accuracy: 0.8539, Loss: 0.2533
Epoch   7 Batch   51/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8414, Loss: 0.2401
Epoch   7 Batch   52/269 - Train Accuracy: 0.8310, Validation Accuracy: 0.8524, Loss: 0.2277
Epoch   7 Batch   53/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8437, Loss: 0.2554
Epoch   7 Batch   54/269 - Train Accuracy: 0.8644, Validation Accuracy: 0.8426, Loss: 0.2477
Epoch   7 Batch   55/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8498, Loss: 0.2304
Epoch   7 Batch   56/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8533, Loss: 0.2402
Epoch   7 Batch   57/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8523, Loss: 0.2520
Epoch   7 Batch   58/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8518, Loss: 0.2444
Epoch   7 Batch   59/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8539, Loss: 0.2195
Epoch   7 Batch   60/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8537, Loss: 0.2281
Epoch   7 Batch   61/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8525, Loss: 0.2241
Epoch   7 Batch   62/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8564, Loss: 0.2290
Epoch   7 Batch   63/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8523, Loss: 0.2452
Epoch   7 Batch   64/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8547, Loss: 0.2341
Epoch   7 Batch   65/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8439, Loss: 0.2294
Epoch   7 Batch   66/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8430, Loss: 0.2317
Epoch   7 Batch   67/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8461, Loss: 0.2429
Epoch   7 Batch   68/269 - Train Accuracy: 0.8378, Validation Accuracy: 0.8481, Loss: 0.2442
Epoch   7 Batch   69/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8495, Loss: 0.2681
Epoch   7 Batch   70/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8511, Loss: 0.2439
Epoch   7 Batch   71/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8483, Loss: 0.2472
Epoch   7 Batch   72/269 - Train Accuracy: 0.8435, Validation Accuracy: 0.8493, Loss: 0.2423
Epoch   7 Batch   73/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8441, Loss: 0.2468
Epoch   7 Batch   74/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8539, Loss: 0.2376
Epoch   7 Batch   75/269 - Train Accuracy: 0.8600, Validation Accuracy: 0.8528, Loss: 0.2342
Epoch   7 Batch   76/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8418, Loss: 0.2388
Epoch   7 Batch   77/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8358, Loss: 0.2350
Epoch   7 Batch   78/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8540, Loss: 0.2338
Epoch   7 Batch   79/269 - Train Accuracy: 0.8156, Validation Accuracy: 0.8273, Loss: 0.2362
Epoch   7 Batch   80/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8484, Loss: 0.2407
Epoch   7 Batch   81/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8476, Loss: 0.2502
Epoch   7 Batch   82/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8412, Loss: 0.2277
Epoch   7 Batch   83/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8419, Loss: 0.2488
Epoch   7 Batch   84/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8414, Loss: 0.2285
Epoch   7 Batch   85/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8415, Loss: 0.2376
Epoch   7 Batch   86/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8487, Loss: 0.2306
Epoch   7 Batch   87/269 - Train Accuracy: 0.8353, Validation Accuracy: 0.8485, Loss: 0.2524
Epoch   7 Batch   88/269 - Train Accuracy: 0.8343, Validation Accuracy: 0.8505, Loss: 0.2490
Epoch   7 Batch   89/269 - Train Accuracy: 0.8620, Validation Accuracy: 0.8387, Loss: 0.2257
Epoch   7 Batch   90/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8505, Loss: 0.2518
Epoch   7 Batch   91/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8557, Loss: 0.2298
Epoch   7 Batch   92/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8398, Loss: 0.2293
Epoch   7 Batch   93/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8574, Loss: 0.2398
Epoch   7 Batch   94/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8443, Loss: 0.2455
Epoch   7 Batch   95/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8512, Loss: 0.2368
Epoch   7 Batch   96/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8456, Loss: 0.2325
Epoch   7 Batch   97/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8532, Loss: 0.2324
Epoch   7 Batch   98/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8523, Loss: 0.2325
Epoch   7 Batch   99/269 - Train Accuracy: 0.8420, Validation Accuracy: 0.8419, Loss: 0.2376
Epoch   7 Batch  100/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8500, Loss: 0.2272
Epoch   7 Batch  101/269 - Train Accuracy: 0.8328, Validation Accuracy: 0.8546, Loss: 0.2539
Epoch   7 Batch  102/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8582, Loss: 0.2330
Epoch   7 Batch  103/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8539, Loss: 0.2391
Epoch   7 Batch  104/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8637, Loss: 0.2318
Epoch   7 Batch  105/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8587, Loss: 0.2302
Epoch   7 Batch  106/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8589, Loss: 0.2229
Epoch   7 Batch  107/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8550, Loss: 0.2358
Epoch   7 Batch  108/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8555, Loss: 0.2264
Epoch   7 Batch  109/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8619, Loss: 0.2347
Epoch   7 Batch  110/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8604, Loss: 0.2209
Epoch   7 Batch  111/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8657, Loss: 0.2489
Epoch   7 Batch  112/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8625, Loss: 0.2250
Epoch   7 Batch  113/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8604, Loss: 0.2169
Epoch   7 Batch  114/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8635, Loss: 0.2241
Epoch   7 Batch  115/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8620, Loss: 0.2372
Epoch   7 Batch  116/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8613, Loss: 0.2350
Epoch   7 Batch  117/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8586, Loss: 0.2249
Epoch   7 Batch  118/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8610, Loss: 0.2135
Epoch   7 Batch  119/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8653, Loss: 0.2363
Epoch   7 Batch  120/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8618, Loss: 0.2297
Epoch   7 Batch  121/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8507, Loss: 0.2155
Epoch   7 Batch  122/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8517, Loss: 0.2234
Epoch   7 Batch  123/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8576, Loss: 0.2323
Epoch   7 Batch  124/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8596, Loss: 0.2103
Epoch   7 Batch  125/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8474, Loss: 0.2143
Epoch   7 Batch  126/269 - Train Accuracy: 0.8422, Validation Accuracy: 0.8616, Loss: 0.2248
Epoch   7 Batch  127/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8606, Loss: 0.2258
Epoch   7 Batch  128/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8611, Loss: 0.2248
Epoch   7 Batch  129/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8591, Loss: 0.2224
Epoch   7 Batch  130/269 - Train Accuracy: 0.8546, Validation Accuracy: 0.8547, Loss: 0.2332
Epoch   7 Batch  131/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8588, Loss: 0.2336
Epoch   7 Batch  132/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8485, Loss: 0.2194
Epoch   7 Batch  133/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8554, Loss: 0.2208
Epoch   7 Batch  134/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8572, Loss: 0.2319
Epoch   7 Batch  135/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8507, Loss: 0.2403
Epoch   7 Batch  136/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8571, Loss: 0.2415
Epoch   7 Batch  137/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8566, Loss: 0.2380
Epoch   7 Batch  138/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8653, Loss: 0.2233
Epoch   7 Batch  139/269 - Train Accuracy: 0.8551, Validation Accuracy: 0.8535, Loss: 0.2144
Epoch   7 Batch  140/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8543, Loss: 0.2358
Epoch   7 Batch  141/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8598, Loss: 0.2287
Epoch   7 Batch  142/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8556, Loss: 0.2203
Epoch   7 Batch  143/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8552, Loss: 0.2232
Epoch   7 Batch  144/269 - Train Accuracy: 0.8672, Validation Accuracy: 0.8491, Loss: 0.2133
Epoch   7 Batch  145/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8518, Loss: 0.2135
Epoch   7 Batch  146/269 - Train Accuracy: 0.8562, Validation Accuracy: 0.8516, Loss: 0.2209
Epoch   7 Batch  147/269 - Train Accuracy: 0.8663, Validation Accuracy: 0.8546, Loss: 0.2104
Epoch   7 Batch  148/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8576, Loss: 0.2222
Epoch   7 Batch  149/269 - Train Accuracy: 0.8431, Validation Accuracy: 0.8568, Loss: 0.2257
Epoch   7 Batch  150/269 - Train Accuracy: 0.8543, Validation Accuracy: 0.8581, Loss: 0.2205
Epoch   7 Batch  151/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8631, Loss: 0.2119
Epoch   7 Batch  152/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8641, Loss: 0.2262
Epoch   7 Batch  153/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8604, Loss: 0.2169
Epoch   7 Batch  154/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8659, Loss: 0.2208
Epoch   7 Batch  155/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8643, Loss: 0.2157
Epoch   7 Batch  156/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8635, Loss: 0.2301
Epoch   7 Batch  157/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8596, Loss: 0.2141
Epoch   7 Batch  158/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8638, Loss: 0.2178
Epoch   7 Batch  159/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8640, Loss: 0.2294
Epoch   7 Batch  160/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8631, Loss: 0.2183
Epoch   7 Batch  161/269 - Train Accuracy: 0.8678, Validation Accuracy: 0.8674, Loss: 0.2180
Epoch   7 Batch  162/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8713, Loss: 0.2168
Epoch   7 Batch  163/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8648, Loss: 0.2170
Epoch   7 Batch  164/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8638, Loss: 0.2183
Epoch   7 Batch  165/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8669, Loss: 0.2171
Epoch   7 Batch  166/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8636, Loss: 0.2019
Epoch   7 Batch  167/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8626, Loss: 0.2130
Epoch   7 Batch  168/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8654, Loss: 0.2244
Epoch   7 Batch  169/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8623, Loss: 0.2224
Epoch   7 Batch  170/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8627, Loss: 0.2093
Epoch   7 Batch  171/269 - Train Accuracy: 0.8736, Validation Accuracy: 0.8537, Loss: 0.2202
Epoch   7 Batch  172/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8629, Loss: 0.2266
Epoch   7 Batch  173/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8714, Loss: 0.2041
Epoch   7 Batch  174/269 - Train Accuracy: 0.8606, Validation Accuracy: 0.8552, Loss: 0.2161
Epoch   7 Batch  175/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8619, Loss: 0.2427
Epoch   7 Batch  176/269 - Train Accuracy: 0.8585, Validation Accuracy: 0.8564, Loss: 0.2264
Epoch   7 Batch  177/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8563, Loss: 0.2055
Epoch   7 Batch  178/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8647, Loss: 0.2139
Epoch   7 Batch  179/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8663, Loss: 0.2134
Epoch   7 Batch  180/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8583, Loss: 0.2141
Epoch   7 Batch  181/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8655, Loss: 0.2258
Epoch   7 Batch  182/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8661, Loss: 0.2131
Epoch   7 Batch  183/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.8614, Loss: 0.1854
Epoch   7 Batch  184/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8671, Loss: 0.2155
Epoch   7 Batch  185/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8579, Loss: 0.2074
Epoch   7 Batch  186/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8548, Loss: 0.2071
Epoch   7 Batch  187/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8575, Loss: 0.2070
Epoch   7 Batch  188/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8564, Loss: 0.2041
Epoch   7 Batch  189/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8599, Loss: 0.2059
Epoch   7 Batch  190/269 - Train Accuracy: 0.8595, Validation Accuracy: 0.8587, Loss: 0.2073
Epoch   7 Batch  191/269 - Train Accuracy: 0.8601, Validation Accuracy: 0.8679, Loss: 0.2120
Epoch   7 Batch  192/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8472, Loss: 0.2143
Epoch   7 Batch  193/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8576, Loss: 0.2107
Epoch   7 Batch  194/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8645, Loss: 0.2152
Epoch   7 Batch  195/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8677, Loss: 0.2089
Epoch   7 Batch  196/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8682, Loss: 0.2036
Epoch   7 Batch  197/269 - Train Accuracy: 0.8681, Validation Accuracy: 0.8649, Loss: 0.2214
Epoch   7 Batch  198/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8512, Loss: 0.2248
Epoch   7 Batch  199/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8521, Loss: 0.2205
Epoch   7 Batch  200/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8567, Loss: 0.2169
Epoch   7 Batch  201/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8572, Loss: 0.2124
Epoch   7 Batch  202/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8638, Loss: 0.2130
Epoch   7 Batch  203/269 - Train Accuracy: 0.8667, Validation Accuracy: 0.8660, Loss: 0.2240
Epoch   7 Batch  204/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8536, Loss: 0.2258
Epoch   7 Batch  205/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8481, Loss: 0.2103
Epoch   7 Batch  206/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8615, Loss: 0.2253
Epoch   7 Batch  207/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8554, Loss: 0.2029
Epoch   7 Batch  208/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8522, Loss: 0.2177
Epoch   7 Batch  209/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8614, Loss: 0.2040
Epoch   7 Batch  210/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8590, Loss: 0.2043
Epoch   7 Batch  211/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8560, Loss: 0.2170
Epoch   7 Batch  212/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8596, Loss: 0.2196
Epoch   7 Batch  213/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8600, Loss: 0.2060
Epoch   7 Batch  214/269 - Train Accuracy: 0.8574, Validation Accuracy: 0.8651, Loss: 0.2166
Epoch   7 Batch  215/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8649, Loss: 0.1931
Epoch   7 Batch  216/269 - Train Accuracy: 0.8494, Validation Accuracy: 0.8617, Loss: 0.2453
Epoch   7 Batch  217/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8634, Loss: 0.2168
Epoch   7 Batch  218/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8630, Loss: 0.2135
Epoch   7 Batch  219/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8653, Loss: 0.2225
Epoch   7 Batch  220/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8675, Loss: 0.1975
Epoch   7 Batch  221/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8659, Loss: 0.2156
Epoch   7 Batch  222/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8539, Loss: 0.1975
Epoch   7 Batch  223/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8645, Loss: 0.2015
Epoch   7 Batch  224/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8588, Loss: 0.2209
Epoch   7 Batch  225/269 - Train Accuracy: 0.8554, Validation Accuracy: 0.8556, Loss: 0.2132
Epoch   7 Batch  226/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8596, Loss: 0.2143
Epoch   7 Batch  227/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8557, Loss: 0.2006
Epoch   7 Batch  228/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8594, Loss: 0.2124
Epoch   7 Batch  229/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8553, Loss: 0.2081
Epoch   7 Batch  230/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8572, Loss: 0.2108
Epoch   7 Batch  231/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8507, Loss: 0.2185
Epoch   7 Batch  232/269 - Train Accuracy: 0.8568, Validation Accuracy: 0.8668, Loss: 0.2175
Epoch   7 Batch  233/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8573, Loss: 0.2115
Epoch   7 Batch  234/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.8629, Loss: 0.2070
Epoch   7 Batch  235/269 - Train Accuracy: 0.8653, Validation Accuracy: 0.8594, Loss: 0.1969
Epoch   7 Batch  236/269 - Train Accuracy: 0.8647, Validation Accuracy: 0.8628, Loss: 0.2072
Epoch   7 Batch  237/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8596, Loss: 0.2020
Epoch   7 Batch  238/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8667, Loss: 0.2071
Epoch   7 Batch  239/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8648, Loss: 0.2080
Epoch   7 Batch  240/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8655, Loss: 0.1957
Epoch   7 Batch  241/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8676, Loss: 0.2215
Epoch   7 Batch  242/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8732, Loss: 0.1933
Epoch   7 Batch  243/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8694, Loss: 0.1975
Epoch   7 Batch  244/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8657, Loss: 0.2101
Epoch   7 Batch  245/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.8675, Loss: 0.2162
Epoch   7 Batch  246/269 - Train Accuracy: 0.8470, Validation Accuracy: 0.8617, Loss: 0.1996
Epoch   7 Batch  247/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8562, Loss: 0.2061
Epoch   7 Batch  248/269 - Train Accuracy: 0.8734, Validation Accuracy: 0.8595, Loss: 0.1972
Epoch   7 Batch  249/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8588, Loss: 0.1853
Epoch   7 Batch  250/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8662, Loss: 0.2012
Epoch   7 Batch  251/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8627, Loss: 0.1928
Epoch   7 Batch  252/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8618, Loss: 0.1946
Epoch   7 Batch  253/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8596, Loss: 0.2086
Epoch   7 Batch  254/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8698, Loss: 0.1960
Epoch   7 Batch  255/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8718, Loss: 0.2033
Epoch   7 Batch  256/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8699, Loss: 0.1975
Epoch   7 Batch  257/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8754, Loss: 0.2158
Epoch   7 Batch  258/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8748, Loss: 0.2066
Epoch   7 Batch  259/269 - Train Accuracy: 0.8769, Validation Accuracy: 0.8694, Loss: 0.1954
Epoch   7 Batch  260/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8690, Loss: 0.2103
Epoch   7 Batch  261/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8771, Loss: 0.2030
Epoch   7 Batch  262/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8749, Loss: 0.2065
Epoch   7 Batch  263/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8723, Loss: 0.2049
Epoch   7 Batch  264/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8691, Loss: 0.2143
Epoch   7 Batch  265/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8683, Loss: 0.2000
Epoch   7 Batch  266/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8639, Loss: 0.1916
Epoch   7 Batch  267/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8701, Loss: 0.2085
Epoch   8 Batch    1/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8694, Loss: 0.1994
Epoch   8 Batch    2/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8699, Loss: 0.1997
Epoch   8 Batch    3/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8646, Loss: 0.2015
Epoch   8 Batch    4/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8637, Loss: 0.1988
Epoch   8 Batch    5/269 - Train Accuracy: 0.8612, Validation Accuracy: 0.8643, Loss: 0.1981
Epoch   8 Batch    6/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.8667, Loss: 0.1838
Epoch   8 Batch    7/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8674, Loss: 0.1911
Epoch   8 Batch    8/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8655, Loss: 0.2073
Epoch   8 Batch    9/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8606, Loss: 0.2057
Epoch   8 Batch   10/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8591, Loss: 0.1897
Epoch   8 Batch   11/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8654, Loss: 0.2065
Epoch   8 Batch   12/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8680, Loss: 0.2097
Epoch   8 Batch   13/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8718, Loss: 0.1768
Epoch   8 Batch   14/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8707, Loss: 0.1927
Epoch   8 Batch   15/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8730, Loss: 0.1758
Epoch   8 Batch   16/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8706, Loss: 0.1988
Epoch   8 Batch   17/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8737, Loss: 0.1825
Epoch   8 Batch   18/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8706, Loss: 0.1940
Epoch   8 Batch   19/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8722, Loss: 0.1777
Epoch   8 Batch   20/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8760, Loss: 0.1922
Epoch   8 Batch   21/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8735, Loss: 0.2100
Epoch   8 Batch   22/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8680, Loss: 0.1885
Epoch   8 Batch   23/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8724, Loss: 0.1975
Epoch   8 Batch   24/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8715, Loss: 0.1899
Epoch   8 Batch   25/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8716, Loss: 0.2034
Epoch   8 Batch   26/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8722, Loss: 0.1813
Epoch   8 Batch   27/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8729, Loss: 0.1896
Epoch   8 Batch   28/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8723, Loss: 0.2072
Epoch   8 Batch   29/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8731, Loss: 0.2093
Epoch   8 Batch   30/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8696, Loss: 0.1882
Epoch   8 Batch   31/269 - Train Accuracy: 0.8765, Validation Accuracy: 0.8714, Loss: 0.1868
Epoch   8 Batch   32/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8744, Loss: 0.1884
Epoch   8 Batch   33/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8725, Loss: 0.1843
Epoch   8 Batch   34/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8651, Loss: 0.1915
Epoch   8 Batch   35/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8718, Loss: 0.2007
Epoch   8 Batch   36/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8715, Loss: 0.1946
Epoch   8 Batch   37/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8792, Loss: 0.1935
Epoch   8 Batch   38/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8659, Loss: 0.1970
Epoch   8 Batch   39/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8788, Loss: 0.1845
Epoch   8 Batch   40/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8716, Loss: 0.1948
Epoch   8 Batch   41/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8709, Loss: 0.2002
Epoch   8 Batch   42/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8772, Loss: 0.1816
Epoch   8 Batch   43/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8770, Loss: 0.1964
Epoch   8 Batch   44/269 - Train Accuracy: 0.8796, Validation Accuracy: 0.8790, Loss: 0.1972
Epoch   8 Batch   45/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8767, Loss: 0.1922
Epoch   8 Batch   46/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8767, Loss: 0.2004
Epoch   8 Batch   47/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8795, Loss: 0.1742
Epoch   8 Batch   48/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8787, Loss: 0.1871
Epoch   8 Batch   49/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8718, Loss: 0.1888
Epoch   8 Batch   50/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8775, Loss: 0.1957
Epoch   8 Batch   51/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8705, Loss: 0.1874
Epoch   8 Batch   52/269 - Train Accuracy: 0.8549, Validation Accuracy: 0.8711, Loss: 0.1792
Epoch   8 Batch   53/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8787, Loss: 0.2105
Epoch   8 Batch   54/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8747, Loss: 0.1936
Epoch   8 Batch   55/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8658, Loss: 0.1824
Epoch   8 Batch   56/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8687, Loss: 0.1904
Epoch   8 Batch   57/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8751, Loss: 0.1977
Epoch   8 Batch   58/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8707, Loss: 0.1865
Epoch   8 Batch   59/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8748, Loss: 0.1675
Epoch   8 Batch   60/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8773, Loss: 0.1764
Epoch   8 Batch   61/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.8728, Loss: 0.1732
Epoch   8 Batch   62/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8691, Loss: 0.1839
Epoch   8 Batch   63/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8730, Loss: 0.1960
Epoch   8 Batch   64/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8640, Loss: 0.1792
Epoch   8 Batch   65/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8646, Loss: 0.1894
Epoch   8 Batch   66/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8642, Loss: 0.1846
Epoch   8 Batch   67/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8743, Loss: 0.2000
Epoch   8 Batch   68/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8769, Loss: 0.2011
Epoch   8 Batch   69/269 - Train Accuracy: 0.8589, Validation Accuracy: 0.8817, Loss: 0.2056
Epoch   8 Batch   70/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8805, Loss: 0.1990
Epoch   8 Batch   71/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8849, Loss: 0.1958
Epoch   8 Batch   72/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8668, Loss: 0.1964
Epoch   8 Batch   73/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8763, Loss: 0.1980
Epoch   8 Batch   74/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8722, Loss: 0.1863
Epoch   8 Batch   75/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8754, Loss: 0.1857
Epoch   8 Batch   76/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8681, Loss: 0.1834
Epoch   8 Batch   77/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8737, Loss: 0.1862
Epoch   8 Batch   78/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8788, Loss: 0.1819
Epoch   8 Batch   79/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8776, Loss: 0.1847
Epoch   8 Batch   80/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8779, Loss: 0.1873
Epoch   8 Batch   81/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8776, Loss: 0.1962
Epoch   8 Batch   82/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.8842, Loss: 0.1790
Epoch   8 Batch   83/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8723, Loss: 0.1939
Epoch   8 Batch   84/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8764, Loss: 0.1796
Epoch   8 Batch   85/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.8726, Loss: 0.1835
Epoch   8 Batch   86/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8725, Loss: 0.1802
Epoch   8 Batch   87/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8736, Loss: 0.1980
Epoch   8 Batch   88/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8770, Loss: 0.1891
Epoch   8 Batch   89/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.8730, Loss: 0.1786
Epoch   8 Batch   90/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8714, Loss: 0.1942
Epoch   8 Batch   91/269 - Train Accuracy: 0.8950, Validation Accuracy: 0.8682, Loss: 0.1761
Epoch   8 Batch   92/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.8695, Loss: 0.1734
Epoch   8 Batch   93/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8663, Loss: 0.1765
Epoch   8 Batch   94/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8708, Loss: 0.1915
Epoch   8 Batch   95/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8730, Loss: 0.1741
Epoch   8 Batch   96/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8705, Loss: 0.1839
Epoch   8 Batch   97/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8699, Loss: 0.1757
Epoch   8 Batch   98/269 - Train Accuracy: 0.8721, Validation Accuracy: 0.8731, Loss: 0.1826
Epoch   8 Batch   99/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8712, Loss: 0.1833
Epoch   8 Batch  100/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8769, Loss: 0.1773
Epoch   8 Batch  101/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8759, Loss: 0.1980
Epoch   8 Batch  102/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8777, Loss: 0.1844
Epoch   8 Batch  103/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8692, Loss: 0.1885
Epoch   8 Batch  104/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8778, Loss: 0.1842
Epoch   8 Batch  105/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8728, Loss: 0.1867
Epoch   8 Batch  106/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8684, Loss: 0.1801
Epoch   8 Batch  107/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8762, Loss: 0.1872
Epoch   8 Batch  108/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8727, Loss: 0.1777
Epoch   8 Batch  109/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8746, Loss: 0.1920
Epoch   8 Batch  110/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8704, Loss: 0.1734
Epoch   8 Batch  111/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8779, Loss: 0.1949
Epoch   8 Batch  112/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8751, Loss: 0.1802
Epoch   8 Batch  113/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8686, Loss: 0.1772
Epoch   8 Batch  114/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8710, Loss: 0.1831
Epoch   8 Batch  115/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8737, Loss: 0.1880
Epoch   8 Batch  116/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.8754, Loss: 0.1857
Epoch   8 Batch  117/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8724, Loss: 0.1776
Epoch   8 Batch  118/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.8723, Loss: 0.1686
Epoch   8 Batch  119/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8739, Loss: 0.1903
Epoch   8 Batch  120/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8727, Loss: 0.1796
Epoch   8 Batch  121/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8762, Loss: 0.1692
Epoch   8 Batch  122/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8785, Loss: 0.1733
Epoch   8 Batch  123/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8785, Loss: 0.1864
Epoch   8 Batch  124/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8754, Loss: 0.1636
Epoch   8 Batch  125/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8704, Loss: 0.1688
Epoch   8 Batch  126/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8718, Loss: 0.1827
Epoch   8 Batch  127/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8705, Loss: 0.1816
Epoch   8 Batch  128/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8785, Loss: 0.1886
Epoch   8 Batch  129/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8811, Loss: 0.1773
Epoch   8 Batch  130/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8797, Loss: 0.1891
Epoch   8 Batch  131/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8817, Loss: 0.1848
Epoch   8 Batch  132/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8722, Loss: 0.1781
Epoch   8 Batch  133/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8784, Loss: 0.1709
Epoch   8 Batch  134/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8742, Loss: 0.1810
Epoch   8 Batch  135/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8768, Loss: 0.1911
Epoch   8 Batch  136/269 - Train Accuracy: 0.8583, Validation Accuracy: 0.8787, Loss: 0.1926
Epoch   8 Batch  137/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8793, Loss: 0.1947
Epoch   8 Batch  138/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8764, Loss: 0.1799
Epoch   8 Batch  139/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8779, Loss: 0.1723
Epoch   8 Batch  140/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8769, Loss: 0.1921
Epoch   8 Batch  141/269 - Train Accuracy: 0.8893, Validation Accuracy: 0.8780, Loss: 0.1833
Epoch   8 Batch  142/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8687, Loss: 0.1739
Epoch   8 Batch  143/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8738, Loss: 0.1716
Epoch   8 Batch  144/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8726, Loss: 0.1661
Epoch   8 Batch  145/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8697, Loss: 0.1696
Epoch   8 Batch  146/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8700, Loss: 0.1766
Epoch   8 Batch  147/269 - Train Accuracy: 0.8925, Validation Accuracy: 0.8782, Loss: 0.1751
Epoch   8 Batch  148/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8778, Loss: 0.1787
Epoch   8 Batch  149/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8766, Loss: 0.1878
Epoch   8 Batch  150/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8779, Loss: 0.1779
Epoch   8 Batch  151/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8770, Loss: 0.1722
Epoch   8 Batch  152/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8773, Loss: 0.1770
Epoch   8 Batch  153/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8762, Loss: 0.1762
Epoch   8 Batch  154/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.8727, Loss: 0.1743
Epoch   8 Batch  155/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8724, Loss: 0.1737
Epoch   8 Batch  156/269 - Train Accuracy: 0.8712, Validation Accuracy: 0.8692, Loss: 0.1786
Epoch   8 Batch  157/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8716, Loss: 0.1701
Epoch   8 Batch  158/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.8794, Loss: 0.1681
Epoch   8 Batch  159/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8808, Loss: 0.1791
Epoch   8 Batch  160/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8808, Loss: 0.1704
Epoch   8 Batch  161/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8816, Loss: 0.1764
Epoch   8 Batch  162/269 - Train Accuracy: 0.8927, Validation Accuracy: 0.8782, Loss: 0.1706
Epoch   8 Batch  163/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8779, Loss: 0.1788
Epoch   8 Batch  164/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8798, Loss: 0.1799
Epoch   8 Batch  165/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8802, Loss: 0.1753
Epoch   8 Batch  166/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.8749, Loss: 0.1695
Epoch   8 Batch  167/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8770, Loss: 0.1781
Epoch   8 Batch  168/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8809, Loss: 0.1810
Epoch   8 Batch  169/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8753, Loss: 0.1753
Epoch   8 Batch  170/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8792, Loss: 0.1748
Epoch   8 Batch  171/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.8761, Loss: 0.1794
Epoch   8 Batch  172/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8726, Loss: 0.1811
Epoch   8 Batch  173/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.8712, Loss: 0.1623
Epoch   8 Batch  174/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8762, Loss: 0.1732
Epoch   8 Batch  175/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8715, Loss: 0.1900
Epoch   8 Batch  176/269 - Train Accuracy: 0.8669, Validation Accuracy: 0.8787, Loss: 0.1862
Epoch   8 Batch  177/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.8774, Loss: 0.1650
Epoch   8 Batch  178/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8824, Loss: 0.1741
Epoch   8 Batch  179/269 - Train Accuracy: 0.8752, Validation Accuracy: 0.8820, Loss: 0.1665
Epoch   8 Batch  180/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8825, Loss: 0.1658
Epoch   8 Batch  181/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8838, Loss: 0.1728
Epoch   8 Batch  182/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8849, Loss: 0.1688
Epoch   8 Batch  183/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.8841, Loss: 0.1450
Epoch   8 Batch  184/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8838, Loss: 0.1718
Epoch   8 Batch  185/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.8801, Loss: 0.1672
Epoch   8 Batch  186/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.8786, Loss: 0.1666
Epoch   8 Batch  187/269 - Train Accuracy: 0.8869, Validation Accuracy: 0.8876, Loss: 0.1666
Epoch   8 Batch  188/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8833, Loss: 0.1546
Epoch   8 Batch  189/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8822, Loss: 0.1642
Epoch   8 Batch  190/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8781, Loss: 0.1557
Epoch   8 Batch  191/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8853, Loss: 0.1579
Epoch   8 Batch  192/269 - Train Accuracy: 0.8834, Validation Accuracy: 0.8858, Loss: 0.1687
Epoch   8 Batch  193/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8789, Loss: 0.1629
Epoch   8 Batch  194/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8852, Loss: 0.1785
Epoch   8 Batch  195/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8807, Loss: 0.1715
Epoch   8 Batch  196/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8780, Loss: 0.1645
Epoch   8 Batch  197/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8789, Loss: 0.1821
Epoch   8 Batch  198/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8868, Loss: 0.1799
Epoch   8 Batch  199/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8873, Loss: 0.1785
Epoch   8 Batch  200/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8884, Loss: 0.1697
Epoch   8 Batch  201/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8857, Loss: 0.1668
Epoch   8 Batch  202/269 - Train Accuracy: 0.8741, Validation Accuracy: 0.8865, Loss: 0.1672
Epoch   8 Batch  203/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.8829, Loss: 0.1836
Epoch   8 Batch  204/269 - Train Accuracy: 0.8763, Validation Accuracy: 0.8848, Loss: 0.1790
Epoch   8 Batch  205/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8789, Loss: 0.1666
Epoch   8 Batch  206/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8825, Loss: 0.1801
Epoch   8 Batch  207/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8803, Loss: 0.1611
Epoch   8 Batch  208/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.8809, Loss: 0.1736
Epoch   8 Batch  209/269 - Train Accuracy: 0.8941, Validation Accuracy: 0.8766, Loss: 0.1624
Epoch   8 Batch  210/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.8804, Loss: 0.1611
Epoch   8 Batch  211/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8823, Loss: 0.1719
Epoch   8 Batch  212/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8775, Loss: 0.1749
Epoch   8 Batch  213/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8805, Loss: 0.1644
Epoch   8 Batch  214/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8845, Loss: 0.1725
Epoch   8 Batch  215/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.8898, Loss: 0.1570
Epoch   8 Batch  216/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8904, Loss: 0.1896
Epoch   8 Batch  217/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8889, Loss: 0.1723
Epoch   8 Batch  218/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8893, Loss: 0.1720
Epoch   8 Batch  219/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8920, Loss: 0.1731
Epoch   8 Batch  220/269 - Train Accuracy: 0.9014, Validation Accuracy: 0.8860, Loss: 0.1609
Epoch   8 Batch  221/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8822, Loss: 0.1705
Epoch   8 Batch  222/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.8880, Loss: 0.1579
Epoch   8 Batch  223/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8817, Loss: 0.1585
Epoch   8 Batch  224/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8859, Loss: 0.1782
Epoch   8 Batch  225/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8812, Loss: 0.1610
Epoch   8 Batch  226/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8800, Loss: 0.1655
Epoch   8 Batch  227/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.8902, Loss: 0.1610
Epoch   8 Batch  228/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8873, Loss: 0.1597
Epoch   8 Batch  229/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8846, Loss: 0.1674
Epoch   8 Batch  230/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8843, Loss: 0.1654
Epoch   8 Batch  231/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8840, Loss: 0.1736
Epoch   8 Batch  232/269 - Train Accuracy: 0.8772, Validation Accuracy: 0.8809, Loss: 0.1711
Epoch   8 Batch  233/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.8830, Loss: 0.1746
Epoch   8 Batch  234/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.8849, Loss: 0.1595
Epoch   8 Batch  235/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.8831, Loss: 0.1566
Epoch   8 Batch  236/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8821, Loss: 0.1520
Epoch   8 Batch  237/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8878, Loss: 0.1604
Epoch   8 Batch  238/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8881, Loss: 0.1621
Epoch   8 Batch  239/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8824, Loss: 0.1648
Epoch   8 Batch  240/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.8948, Loss: 0.1515
Epoch   8 Batch  241/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8948, Loss: 0.1798
Epoch   8 Batch  242/269 - Train Accuracy: 0.8906, Validation Accuracy: 0.8896, Loss: 0.1634
Epoch   8 Batch  243/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.8780, Loss: 0.1527
Epoch   8 Batch  244/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.8872, Loss: 0.1687
Epoch   8 Batch  245/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8857, Loss: 0.1778
Epoch   8 Batch  246/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8889, Loss: 0.1609
Epoch   8 Batch  247/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8912, Loss: 0.1666
Epoch   8 Batch  248/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.8868, Loss: 0.1528
Epoch   8 Batch  249/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.8800, Loss: 0.1445
Epoch   8 Batch  250/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8855, Loss: 0.1552
Epoch   8 Batch  251/269 - Train Accuracy: 0.9105, Validation Accuracy: 0.8815, Loss: 0.1580
Epoch   8 Batch  252/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8855, Loss: 0.1523
Epoch   8 Batch  253/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8892, Loss: 0.1707
Epoch   8 Batch  254/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8870, Loss: 0.1581
Epoch   8 Batch  255/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.8946, Loss: 0.1601
Epoch   8 Batch  256/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8851, Loss: 0.1559
Epoch   8 Batch  257/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8866, Loss: 0.1706
Epoch   8 Batch  258/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8904, Loss: 0.1704
Epoch   8 Batch  259/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.8938, Loss: 0.1612
Epoch   8 Batch  260/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8877, Loss: 0.1647
Epoch   8 Batch  261/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8869, Loss: 0.1638
Epoch   8 Batch  262/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.8864, Loss: 0.1614
Epoch   8 Batch  263/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8886, Loss: 0.1667
Epoch   8 Batch  264/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8860, Loss: 0.1681
Epoch   8 Batch  265/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8907, Loss: 0.1599
Epoch   8 Batch  266/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8853, Loss: 0.1552
Epoch   8 Batch  267/269 - Train Accuracy: 0.8927, Validation Accuracy: 0.8813, Loss: 0.1613
Epoch   9 Batch    1/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8804, Loss: 0.1582
Epoch   9 Batch    2/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.8752, Loss: 0.1631
Epoch   9 Batch    3/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.8809, Loss: 0.1666
Epoch   9 Batch    4/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8819, Loss: 0.1662
Epoch   9 Batch    5/269 - Train Accuracy: 0.8838, Validation Accuracy: 0.8817, Loss: 0.1589
Epoch   9 Batch    6/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.8830, Loss: 0.1536
Epoch   9 Batch    7/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.8864, Loss: 0.1557
Epoch   9 Batch    8/269 - Train Accuracy: 0.8993, Validation Accuracy: 0.8888, Loss: 0.1628
Epoch   9 Batch    9/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8912, Loss: 0.1584
Epoch   9 Batch   10/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8900, Loss: 0.1531
Epoch   9 Batch   11/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8865, Loss: 0.1655
Epoch   9 Batch   12/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8858, Loss: 0.1722
Epoch   9 Batch   13/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8850, Loss: 0.1466
Epoch   9 Batch   14/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8845, Loss: 0.1576
Epoch   9 Batch   15/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8850, Loss: 0.1388
Epoch   9 Batch   16/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8864, Loss: 0.1617
Epoch   9 Batch   17/269 - Train Accuracy: 0.8961, Validation Accuracy: 0.8881, Loss: 0.1503
Epoch   9 Batch   18/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.8825, Loss: 0.1503
Epoch   9 Batch   19/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.8871, Loss: 0.1455
Epoch   9 Batch   20/269 - Train Accuracy: 0.8926, Validation Accuracy: 0.8835, Loss: 0.1542
Epoch   9 Batch   21/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8865, Loss: 0.1760
Epoch   9 Batch   22/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.8821, Loss: 0.1437
Epoch   9 Batch   23/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8823, Loss: 0.1631
Epoch   9 Batch   24/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8841, Loss: 0.1607
Epoch   9 Batch   25/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8832, Loss: 0.1670
Epoch   9 Batch   26/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.8849, Loss: 0.1434
Epoch   9 Batch   27/269 - Train Accuracy: 0.8859, Validation Accuracy: 0.8869, Loss: 0.1519
Epoch   9 Batch   28/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8889, Loss: 0.1696
Epoch   9 Batch   29/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.8862, Loss: 0.1664
Epoch   9 Batch   30/269 - Train Accuracy: 0.8959, Validation Accuracy: 0.8905, Loss: 0.1496
Epoch   9 Batch   31/269 - Train Accuracy: 0.8993, Validation Accuracy: 0.8933, Loss: 0.1545
Epoch   9 Batch   32/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.9011, Loss: 0.1508
Epoch   9 Batch   33/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.8977, Loss: 0.1471
Epoch   9 Batch   34/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.8941, Loss: 0.1507
Epoch   9 Batch   35/269 - Train Accuracy: 0.8950, Validation Accuracy: 0.8945, Loss: 0.1608
Epoch   9 Batch   36/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8894, Loss: 0.1550
Epoch   9 Batch   37/269 - Train Accuracy: 0.8893, Validation Accuracy: 0.8970, Loss: 0.1564
Epoch   9 Batch   38/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8850, Loss: 0.1542
Epoch   9 Batch   39/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.8924, Loss: 0.1474
Epoch   9 Batch   40/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8912, Loss: 0.1618
Epoch   9 Batch   41/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8944, Loss: 0.1669
Epoch   9 Batch   42/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.8951, Loss: 0.1475
Epoch   9 Batch   43/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.8918, Loss: 0.1601
Epoch   9 Batch   44/269 - Train Accuracy: 0.8898, Validation Accuracy: 0.8918, Loss: 0.1587
Epoch   9 Batch   45/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8915, Loss: 0.1526
Epoch   9 Batch   46/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8920, Loss: 0.1490
Epoch   9 Batch   47/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.8981, Loss: 0.1371
Epoch   9 Batch   48/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.8912, Loss: 0.1401
Epoch   9 Batch   49/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.8934, Loss: 0.1511
Epoch   9 Batch   50/269 - Train Accuracy: 0.8779, Validation Accuracy: 0.8939, Loss: 0.1662
Epoch   9 Batch   51/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.8920, Loss: 0.1526
Epoch   9 Batch   52/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8954, Loss: 0.1417
Epoch   9 Batch   53/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8926, Loss: 0.1630
Epoch   9 Batch   54/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.8932, Loss: 0.1568
Epoch   9 Batch   55/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.8989, Loss: 0.1471
Epoch   9 Batch   56/269 - Train Accuracy: 0.8871, Validation Accuracy: 0.8971, Loss: 0.1554
Epoch   9 Batch   57/269 - Train Accuracy: 0.9044, Validation Accuracy: 0.8976, Loss: 0.1574
Epoch   9 Batch   58/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.9034, Loss: 0.1560
Epoch   9 Batch   59/269 - Train Accuracy: 0.9220, Validation Accuracy: 0.9012, Loss: 0.1312
Epoch   9 Batch   60/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.8975, Loss: 0.1419
Epoch   9 Batch   61/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.8957, Loss: 0.1328
Epoch   9 Batch   62/269 - Train Accuracy: 0.9082, Validation Accuracy: 0.8978, Loss: 0.1511
Epoch   9 Batch   63/269 - Train Accuracy: 0.8961, Validation Accuracy: 0.8972, Loss: 0.1574
Epoch   9 Batch   64/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.8968, Loss: 0.1391
Epoch   9 Batch   65/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8926, Loss: 0.1422
Epoch   9 Batch   66/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8916, Loss: 0.1527
Epoch   9 Batch   67/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8959, Loss: 0.1575
Epoch   9 Batch   68/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8955, Loss: 0.1618
Epoch   9 Batch   69/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8982, Loss: 0.1772
Epoch   9 Batch   70/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9017, Loss: 0.1597
Epoch   9 Batch   71/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9029, Loss: 0.1616
Epoch   9 Batch   72/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8989, Loss: 0.1537
Epoch   9 Batch   73/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.9007, Loss: 0.1585
Epoch   9 Batch   74/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.8952, Loss: 0.1452
Epoch   9 Batch   75/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.8980, Loss: 0.1491
Epoch   9 Batch   76/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8952, Loss: 0.1518
Epoch   9 Batch   77/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8952, Loss: 0.1437
Epoch   9 Batch   78/269 - Train Accuracy: 0.8998, Validation Accuracy: 0.8928, Loss: 0.1504
Epoch   9 Batch   79/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8940, Loss: 0.1481
Epoch   9 Batch   80/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.8965, Loss: 0.1464
Epoch   9 Batch   81/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8968, Loss: 0.1608
Epoch   9 Batch   82/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9001, Loss: 0.1356
Epoch   9 Batch   83/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8984, Loss: 0.1606
Epoch   9 Batch   84/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.8987, Loss: 0.1436
Epoch   9 Batch   85/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8908, Loss: 0.1410
Epoch   9 Batch   86/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.8904, Loss: 0.1358
Epoch   9 Batch   87/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8912, Loss: 0.1581
Epoch   9 Batch   88/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8866, Loss: 0.1468
Epoch   9 Batch   89/269 - Train Accuracy: 0.9124, Validation Accuracy: 0.8924, Loss: 0.1434
Epoch   9 Batch   90/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.8921, Loss: 0.1585
Epoch   9 Batch   91/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.8859, Loss: 0.1471
Epoch   9 Batch   92/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.8895, Loss: 0.1457
Epoch   9 Batch   93/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.8906, Loss: 0.1458
Epoch   9 Batch   94/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.8913, Loss: 0.1565
Epoch   9 Batch   95/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.8901, Loss: 0.1419
Epoch   9 Batch   96/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8919, Loss: 0.1456
Epoch   9 Batch   97/269 - Train Accuracy: 0.9051, Validation Accuracy: 0.8993, Loss: 0.1415
Epoch   9 Batch   98/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8944, Loss: 0.1442
Epoch   9 Batch   99/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8938, Loss: 0.1429
Epoch   9 Batch  100/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.8960, Loss: 0.1437
Epoch   9 Batch  101/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8963, Loss: 0.1573
Epoch   9 Batch  102/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9013, Loss: 0.1428
Epoch   9 Batch  103/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8971, Loss: 0.1471
Epoch   9 Batch  104/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.8937, Loss: 0.1445
Epoch   9 Batch  105/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.9027, Loss: 0.1518
Epoch   9 Batch  106/269 - Train Accuracy: 0.9037, Validation Accuracy: 0.9015, Loss: 0.1422
Epoch   9 Batch  107/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.8873, Loss: 0.1493
Epoch   9 Batch  108/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.8961, Loss: 0.1473
Epoch   9 Batch  109/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8983, Loss: 0.1538
Epoch   9 Batch  110/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.8965, Loss: 0.1396
Epoch   9 Batch  111/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8989, Loss: 0.1610
Epoch   9 Batch  112/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.8983, Loss: 0.1526
Epoch   9 Batch  113/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.8983, Loss: 0.1410
Epoch   9 Batch  114/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.8969, Loss: 0.1458
Epoch   9 Batch  115/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.8975, Loss: 0.1474
Epoch   9 Batch  116/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.8978, Loss: 0.1520
Epoch   9 Batch  117/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9006, Loss: 0.1409
Epoch   9 Batch  118/269 - Train Accuracy: 0.9152, Validation Accuracy: 0.8998, Loss: 0.1332
Epoch   9 Batch  119/269 - Train Accuracy: 0.8962, Validation Accuracy: 0.8982, Loss: 0.1532
Epoch   9 Batch  120/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8976, Loss: 0.1475
Epoch   9 Batch  121/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.8971, Loss: 0.1344
Epoch   9 Batch  122/269 - Train Accuracy: 0.8992, Validation Accuracy: 0.8959, Loss: 0.1390
Epoch   9 Batch  123/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8969, Loss: 0.1502
Epoch   9 Batch  124/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.9018, Loss: 0.1271
Epoch   9 Batch  125/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.8959, Loss: 0.1342
Epoch   9 Batch  126/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8962, Loss: 0.1426
Epoch   9 Batch  127/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8930, Loss: 0.1416
Epoch   9 Batch  128/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.8969, Loss: 0.1411
Epoch   9 Batch  129/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8965, Loss: 0.1396
Epoch   9 Batch  130/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8953, Loss: 0.1517
Epoch   9 Batch  131/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8987, Loss: 0.1471
Epoch   9 Batch  132/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.8942, Loss: 0.1509
Epoch   9 Batch  133/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.8975, Loss: 0.1396
Epoch   9 Batch  134/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.8988, Loss: 0.1484
Epoch   9 Batch  135/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.8991, Loss: 0.1543
Epoch   9 Batch  136/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8981, Loss: 0.1513
Epoch   9 Batch  137/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8999, Loss: 0.1534
Epoch   9 Batch  138/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9012, Loss: 0.1403
Epoch   9 Batch  139/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.8998, Loss: 0.1379
Epoch   9 Batch  140/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.8991, Loss: 0.1557
Epoch   9 Batch  141/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.8981, Loss: 0.1472
Epoch   9 Batch  142/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8994, Loss: 0.1393
Epoch   9 Batch  143/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.8968, Loss: 0.1340
Epoch   9 Batch  144/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.8975, Loss: 0.1248
Epoch   9 Batch  145/269 - Train Accuracy: 0.9080, Validation Accuracy: 0.8960, Loss: 0.1339
Epoch   9 Batch  146/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8941, Loss: 0.1381
Epoch   9 Batch  147/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.8955, Loss: 0.1417
Epoch   9 Batch  148/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.9015, Loss: 0.1422
Epoch   9 Batch  149/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8961, Loss: 0.1554
Epoch   9 Batch  150/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.8888, Loss: 0.1366
Epoch   9 Batch  151/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.8904, Loss: 0.1397
Epoch   9 Batch  152/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9010, Loss: 0.1419
Epoch   9 Batch  153/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.8983, Loss: 0.1385
Epoch   9 Batch  154/269 - Train Accuracy: 0.9250, Validation Accuracy: 0.8944, Loss: 0.1420
Epoch   9 Batch  155/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.8893, Loss: 0.1316
Epoch   9 Batch  156/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.8922, Loss: 0.1523
Epoch   9 Batch  157/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9026, Loss: 0.1387
Epoch   9 Batch  158/269 - Train Accuracy: 0.9031, Validation Accuracy: 0.9024, Loss: 0.1421
Epoch   9 Batch  159/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.9036, Loss: 0.1473
Epoch   9 Batch  160/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9038, Loss: 0.1434
Epoch   9 Batch  161/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9059, Loss: 0.1384
Epoch   9 Batch  162/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9011, Loss: 0.1340
Epoch   9 Batch  163/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.9039, Loss: 0.1448
Epoch   9 Batch  164/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9036, Loss: 0.1404
Epoch   9 Batch  165/269 - Train Accuracy: 0.8998, Validation Accuracy: 0.8990, Loss: 0.1362
Epoch   9 Batch  166/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.8952, Loss: 0.1358
Epoch   9 Batch  167/269 - Train Accuracy: 0.8941, Validation Accuracy: 0.8938, Loss: 0.1420
Epoch   9 Batch  168/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.8980, Loss: 0.1453
Epoch   9 Batch  169/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.8945, Loss: 0.1457
Epoch   9 Batch  170/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.8961, Loss: 0.1400
Epoch   9 Batch  171/269 - Train Accuracy: 0.9114, Validation Accuracy: 0.8907, Loss: 0.1374
Epoch   9 Batch  172/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8947, Loss: 0.1509
Epoch   9 Batch  173/269 - Train Accuracy: 0.9066, Validation Accuracy: 0.8975, Loss: 0.1372
Epoch   9 Batch  174/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.8942, Loss: 0.1447
Epoch   9 Batch  175/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8945, Loss: 0.1571
Epoch   9 Batch  176/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8991, Loss: 0.1511
Epoch   9 Batch  177/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.8967, Loss: 0.1335
Epoch   9 Batch  178/269 - Train Accuracy: 0.9080, Validation Accuracy: 0.8970, Loss: 0.1362
Epoch   9 Batch  179/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8956, Loss: 0.1369
Epoch   9 Batch  180/269 - Train Accuracy: 0.9166, Validation Accuracy: 0.8973, Loss: 0.1417
Epoch   9 Batch  181/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8876, Loss: 0.1463
Epoch   9 Batch  182/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.8914, Loss: 0.1397
Epoch   9 Batch  183/269 - Train Accuracy: 0.9171, Validation Accuracy: 0.9022, Loss: 0.1303
Epoch   9 Batch  184/269 - Train Accuracy: 0.9104, Validation Accuracy: 0.8991, Loss: 0.1434
Epoch   9 Batch  185/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9006, Loss: 0.1413
Epoch   9 Batch  186/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.8993, Loss: 0.1401
Epoch   9 Batch  187/269 - Train Accuracy: 0.9065, Validation Accuracy: 0.8995, Loss: 0.1415
Epoch   9 Batch  188/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.8975, Loss: 0.1378
Epoch   9 Batch  189/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9023, Loss: 0.1311
Epoch   9 Batch  190/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9030, Loss: 0.1302
Epoch   9 Batch  191/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.9008, Loss: 0.1317
Epoch   9 Batch  192/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9003, Loss: 0.1422
Epoch   9 Batch  193/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.8971, Loss: 0.1371
Epoch   9 Batch  194/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8976, Loss: 0.1465
Epoch   9 Batch  195/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.8994, Loss: 0.1394
Epoch   9 Batch  196/269 - Train Accuracy: 0.8950, Validation Accuracy: 0.9049, Loss: 0.1324
Epoch   9 Batch  197/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9062, Loss: 0.1463
Epoch   9 Batch  198/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.9004, Loss: 0.1393
Epoch   9 Batch  199/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.9002, Loss: 0.1434
Epoch   9 Batch  200/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.9076, Loss: 0.1419
Epoch   9 Batch  201/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.8988, Loss: 0.1417
Epoch   9 Batch  202/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9126, Loss: 0.1426
Epoch   9 Batch  203/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.9046, Loss: 0.1483
Epoch   9 Batch  204/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.9013, Loss: 0.1449
Epoch   9 Batch  205/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8948, Loss: 0.1381
Epoch   9 Batch  206/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.9014, Loss: 0.1486
Epoch   9 Batch  207/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8995, Loss: 0.1324
Epoch   9 Batch  208/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.9044, Loss: 0.1480
Epoch   9 Batch  209/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.8995, Loss: 0.1271
Epoch   9 Batch  210/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9023, Loss: 0.1308
Epoch   9 Batch  211/269 - Train Accuracy: 0.8963, Validation Accuracy: 0.9009, Loss: 0.1399
Epoch   9 Batch  212/269 - Train Accuracy: 0.9003, Validation Accuracy: 0.9014, Loss: 0.1425
Epoch   9 Batch  213/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.9041, Loss: 0.1330
Epoch   9 Batch  214/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.9015, Loss: 0.1392
Epoch   9 Batch  215/269 - Train Accuracy: 0.9252, Validation Accuracy: 0.9047, Loss: 0.1299
Epoch   9 Batch  216/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8955, Loss: 0.1549
Epoch   9 Batch  217/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.8998, Loss: 0.1490
Epoch   9 Batch  218/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.8973, Loss: 0.1341
Epoch   9 Batch  219/269 - Train Accuracy: 0.9021, Validation Accuracy: 0.8984, Loss: 0.1388
Epoch   9 Batch  220/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.8952, Loss: 0.1327
Epoch   9 Batch  221/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.8999, Loss: 0.1413
Epoch   9 Batch  222/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.8988, Loss: 0.1216
Epoch   9 Batch  223/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.9050, Loss: 0.1337
Epoch   9 Batch  224/269 - Train Accuracy: 0.8981, Validation Accuracy: 0.9032, Loss: 0.1451
Epoch   9 Batch  225/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.9080, Loss: 0.1354
Epoch   9 Batch  226/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.9023, Loss: 0.1399
Epoch   9 Batch  227/269 - Train Accuracy: 0.9230, Validation Accuracy: 0.9038, Loss: 0.1401
Epoch   9 Batch  228/269 - Train Accuracy: 0.8927, Validation Accuracy: 0.8981, Loss: 0.1344
Epoch   9 Batch  229/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.9000, Loss: 0.1324
Epoch   9 Batch  230/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.9058, Loss: 0.1314
Epoch   9 Batch  231/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9005, Loss: 0.1461
Epoch   9 Batch  232/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.9028, Loss: 0.1350
Epoch   9 Batch  233/269 - Train Accuracy: 0.9126, Validation Accuracy: 0.9031, Loss: 0.1382
Epoch   9 Batch  234/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9031, Loss: 0.1317
Epoch   9 Batch  235/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9057, Loss: 0.1278
Epoch   9 Batch  236/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.8994, Loss: 0.1346
Epoch   9 Batch  237/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.9029, Loss: 0.1358
Epoch   9 Batch  238/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9080, Loss: 0.1357
Epoch   9 Batch  239/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.9086, Loss: 0.1315
Epoch   9 Batch  240/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.9064, Loss: 0.1261
Epoch   9 Batch  241/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.9150, Loss: 0.1478
Epoch   9 Batch  242/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9052, Loss: 0.1262
Epoch   9 Batch  243/269 - Train Accuracy: 0.9160, Validation Accuracy: 0.9166, Loss: 0.1219
Epoch   9 Batch  244/269 - Train Accuracy: 0.9103, Validation Accuracy: 0.9023, Loss: 0.1339
Epoch   9 Batch  245/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.9081, Loss: 0.1433
Epoch   9 Batch  246/269 - Train Accuracy: 0.8847, Validation Accuracy: 0.9025, Loss: 0.1381
Epoch   9 Batch  247/269 - Train Accuracy: 0.9097, Validation Accuracy: 0.9111, Loss: 0.1381
Epoch   9 Batch  248/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.9080, Loss: 0.1223
Epoch   9 Batch  249/269 - Train Accuracy: 0.9209, Validation Accuracy: 0.9096, Loss: 0.1235
Epoch   9 Batch  250/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.8999, Loss: 0.1267
Epoch   9 Batch  251/269 - Train Accuracy: 0.9260, Validation Accuracy: 0.9110, Loss: 0.1347
Epoch   9 Batch  252/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9097, Loss: 0.1145
Epoch   9 Batch  253/269 - Train Accuracy: 0.8906, Validation Accuracy: 0.9071, Loss: 0.1397
Epoch   9 Batch  254/269 - Train Accuracy: 0.9065, Validation Accuracy: 0.9071, Loss: 0.1329
Epoch   9 Batch  255/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9074, Loss: 0.1314
Epoch   9 Batch  256/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.9081, Loss: 0.1315
Epoch   9 Batch  257/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.9031, Loss: 0.1395
Epoch   9 Batch  258/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.9065, Loss: 0.1398
Epoch   9 Batch  259/269 - Train Accuracy: 0.9085, Validation Accuracy: 0.9010, Loss: 0.1284
Epoch   9 Batch  260/269 - Train Accuracy: 0.8944, Validation Accuracy: 0.9010, Loss: 0.1422
Epoch   9 Batch  261/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9066, Loss: 0.1282
Epoch   9 Batch  262/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9094, Loss: 0.1348
Epoch   9 Batch  263/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9113, Loss: 0.1300
Epoch   9 Batch  264/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.9047, Loss: 0.1333
Epoch   9 Batch  265/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.9055, Loss: 0.1227
Epoch   9 Batch  266/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9098, Loss: 0.1216
Epoch   9 Batch  267/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9036, Loss: 0.1413
Modelo treinado e salvo
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Salvar-Par&#226;metros">Salvar Par&#226;metros<a class="anchor-link" href="#Salvar-Par&#226;metros">&#182;</a></h3><p>Salvar os parametros <code>batch_size</code> e <code>save_path</code> para inferencia.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">helper</span><span class="o">.</span><span class="n">save_params</span><span class="p">(</span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Checkpoint">Checkpoint<a class="anchor-link" href="#Checkpoint">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[30]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">helper</span>
<span class="kn">import</span> <span class="nn">problem_unittests</span> <span class="k">as</span> <span class="nn">tests</span>

<span class="n">_</span><span class="p">,</span> <span class="p">(</span><span class="n">source_vocab_to_int</span><span class="p">,</span> <span class="n">target_vocab_to_int</span><span class="p">),</span> <span class="p">(</span><span class="n">source_int_to_vocab</span><span class="p">,</span> <span class="n">target_int_to_vocab</span><span class="p">)</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_preprocess</span><span class="p">()</span>
<span class="n">load_path</span> <span class="o">=</span> <span class="n">helper</span><span class="o">.</span><span class="n">load_params</span><span class="p">()</span>
</pre></div>

</div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Senten&#231;a-a-Sequencia">Senten&#231;a a Sequencia<a class="anchor-link" href="#Senten&#231;a-a-Sequencia">&#182;</a></h2><p>Para alimentar uma frase no modelo para tradução, você primeiro precisa pré-processá-la. Implemente a função <code>sentence_para_seq ()</code> para pré-processar novas sentenças.</p>
<ul>
<li>Converta a frase para minúscula</li>
<li>Converta palavras em ids usando o <code>vocab_to_int</code><ul>
<li>Converter palavras não no vocabulário, ao <code>&lt;UNK&gt;</code> id palavra.</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[31]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">sentence_to_seq</span><span class="p">(</span><span class="n">sentence</span><span class="p">,</span> <span class="n">vocab_to_int</span><span class="p">):</span>
    <span class="n">word_ids</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">sentence</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">vocab_to_int</span><span class="p">:</span>
            <span class="n">word_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="n">word</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">word_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab_to_int</span><span class="p">[</span><span class="s1">&#39;&lt;UNK&gt;&#39;</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">word_ids</span>

<span class="n">tests</span><span class="o">.</span><span class="n">test_sentence_to_seq</span><span class="p">(</span><span class="n">sentence_to_seq</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>Tests Passed
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Traduzir">Traduzir<a class="anchor-link" href="#Traduzir">&#182;</a></h2><p>Isso irá traduzir o <code>translate_sentence</code> do inglês para o francês.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[33]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">translate_sentence</span> <span class="o">=</span> <span class="s1">&#39;he saw a old yellow truck .&#39;</span>

<span class="n">translate_sentence</span> <span class="o">=</span> <span class="n">sentence_to_seq</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">,</span> <span class="n">source_vocab_to_int</span><span class="p">)</span>

<span class="n">loaded_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">loaded_graph</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="c1"># Load saved model</span>
    <span class="n">loader</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="n">load_path</span> <span class="o">+</span> <span class="s1">&#39;.meta&#39;</span><span class="p">)</span>
    <span class="n">loader</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="n">load_path</span><span class="p">)</span>

    <span class="n">input_data</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;input:0&#39;</span><span class="p">)</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;predictions:0&#39;</span><span class="p">)</span>
    <span class="n">target_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;target_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">source_sequence_length</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;source_sequence_length:0&#39;</span><span class="p">)</span>
    <span class="n">keep_prob</span> <span class="o">=</span> <span class="n">loaded_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">&#39;keep_prob:0&#39;</span><span class="p">)</span>

    <span class="n">translate_logits</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="p">{</span><span class="n">input_data</span><span class="p">:</span> <span class="p">[</span><span class="n">translate_sentence</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">target_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)</span><span class="o">*</span><span class="mi">2</span><span class="p">]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">source_sequence_length</span><span class="p">:</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">translate_sentence</span><span class="p">)]</span><span class="o">*</span><span class="n">batch_size</span><span class="p">,</span>
                                         <span class="n">keep_prob</span><span class="p">:</span> <span class="mf">1.0</span><span class="p">})[</span><span class="mi">0</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Input&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  English Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">source_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_sentence</span><span class="p">]))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  Word Ids:      </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;  French Words: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">target_int_to_vocab</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">translate_logits</span><span class="p">])))</span>
</pre></div>

</div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area"><div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>INFO:tensorflow:Restoring parameters from checkpoints/dev
Input
  Word Ids:      [4, 13, 223, 209, 214, 61, 162]
  English Words: [&#39;he&#39;, &#39;saw&#39;, &#39;a&#39;, &#39;old&#39;, &#39;yellow&#39;, &#39;truck&#39;, &#39;.&#39;]

Prediction
  Word Ids:      [353, 30, 268, 176, 194, 234, 64, 1]
  French Words: il conduit une petite voiture jaune . &lt;EOS&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Tradu&#231;&#227;o-Imperfeita">Tradu&#231;&#227;o Imperfeita<a class="anchor-link" href="#Tradu&#231;&#227;o-Imperfeita">&#182;</a></h2><p>Você pode notar que algumas frases traduzem melhor que outras. Como o conjunto de dados que você está usando tem apenas um vocabulário de 227 palavras em inglês dos milhares que você usa, você só verá bons resultados usando essas palavras. Para este projeto, você não precisa de uma tradução perfeita. No entanto, se você quiser criar um modelo de tradução melhor, precisará de dados melhores.</p>
<p>Você pode treinar no [WMT10 corpus francês-inglês] (<a href="http://www.statmt.org/wmt10/training-giga-fren.tar">http://www.statmt.org/wmt10/training-giga-fren.tar</a>). Este conjunto de dados tem mais vocabulário e mais rico em tópicos discutidos. No entanto, isso levará dias para treinar, portanto, verifique se você tem uma GPU e se a rede neural está tendo um bom desempenho no conjunto de dados que fornecemos. Apenas certifique-se de tocar com o corpus do WMT10 depois de enviar este projeto.</p>
<h2 id="Enviando-este-projeto">Enviando este projeto<a class="anchor-link" href="#Enviando-este-projeto">&#182;</a></h2><p>Ao enviar este projeto, certifique-se de executar todas as células antes de salvar o bloco de anotações. Salve o arquivo do notebook como "dlnd_language_translation.ipynb" e salve-o como um arquivo HTML em "File" -&gt; "Download as". Inclua os arquivos "helper.py" e "problem_unittests.py" no seu envio.</p>

</div>
</div>
</div>
    </div>
  </div>
</body>
</html>
